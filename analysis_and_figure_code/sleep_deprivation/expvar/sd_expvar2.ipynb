{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import scipy.signal as sg\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from neuropy import plotting\n",
    "import subjects\n",
    "from neuropy.core import BinnedSpiketrain\n",
    "import ev_utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### During quiet waking only\n",
    "- Reviewers had raised an important point that we are comparing waking/quiet-waking to sleep rather than sleep-deprivation to sleep.\n",
    "- To address this we thought of provided explained variance for quiet waking period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core import BinnedSpiketrain\n",
    "import pingouin as pg\n",
    "\n",
    "sessions = subjects.pf_sess()\n",
    "\n",
    "ev_df = []\n",
    "for s, sess in enumerate(sessions):\n",
    "    pre = sess.paradigm[\"pre\"].flatten()\n",
    "    maze = sess.paradigm[\"maze\"].flatten()\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "\n",
    "    neurons = sess.neurons_stable.get_neuron_type(\"pyr\")\n",
    "    wave_similarity = neurons.get_waveform_similarity()\n",
    "    pairs_bool = wave_similarity < 0.8  # only pairs which are least similar\n",
    "\n",
    "    get_corr = lambda epoch: (\n",
    "        neurons.time_slice(epoch[0], epoch[1])\n",
    "        .get_binned_spiketrains(bin_size=0.25, ignore_epochs=sess.artifact)\n",
    "        .get_pairwise_corr(pairs_bool=pairs_bool)\n",
    "    )\n",
    "\n",
    "    # zt_epochs = sess.paradigm.from_array(\n",
    "    #     [post[0], post[0] + 5 * 3600],\n",
    "    #     [post[0] + 5 * 3600, post[0] + 7.5 * 3600],\n",
    "    #     [\"0-5\", \"5-7.5\"],\n",
    "    # )\n",
    "    zt_epochs = sess.get_zt_epochs(include_pre=False, include_maze=False)\n",
    "    qw = sess.brainstates[\"QW\"]\n",
    "\n",
    "    pre_corr = get_corr(pre)\n",
    "    maze_corr = get_corr(maze)\n",
    "\n",
    "    ev, rev = [], []\n",
    "    for e in zt_epochs.itertuples():\n",
    "        if sess.tag == \"NSD\":\n",
    "            e_qw = qw.time_slice(e.start, e.stop, strict=False)\n",
    "        else:\n",
    "            e_qw = sess.paradigm.from_array([e.start], [e.stop])\n",
    "\n",
    "        e_spkcounts = np.hstack(neurons.get_spikes_in_epochs(e_qw, bin_size=0.25)[0])\n",
    "        e_binspk = BinnedSpiketrain(\n",
    "            e_spkcounts,\n",
    "            0.25,\n",
    "            neuron_ids=neurons.neuron_ids,\n",
    "            shank_ids=neurons.shank_ids,\n",
    "        )\n",
    "        e_corr = e_binspk.get_pairwise_corr(pairs_bool)\n",
    "        e_df = pd.DataFrame(dict(pre=pre_corr, maze=maze_corr, e=e_corr))\n",
    "        kw = dict(data=e_df, x=\"maze\")\n",
    "        ev.append(pg.partial_corr(**kw, y=\"e\", covar=\"pre\").r.values[0] ** 2)\n",
    "        rev.append(pg.partial_corr(**kw, y=\"pre\", covar=\"e\").r.values[0] ** 2)\n",
    "\n",
    "    ev_diff = np.array(ev) - np.array(rev)\n",
    "    ev_perc = (ev_diff / np.array(rev)) * 100\n",
    "\n",
    "    ev_df.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"ev\": ev,\n",
    "                \"rev\": rev,\n",
    "                \"ev_diff\": ev_diff,\n",
    "                \"ev_perc\": ev_perc,\n",
    "                \"zt\": zt_epochs.labels,\n",
    "                \"session\": s,\n",
    "                \"name\": sess.animal.name + sess.animal.day,\n",
    "                \"sex\": sess.animal.sex,\n",
    "                \"grp\": sess.tag,\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "ev_df = pd.concat(ev_df, ignore_index=True)\n",
    "subjects.GroupData().save(ev_df, \"ev_in_qw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters import stripplot\n",
    "\n",
    "fig = plotting.Fig(5, 4)\n",
    "\n",
    "ax = fig.subplot(fig.gs[0])\n",
    "\n",
    "# sns.boxplot(data=ev_df,x='zt',y='ev',hue='grp',showfliers=False)\n",
    "stripplot(data=ev_df, x=\"zt\", y=\"ev_diff\", hue=\"grp\", dodge=True, stat_anot=True, ax=ax)\n",
    "ax.set_ylabel(\"Explained variance (above chance level)\")\n",
    "ax.set_xlabel(\"ZT bins\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap/Resample pairs comparision between SD and NSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "from ev_funcs import sd_delta_ev\n",
    "\n",
    "sessions = subjects.pf_sess()\n",
    "pcorr_df = []\n",
    "for sub, sess in enumerate(tqdm(sessions)):\n",
    "    pre = sess.paradigm[\"pre\"].flatten()\n",
    "    maze = sess.paradigm[\"maze\"].flatten()\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "\n",
    "    zt_epochs = sess.get_zt_epochs()\n",
    "\n",
    "    neurons = sess.neurons_stable.get_neuron_type(\"pyr\")\n",
    "    wave_similarity = neurons.get_waveform_similarity()\n",
    "    pairs_bool = wave_similarity < 0.8  # only pairs which are least similar\n",
    "\n",
    "    get_corr = lambda epoch: (\n",
    "        neurons.time_slice(epoch[0], epoch[1])\n",
    "        .get_binned_spiketrains(bin_size=0.25, ignore_epochs=sess.artifact)\n",
    "        .get_pairwise_corr(pairs_bool=pairs_bool)\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    # df[\"pre\"] = get_corr(pre)\n",
    "    # df[\"maze\"] = get_corr(maze)\n",
    "\n",
    "    for i, e in enumerate(zt_epochs.itertuples()):\n",
    "        df[e.label] = get_corr([e.start, e.stop])\n",
    "\n",
    "    df[\"session\"] = sub\n",
    "    df[\"grp\"] = sess.tag\n",
    "\n",
    "    pcorr_df.append(df)\n",
    "\n",
    "pcorr_df = pd.concat(pcorr_df, ignore_index=True)\n",
    "# subjects.GroupData().save(ev_df, \"ev_chunks_shuffle\")\n",
    "\n",
    "# ------ Shuffling  -------\n",
    "rng = np.random.default_rng()\n",
    "ev_df = []\n",
    "# ev_df.append(\n",
    "#     pd.DataFrame(dict(delta_ev=get_ev(pcorr_df), zt=zt_epochs.labels[2:], method=\"exp\"))\n",
    "# )\n",
    "data_ev = sd_delta_ev(pcorr_df)\n",
    "\n",
    "pcorr_maze = (\n",
    "    pcorr_df.loc[:, [\"PRE\", \"MAZE\", \"session\", \"grp\"]].copy().reset_index(drop=True)\n",
    ")\n",
    "pcorr_post = pcorr_df.loc[:, [\"0-2.5\", \"2.5-5\", \"5-7.5\"]].copy().reset_index(drop=True)\n",
    "\n",
    "ev = []\n",
    "for i in range(1000):\n",
    "    shuff_df = pd.concat(\n",
    "        [pcorr_maze, pcorr_post.sample(frac=1, replace=True).reset_index(drop=True)],\n",
    "        axis=1,\n",
    "    )\n",
    "    shuff_df = pd.DataFrame(\n",
    "        dict(\n",
    "            delta_ev=data_ev - sd_delta_ev(shuff_df),\n",
    "            zt=zt_epochs.labels[2:],\n",
    "            method=\"shuffle\",\n",
    "        )\n",
    "    )\n",
    "    ev_df.append(shuff_df)\n",
    "\n",
    "ev_df = pd.concat(ev_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotting.Fig(5, 4)\n",
    "\n",
    "ax = fig.subplot(fig.gs[0])\n",
    "sns.boxplot(data=ev_df, x=\"zt\", y=\"delta_ev\", hue=\"method\", ax=ax)\n",
    "# fig.savefig(subjects.figpath_sd / \"delta_ev_with_shuffle\")\n",
    "# ax.set_yscale('log')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compared pooled reactivation with shuffles in 15 minutes time windows\n",
    "- In this I calculated EV using pooled pairwise correlations across sessions (while excluding one session each time) and comparing that to shuffled (across NSD and SD) pairs with replacement.\n",
    "\n",
    "From Kamran\n",
    ">Another good control (supplementary) would be to repeat it n times by excluding each of n animals. This would confirm that no single animal is biasing the results.\n",
    "- Two ways of plotting it, one will difference in EV between NSD and SD sessions or plotting each curve separately with their shuffles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "\n",
    "pcorr_df = []\n",
    "for sub, sess in enumerate(tqdm(sessions)):\n",
    "    pre = sess.paradigm[\"pre\"].flatten()\n",
    "    maze = sess.paradigm[\"maze\"].flatten()\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "\n",
    "    zt_epochs = sess.get_sliding_zt_epochs(window=900, slideby=300)\n",
    "\n",
    "    neurons = sess.neurons_stable.get_neuron_type(\"pyr\")\n",
    "    wave_similarity = neurons.get_waveform_similarity()\n",
    "    pairs_bool = wave_similarity < 0.8  # only pairs which are least similar\n",
    "\n",
    "    get_corr = lambda epoch: (\n",
    "        neurons.time_slice(epoch[0], epoch[1])\n",
    "        .get_binned_spiketrains(bin_size=0.25, ignore_epochs=sess.artifact)\n",
    "        .get_pairwise_corr(pairs_bool=pairs_bool)\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for i, e in enumerate(zt_epochs.itertuples()):\n",
    "        df[e.label] = get_corr([e.start, e.stop])\n",
    "\n",
    "    df[\"session\"] = sub\n",
    "    df[\"grp\"] = sess.tag\n",
    "\n",
    "    pcorr_df.append(df)\n",
    "\n",
    "pcorr_df = pd.concat(pcorr_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ev_funcs import sd_delta_ev\n",
    "\n",
    "ev_df = []\n",
    "non_shuffled_col = [\"PRE\", \"MAZE\", \"session\", \"grp\"]\n",
    "\n",
    "# ===== Leave one session out =========\n",
    "n_sessions = len(sessions)\n",
    "for i in tqdm(range(n_sessions)):\n",
    "    df = pcorr_df[pcorr_df[\"session\"] != i]  # one session left out\n",
    "\n",
    "    # Uncomment if using difference of explained variance\n",
    "    # ev_df.append(\n",
    "    #     pd.DataFrame(\n",
    "    #         dict(delta_ev=sd_delta_ev(df), zt=zt_epochs.labels[2:], method=\"exp\")\n",
    "    #     )\n",
    "    # )\n",
    "    _, nsd_ev, sd_ev = sd_delta_ev(df)\n",
    "\n",
    "    ev_df.append(pd.DataFrame(dict(ev=nsd_ev, zt=zt_epochs.labels[2:], method=\"NSD\")))\n",
    "    ev_df.append(pd.DataFrame(dict(ev=sd_ev, zt=zt_epochs.labels[2:], method=\"SD\")))\n",
    "\n",
    "    # ====== Shuffling ===========\n",
    "    df_maze = df.loc[:, non_shuffled_col].copy().reset_index(drop=True)\n",
    "    df_post = df.loc[:, ~df.columns.isin(df_maze.columns)].copy().reset_index(drop=True)\n",
    "\n",
    "    for i in range(100):\n",
    "        df_shuff = pd.concat(\n",
    "            [df_maze, df_post.sample(frac=1, replace=True).reset_index(drop=True)],\n",
    "            axis=1,\n",
    "        )\n",
    "        # Uncomment if using difference of explained variance\n",
    "        # df = pd.DataFrame(\n",
    "        #     dict(\n",
    "        #         delta_ev=sd_delta_ev(df_shuff),\n",
    "        #         zt=zt_epochs.labels[2:],\n",
    "        #         method=\"shuffle\",\n",
    "        #     )\n",
    "        # )\n",
    "        _, nsd_shuff, sd_shuff = sd_delta_ev(df_shuff)\n",
    "\n",
    "        ev_df.append(\n",
    "            pd.DataFrame(dict(ev=nsd_shuff, zt=zt_epochs.labels[2:], method=\"NSD_shuff\"))\n",
    "        )\n",
    "        ev_df.append(\n",
    "            pd.DataFrame(dict(ev=sd_shuff, zt=zt_epochs.labels[2:], method=\"SD_shuff\"))\n",
    "        )\n",
    "\n",
    "ev_df = pd.concat(ev_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage sleep in the background\n",
    "nrem_df = []\n",
    "for sess in sessions:\n",
    "    zt_epochs = sess.get_sliding_zt_epochs()[2:]\n",
    "    states = sess.brainstates[\"NREM\"]\n",
    "    nrem_dur = []\n",
    "    for e in zt_epochs.itertuples():\n",
    "        nrem_dur.append(states.time_slice(e.start, e.stop, strict=False).durations.sum())\n",
    "    nrem_dur = np.array(nrem_dur)\n",
    "\n",
    "    nrem_df.append(\n",
    "        pd.DataFrame(dict(zt=zt_epochs.labels, nrem=nrem_dur / (15 * 60), grp=sess.tag))\n",
    "    )\n",
    "\n",
    "nrem_df = pd.concat(nrem_df, ignore_index=True)\n",
    "nrem_df[\"zt\"] = nrem_df[\"zt\"].values.astype(float)\n",
    "\n",
    "ev_df[\"zt\"] = ev_df[\"zt\"].values.astype(float)\n",
    "\n",
    "fig = plotting.Fig(4, 2)\n",
    "palette = subjects.colors_sd(1) + subjects.colors_sd(1.5)\n",
    "ax = fig.subplot(fig.gs[0])\n",
    "sns.lineplot(\n",
    "    data=ev_df,\n",
    "    x=\"zt\",\n",
    "    y=\"ev\",\n",
    "    hue=\"method\",\n",
    "    errorbar=\"sd\",\n",
    "    palette=palette,\n",
    "    err_kws=dict(ec=None),\n",
    ")\n",
    "ax.set_ylabel(\"Explained variance\")\n",
    "ax.set_xlabel(\"Time(h)\")\n",
    "ax.set_title(\"Reactivation using pooled pairwise correlation\")\n",
    "fig.legend_with_text_only(ax)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "for g, grp in enumerate([\"NSD\", \"SD\"]):\n",
    "    df = nrem_df[nrem_df.grp == grp]\n",
    "    mean_nrem = df.groupby(\"zt\").mean(numeric_only=True)[\"nrem\"]\n",
    "    ax2.fill_between(mean_nrem.index, 0, mean_nrem, step=\"mid\", alpha=0.5)\n",
    "\n",
    "fig.toggle_spines(ax2, sides=[\"right\"], keep=True)\n",
    "ax2.set_ylabel(\"NREM proportion\")\n",
    "ax2.legend(\"\", frameon=False)\n",
    "fig.savefig(subjects.figpath_sd / \"pooled_ev_with_shuffle\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QW for NSD and usual for SD sessions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core import BinnedSpiketrain\n",
    "\n",
    "sessions = subjects.pf_sess()\n",
    "\n",
    "pcorr_df = []\n",
    "for sub, sess in enumerate(tqdm(sessions)):\n",
    "    pre = sess.paradigm[\"pre\"].flatten()\n",
    "    maze = sess.paradigm[\"maze\"].flatten()\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "\n",
    "    zt_epochs = sess.get_sliding_zt_epochs(window=900, slideby=300)\n",
    "\n",
    "    neurons = sess.neurons_stable.get_neuron_type(\"pyr\")\n",
    "    wave_similarity = neurons.get_waveform_similarity()\n",
    "    pairs_bool = wave_similarity < 0.8  # only pairs which are least similar\n",
    "\n",
    "    get_corr = lambda epoch: (\n",
    "        neurons.time_slice(epoch[0], epoch[1])\n",
    "        .get_binned_spiketrains(bin_size=0.25, ignore_epochs=sess.artifact)\n",
    "        .get_pairwise_corr(pairs_bool=pairs_bool)\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # for i, e in enumerate(zt_epochs.itertuples()):\n",
    "    #     df[e.label] = get_corr([e.start, e.stop])\n",
    "\n",
    "    qw = sess.brainstates[\"QW\"]\n",
    "\n",
    "    pre_corr = get_corr(pre)\n",
    "    maze_corr = get_corr(maze)\n",
    "\n",
    "    ev, rev = [], []\n",
    "    for e in zt_epochs.itertuples():\n",
    "        e_qw = qw.time_slice(e.start, e.stop, strict=False)\n",
    "        # if sess.tag == \"NSD\":\n",
    "        #     e_qw = qw.time_slice(e.start, e.stop, strict=False)\n",
    "        # else:\n",
    "        #     e_qw = sess.paradigm.from_array([e.start], [e.stop])\n",
    "\n",
    "        if e_qw.durations.sum() > 1:\n",
    "            e_spkcounts = np.hstack(neurons.get_spikes_in_epochs(e_qw, bin_size=0.25)[0])\n",
    "            e_binspk = BinnedSpiketrain(\n",
    "                e_spkcounts,\n",
    "                0.25,\n",
    "                neuron_ids=neurons.neuron_ids,\n",
    "                shank_ids=neurons.shank_ids,\n",
    "            )\n",
    "            e_corr = e_binspk.get_pairwise_corr(pairs_bool)\n",
    "        else:\n",
    "            e_corr = np.nan * np.ones(len(pre_corr))\n",
    "\n",
    "        df[e.label] = e_corr\n",
    "\n",
    "    df[\"session\"] = sub\n",
    "    df[\"grp\"] = sess.tag\n",
    "\n",
    "    pcorr_df.append(df)\n",
    "\n",
    "pcorr_df = pd.concat(pcorr_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ev_funcs import sd_delta_ev\n",
    "\n",
    "ev_df = []\n",
    "non_shuffled_col = [\"PRE\", \"MAZE\", \"session\", \"grp\"]\n",
    "\n",
    "# ===== Leave one session out =========\n",
    "n_sessions = len(sessions)\n",
    "for i in tqdm(range(n_sessions)):\n",
    "    df = pcorr_df[pcorr_df[\"session\"] != i]  # one session left out\n",
    "\n",
    "    # Uncomment if using difference of explained variance\n",
    "    # ev_df.append(\n",
    "    #     pd.DataFrame(\n",
    "    #         dict(delta_ev=sd_delta_ev(df), zt=zt_epochs.labels[2:], method=\"exp\")\n",
    "    #     )\n",
    "    # )\n",
    "    _, nsd_ev, sd_ev = sd_delta_ev(df)\n",
    "\n",
    "    ev_df.append(pd.DataFrame(dict(ev=nsd_ev, zt=zt_epochs.labels[2:], method=\"NSD\")))\n",
    "    ev_df.append(pd.DataFrame(dict(ev=sd_ev, zt=zt_epochs.labels[2:], method=\"SD\")))\n",
    "\n",
    "    # ====== Shuffling ===========\n",
    "    df_maze = df.loc[:, non_shuffled_col].copy().reset_index(drop=True)\n",
    "    df_post = df.loc[:, ~df.columns.isin(df_maze.columns)].copy().reset_index(drop=True)\n",
    "\n",
    "    # for i in range(100):\n",
    "\n",
    "    #     df_shuff = pd.concat(\n",
    "    #         [df_maze, df_post.sample(frac=1, replace=True).reset_index(drop=True)],\n",
    "    #         axis=1,\n",
    "    #     )\n",
    "    #     # Uncomment if using difference of explained variance\n",
    "    #     # df = pd.DataFrame(\n",
    "    #     #     dict(\n",
    "    #     #         delta_ev=sd_delta_ev(df_shuff),\n",
    "    #     #         zt=zt_epochs.labels[2:],\n",
    "    #     #         method=\"shuffle\",\n",
    "    #     #     )\n",
    "    #     # )\n",
    "    #     _, nsd_shuff, sd_shuff = sd_delta_ev(df_shuff)\n",
    "\n",
    "    #     ev_df.append(\n",
    "    #         pd.DataFrame(\n",
    "    #             dict(ev=nsd_shuff, zt=zt_epochs.labels[2:], method=\"NSD_shuff\")\n",
    "    #         )\n",
    "    #     )\n",
    "    #     ev_df.append(\n",
    "    #         pd.DataFrame(dict(ev=sd_shuff, zt=zt_epochs.labels[2:], method=\"SD_shuff\"))\n",
    "    #     )\n",
    "\n",
    "ev_df = pd.concat(ev_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage sleep in the background\n",
    "nrem_df = []\n",
    "for sess in sessions:\n",
    "    zt_epochs = sess.get_sliding_zt_epochs()[2:]\n",
    "    states = sess.brainstates[\"QW\"]\n",
    "    nrem_dur = []\n",
    "    for e in zt_epochs.itertuples():\n",
    "        nrem_dur.append(states.time_slice(e.start, e.stop, strict=False).durations.sum())\n",
    "    nrem_dur = np.array(nrem_dur)\n",
    "\n",
    "    nrem_df.append(\n",
    "        pd.DataFrame(dict(zt=zt_epochs.labels, nrem=nrem_dur / (15 * 60), grp=sess.tag))\n",
    "    )\n",
    "\n",
    "nrem_df = pd.concat(nrem_df, ignore_index=True)\n",
    "nrem_df[\"zt\"] = nrem_df[\"zt\"].values.astype(float)\n",
    "\n",
    "ev_df[\"zt\"] = ev_df[\"zt\"].values.astype(float)\n",
    "\n",
    "fig = plotting.Fig(4, 2)\n",
    "palette = subjects.colors_sd(1) + subjects.colors_sd(1.5)\n",
    "ax = fig.subplot(fig.gs[0])\n",
    "sns.lineplot(\n",
    "    data=ev_df,\n",
    "    x=\"zt\",\n",
    "    y=\"ev\",\n",
    "    hue=\"method\",\n",
    "    errorbar=\"sd\",\n",
    "    palette=palette,\n",
    "    err_kws=dict(ec=None),\n",
    ")\n",
    "ax.set_ylabel(\"Explained variance\")\n",
    "ax.set_xlabel(\"Time(h)\")\n",
    "ax.set_title(\"Reactivation using pooled pairwise correlation\")\n",
    "fig.legend_with_text_only(ax)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "for g, grp in enumerate([\"NSD\", \"SD\"]):\n",
    "    df = nrem_df[nrem_df.grp == grp]\n",
    "    mean_nrem = df.groupby(\"zt\").mean(numeric_only=True)[\"nrem\"]\n",
    "    ax2.fill_between(mean_nrem.index, 0, mean_nrem, step=\"mid\", alpha=0.5)\n",
    "\n",
    "fig.toggle_spines(ax2, sides=[\"right\"], keep=True)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.set_ylabel(\"NREM proportion\")\n",
    "ax2.legend(\"\", frameon=False)\n",
    "fig.savefig(subjects.figpath_sd / \"pooled_ev_with_shuffle\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing decay of pairwise correlation between PRE and SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "\n",
    "pre_df, sd_df = [], []\n",
    "for sub, sess in enumerate(tqdm(sessions)):\n",
    "    neurons = sess.neurons_stable.get_neuron_type(\"pyr\")\n",
    "\n",
    "    pre = sess.paradigm[\"pre\"].flatten()\n",
    "    maze = sess.paradigm[\"maze\"].flatten()\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "\n",
    "    pre_epoch = sess.get_zt_epochs()[\"PRE\"]\n",
    "\n",
    "    wave_similarity = neurons.get_waveform_similarity()\n",
    "    pairs_bool = wave_similarity < 0.8  # only pairs which are least similar\n",
    "\n",
    "    get_corr = lambda epoch: (\n",
    "        neurons.time_slice(epoch[0], epoch[1])\n",
    "        .get_binned_spiketrains(bin_size=0.25, ignore_epochs=sess.artifact)\n",
    "        .get_pairwise_corr(pairs_bool=pairs_bool)\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # for i, e in enumerate(zt_epochs.itertuples()):\n",
    "    #     df[e.label] = get_corr([e.start, e.stop])\n",
    "\n",
    "    qw = sess.brainstates[\"QW\"]\n",
    "\n",
    "    pre_corr = get_corr(pre)\n",
    "    maze_corr = get_corr(maze)\n",
    "\n",
    "    ev, rev = [], []\n",
    "    for e in zt_epochs.itertuples():\n",
    "        if sess.tag == \"NSD\":\n",
    "            e_qw = qw.time_slice(e.start, e.stop, strict=False)\n",
    "        else:\n",
    "            e_qw = sess.paradigm.from_array([e.start], [e.stop])\n",
    "        if e_qw.durations.sum() > 1:\n",
    "            e_spkcounts = np.hstack(neurons.get_spikes_in_epochs(e_qw, bin_size=0.25)[0])\n",
    "            e_binspk = BinnedSpiketrain(\n",
    "                e_spkcounts,\n",
    "                0.25,\n",
    "                neuron_ids=neurons.neuron_ids,\n",
    "                shank_ids=neurons.shank_ids,\n",
    "            )\n",
    "            e_corr = e_binspk.get_pairwise_corr(pairs_bool)\n",
    "        else:\n",
    "            e_corr = np.nan * np.ones(len(pre_corr))\n",
    "\n",
    "        df[e.label] = e_corr\n",
    "\n",
    "    df[\"session\"] = sub\n",
    "    df[\"grp\"] = sess.tag\n",
    "\n",
    "    pcorr_df.append(df)\n",
    "\n",
    "pcorr_df = pd.concat(pcorr_df, ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EV NREM vs QW Hiro, my data, Grosmark data combined\n",
    "- Each dataset will have separate curves, so total 6 curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core import BinnedSpiketrain\n",
    "\n",
    "sessions = (\n",
    "    subjects.Nsd().pf_sess + subjects.NsdHiro().allsess + subjects.NsdGrosmark().allsess\n",
    ")\n",
    "\n",
    "# sessions = subjects.NsdGrosmark().ratBuddy_06272013\n",
    "\n",
    "pcorr_df = []\n",
    "\n",
    "for sub, sess in enumerate(tqdm(sessions)):\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "    zt_epochs = sess.get_sliding_zt_epochs(window=900, slideby=300)\n",
    "    pre = zt_epochs[\"PRE\"].flatten()\n",
    "    maze = zt_epochs[\"MAZE\"].flatten()\n",
    "    zt_epochs = zt_epochs[2:]  # removed PRE and MAZE\n",
    "\n",
    "    if sess.tag == \"NSD_HM\":\n",
    "        neurons = sess.neurons.get_neuron_type(\"pyr\")\n",
    "        # Across shnaks only\n",
    "        shank_ids = neurons.shank_ids\n",
    "        pairs_bool = shank_ids.reshape(-1, 1) - shank_ids.reshape(1, -1)\n",
    "        dataset_tag = \"HM\"\n",
    "\n",
    "    elif sess.tag == \"NSD_GM\":\n",
    "        neurons = sess.neurons.get_neuron_type(\"pyr\")\n",
    "        # Across shnaks only\n",
    "        shank_ids = neurons.shank_ids\n",
    "        pairs_bool = shank_ids.reshape(-1, 1) - shank_ids.reshape(1, -1)\n",
    "        dataset_tag = \"GM\"\n",
    "\n",
    "    else:\n",
    "        neurons = sess.neurons_stable.get_neuron_type(\"pyr\")\n",
    "        wave_similarity = neurons.get_waveform_similarity()\n",
    "        pairs_bool = wave_similarity < 0.8  # only pairs which are least similar\n",
    "        dataset_tag = \"BG\"\n",
    "\n",
    "    get_corr = lambda epoch: (\n",
    "        neurons.time_slice(epoch[0], epoch[1])\n",
    "        .get_binned_spiketrains(bin_size=0.25, ignore_epochs=sess.artifact)\n",
    "        .get_pairwise_corr(pairs_bool=pairs_bool)\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"PRE\"] = get_corr(pre)\n",
    "    df[\"MAZE\"] = get_corr(maze)\n",
    "\n",
    "    for state_name in [\"NREM\", \"QW\"]:\n",
    "        states = sess.brainstates[state_name]\n",
    "\n",
    "        for e in zt_epochs.itertuples():\n",
    "            e_states = states.time_slice(e.start, e.stop, strict=False)\n",
    "            # if sess.tag == \"NSD\":\n",
    "            #     e_qw = qw.time_slice(e.start, e.stop, strict=False)\n",
    "            # else:\n",
    "            #     e_qw = sess.paradigm.from_array([e.start], [e.stop])\n",
    "\n",
    "            if e_states.durations.sum() > 1:\n",
    "                # In grosmark Buddy session sometimes there are 'zero' duration epoch, so taking care of that\n",
    "                e_states = e_states.duration_slice(min_dur=0.5)\n",
    "                e_spkcounts = np.hstack(\n",
    "                    neurons.get_spikes_in_epochs(e_states, bin_size=0.25)[0]\n",
    "                )\n",
    "                e_binspk = BinnedSpiketrain(\n",
    "                    e_spkcounts,\n",
    "                    0.25,\n",
    "                    neuron_ids=neurons.neuron_ids,\n",
    "                    shank_ids=neurons.shank_ids,\n",
    "                )\n",
    "                e_corr = e_binspk.get_pairwise_corr(pairs_bool)\n",
    "            else:\n",
    "                e_corr = np.nan * np.ones(len(df))\n",
    "\n",
    "            df[f\"{state_name}_{e.label}\"] = e_corr\n",
    "\n",
    "    df[\"session\"] = sub\n",
    "    df[\"grp\"] = sess.tag\n",
    "    df[\"dataset\"] = dataset_tag\n",
    "\n",
    "    pcorr_df.append(df)\n",
    "\n",
    "pcorr_df = pd.concat(pcorr_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ev_funcs import sd_delta_ev\n",
    "import pingouin as pg\n",
    "\n",
    "ev_df = []\n",
    "\n",
    "n_sessions = len(sessions)\n",
    "for dataset in [\"BG\", \"HM\", \"GM\"]:\n",
    "    df_dataset = pcorr_df[pcorr_df.dataset == dataset]\n",
    "    session_id = np.unique(df_dataset.session.values)\n",
    "\n",
    "    for i in tqdm(session_id):\n",
    "        df = df_dataset[df_dataset[\"session\"] != i]  # one session left out\n",
    "        df = df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "        columns = df.columns\n",
    "        epochs = columns[~df.columns.isin([\"PRE\", \"MAZE\", \"grp\", \"session\", \"dataset\"])]\n",
    "\n",
    "        try:\n",
    "            ev = np.zeros(len(epochs))\n",
    "            for e, epoch in enumerate(epochs):\n",
    "                r = pg.partial_corr(data=df, x=\"MAZE\", y=epoch, covar=\"PRE\").r.values\n",
    "                ev[e] = r**2\n",
    "        except:\n",
    "            ev = np.nan * np.zeros(len(epochs))\n",
    "\n",
    "        new_labels = [f\"{dataset}-{_}\" for _ in epochs]\n",
    "        ev_df.append(pd.DataFrame(dict(ev=ev, zt=new_labels)))\n",
    "        # ev_df.append(pd.DataFrame(dict(ev=sd_ev, zt=zt_epochs.labels[2:], method=\"SD\")))\n",
    "\n",
    "ev_df = pd.concat(ev_df, ignore_index=True)\n",
    "# separating zt names to float and adding a column for states\n",
    "ev_df[\"state\"] = [_.split(\"_\")[0] for _ in ev_df[\"zt\"]]  # separate dataset/state name\n",
    "ev_df[\"zt\"] = [float(_.split(\"_\")[1]) for _ in ev_df[\"zt\"]]  # string to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from palettable.colorbrewer.qualitative import Paired_6_r,Dark2_6,Accent_6,Pastel2_6\n",
    "from palettable.cartocolors.qualitative import Bold_6, Vivid_6, Pastel_6\n",
    "\n",
    "# Percentage sleep in the background\n",
    "nrem_df = []\n",
    "for sess in sessions:\n",
    "    zt_epochs = sess.get_sliding_zt_epochs()[2:]\n",
    "    states = sess.brainstates[\"QW\"]\n",
    "    nrem_dur = []\n",
    "    for e in zt_epochs.itertuples():\n",
    "        nrem_dur.append(states.time_slice(e.start, e.stop, strict=False).durations.sum())\n",
    "    nrem_dur = np.array(nrem_dur)\n",
    "\n",
    "    nrem_df.append(\n",
    "        pd.DataFrame(dict(zt=zt_epochs.labels, nrem=nrem_dur / (15 * 60), grp=sess.tag))\n",
    "    )\n",
    "\n",
    "nrem_df = pd.concat(nrem_df, ignore_index=True)\n",
    "nrem_df[\"zt\"] = nrem_df[\"zt\"].values.astype(float)\n",
    "\n",
    "\n",
    "fig = plotting.Fig(4, 2)\n",
    "palette = subjects.colors_sd(1) + subjects.colors_sd(1.5)\n",
    "ax = fig.subplot(fig.gs[0])\n",
    "sns.lineplot(\n",
    "    data=ev_df,\n",
    "    x=\"zt\",\n",
    "    y=\"ev\",\n",
    "    hue=\"state\",\n",
    "    errorbar=\"se\",\n",
    "    palette=Vivid_6.mpl_colors,\n",
    "    err_kws=dict(ec=None),\n",
    ")\n",
    "ax.set_ylabel(\"Explained variance\")\n",
    "ax.set_xlabel(\"Time(h)\")\n",
    "ax.set_title(\"Reactivation using pooled pairwise correlation (Hiro's data, NREM only)\")\n",
    "fig.legend_with_text_only(ax)\n",
    "\n",
    "# ax2 = ax.twinx()\n",
    "\n",
    "# for g, grp in enumerate([\"NSD\", \"SD\", \"NSD_Hiro\"]):\n",
    "#     df = nrem_df[nrem_df.grp == grp]\n",
    "#     mean_nrem = df.groupby(\"zt\").mean(numeric_only=True)[\"nrem\"]\n",
    "#     ax2.fill_between(mean_nrem.index, 0, mean_nrem, step=\"mid\", alpha=0.5)\n",
    "\n",
    "# fig.toggle_spines(ax2, sides=[\"right\"], keep=True)\n",
    "# ax2.set_ylim(0, 1)\n",
    "# ax2.set_xlim(0, 8)\n",
    "# ax2.set_ylabel(\"\")\n",
    "# ax2.legend(\"\", frameon=False)\n",
    "fig.savefig(subjects.figpath_sd / \"alldata_ev_nrem_qw\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarichal bootstraping of pairs within sessions with replacement\n",
    "- Inspired from Saravanan et al., where they claim this way of bootstraping is better when the datasets are not independent. For example, in NSD and SD sessions were performed in the same animal.\n",
    "- Can also be used for brainstate specific calculations \n",
    "- This generates two files: bootstrap_session_pairs_ev.npy (bootstraping at both session and pairs level) and bootstrap_session_only_ev.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "pcorr_df = []\n",
    "for sub, sess in enumerate(tqdm(sessions)):\n",
    "    states = sess.brainstates\n",
    "    zt_epochs = sess.get_zt_epochs()\n",
    "    neurons = sess.neurons_stable.get_neuron_type(\"pyr\")\n",
    "\n",
    "    pcorr, labels = ev_utils.get_pcorr(\n",
    "        neurons=neurons, epochs=zt_epochs, ignore_epochs=sess.artifact\n",
    "    )\n",
    "    df = pd.DataFrame(data=pcorr, columns=labels)\n",
    "\n",
    "    # --- if statewise ------\n",
    "    # pcorr1, labels1 = ev_utils.get_pcorr(\n",
    "    #     neurons=neurons, epochs=zt_epochs[:2], ignore_epochs=sess.artifact\n",
    "    # )\n",
    "    # pcorr2, labels2 = ev_utils.get_pcorr(\n",
    "    #     neurons=neurons, epochs=zt_epochs[2:], sub_epochs=states[\"QW\"]\n",
    "    # )\n",
    "    # df = pd.DataFrame(\n",
    "    #     data=np.hstack([pcorr1, pcorr2]), columns=np.concatenate([labels1, labels2])\n",
    "    # )\n",
    "\n",
    "    df[\"session\"] = sub\n",
    "    df[\"grp\"] = sess.tag\n",
    "    pcorr_df.append(df)\n",
    "\n",
    "pcorr_df = pd.concat(pcorr_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stats_utils import bootstrap_resample\n",
    "from ev_utils import get_ev, get_ev_mean\n",
    "\n",
    "kw = dict(df=pcorr_df, n_iter=10000, n_jobs=10)\n",
    "\n",
    "for level in [\"session\", \"samples\", \"both\"]:\n",
    "    ev_df = bootstrap_resample(level=level, apply=get_ev, **kw)\n",
    "    if level == \"session\":\n",
    "        fname = \"ev_bootstrap_session\"\n",
    "    if level == \"samples\":\n",
    "        fname = \"ev_bootstrap_pairs\"\n",
    "    if level == \"both\":\n",
    "        fname = \"ev_bootstrap_session_pairs\"\n",
    "\n",
    "    subjects.GroupData().save(ev_df, fname)\n",
    "\n",
    "for level in [\"session\", \"samples\", \"both\"]:\n",
    "    ev_df = bootstrap_resample(level=level, apply=get_ev_mean, **kw)\n",
    "    if level == \"session\":\n",
    "        fname = \"ev_bootstrap_session_mean\"\n",
    "    if level == \"samples\":\n",
    "        fname = \"ev_bootstrap_pairs_mean\"\n",
    "    if level == \"both\":\n",
    "        fname = \"ev_bootstrap_session_pairs_mean\"\n",
    "\n",
    "    subjects.GroupData().save(ev_df, fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters import violinplot_sd\n",
    "from stats_utils import get_bootstrap_prob\n",
    "\n",
    "fig = plotting.Fig(5, 5)\n",
    "\n",
    "ax = fig.subplot(fig.gs[0])\n",
    "\n",
    "violinplot_sd(\n",
    "    data=ev_df,\n",
    "    x=\"zt\",\n",
    "    y=\"ev\",\n",
    "    hue=\"grp\",\n",
    "    ax=ax,\n",
    "    # showfliers=False,\n",
    "    # palette=subjects.colors_sd(1),\n",
    "    # saturation=1,\n",
    "    split=False,\n",
    "    stat_across=get_bootstrap_prob,\n",
    "    stat_within=get_bootstrap_prob,\n",
    ")\n",
    "ax.legend(\"\", frameon=False)\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(\"Explained variance\")\n",
    "\n",
    "# fig.savefig(subjects.figpath_sd / \"hierarichal_bootstrap_mean_ev_session\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EV during REM sleep (2.5 hour blocks)\n",
    "- 23/06/2023: No differences were observed between NSD and SD for EV during REM. The magnitude of EV were similar between both conditions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "\n",
    "ev_df = []\n",
    "for s, sess in enumerate(tqdm(sessions)):\n",
    "    pre_maze_epochs = sess.get_zt_epochs()[:2]\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "    neurons = sess.neurons_stable.get_neuron_type(\"pyr\")\n",
    "    rem = sess.brainstates[\"REM\"]\n",
    "\n",
    "    pcorr_pre_maze, pre_maze_labels = ev_utils.get_pcorr(neurons, pre_maze_epochs)\n",
    "    pre_maze_df = pd.DataFrame(pcorr_pre_maze, columns=pre_maze_labels)\n",
    "\n",
    "    if sess.tag == \"NSD\":\n",
    "        zt_epochs = sess.get_zt_epochs()[2:]\n",
    "    if sess.tag == \"SD\":\n",
    "        zt_epochs = sess.get_zt_epochs()[4:]\n",
    "\n",
    "    pcorr_zt, _ = ev_utils.get_pcorr(neurons, zt_epochs, sub_epochs=rem)\n",
    "    zt_df = pd.DataFrame(data=pcorr_zt, columns=zt_epochs.labels)\n",
    "\n",
    "    df = pd.concat([pre_maze_df, zt_df], axis=1)\n",
    "    df[\"session\"] = s\n",
    "    df[\"grp\"] = sess.tag\n",
    "\n",
    "    sess_ev = ev_utils.get_ev(df)\n",
    "    sess_ev[\"session\"] = s\n",
    "    sess_ev[\"grp\"] = sess.tag\n",
    "    ev_df.append(sess_ev)\n",
    "\n",
    "ev_df = pd.concat(ev_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "sns.stripplot(data=ev_df, x=\"zt\", y=\"ev\", hue=\"grp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are EV during correlated with EV during recovery sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = subjects.GroupData().ev_in_chunks\n",
    "sd_data = data[data.grp == \"SD\"]\n",
    "sd1_ev = sd_data[sd_data.zt == \"0-2.5\"]\n",
    "rs_ev = sd_data[sd_data.zt == \"5-7.5\"]\n",
    "\n",
    "x = sd1_ev[\"ev\"]\n",
    "y = rs_ev[\"ev\"]\n",
    "linfit = stats.linregress(x, y)\n",
    "r = linfit.rvalue\n",
    "m = linfit.slope\n",
    "c = linfit.intercept\n",
    "\n",
    "fig = subjects.SdFig().fig2_supp()\n",
    "ax = fig.subplot(fig.gs[0])\n",
    "ax.scatter(x, y, s=10, c=subjects.colors_sd()[1])\n",
    "ax.plot(x, x * m + c, color=\"k\")\n",
    "ax.set_ylabel(\"Explained variance (RS)\")\n",
    "ax.set_xlabel(\"Explained variance (SD1)\")\n",
    "ax.set_title(f\"r = {np.round(r,2)}, pvalue = {np.round(linfit.pvalue,2)}\")\n",
    "ax.set_ylim(0.02, 0.06)\n",
    "\n",
    "fig.savefig(subjects.figpath_sd / \"ev_SD1_vs_RS\", format=\"svg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pairwise correlations (explained variance) for NREM only \n",
    "- Have pairwise correlations only specific to NREM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "\n",
    "pcorr_df = []\n",
    "for s, sess in enumerate(tqdm(sessions)):\n",
    "    pre_maze_epochs = sess.get_zt_epochs()[:2]\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "    neurons = sess.neurons_stable.get_neuron_type(\"pyr\")\n",
    "    nrem = sess.brainstates[\"NREM\"]\n",
    "\n",
    "    pcorr_pre_maze, pre_maze_labels = ev_utils.get_pcorr(neurons, pre_maze_epochs)\n",
    "    pre_maze_df = pd.DataFrame(pcorr_pre_maze, columns=pre_maze_labels)\n",
    "\n",
    "    zt_starts = np.arange(post[0], post[0] + 7.5 * 3600, 300)\n",
    "    zt_stops = zt_starts + 900\n",
    "    zt_labels = np.arange(len(zt_starts)).astype(\"str\")\n",
    "    zt_epochs = sess.paradigm.from_array(zt_starts, zt_stops, zt_labels)\n",
    "\n",
    "    pcorr_zt, _ = ev_utils.get_pcorr(neurons, zt_epochs, sub_epochs=nrem)\n",
    "    zt_df = pd.DataFrame(data=pcorr_zt, columns=zt_labels.astype(\"int\"))\n",
    "\n",
    "    df = pd.concat([pre_maze_df, zt_df], axis=1)\n",
    "    df[\"session\"] = s\n",
    "    df[\"grp\"] = sess.tag\n",
    "    pcorr_df.append(df)\n",
    "\n",
    "pcorr_df = pd.concat(pcorr_df, ignore_index=True)\n",
    "\n",
    "subjects.GroupData().save(pcorr_df, \"pairwise_correlations_NREM\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pairwise correlations (explained variance) for WAKE only \n",
    "- Have pairwise correlations only specific to WAKE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "\n",
    "pcorr_df = []\n",
    "for s, sess in enumerate(tqdm(sessions)):\n",
    "    pre_maze_epochs = sess.get_zt_epochs()[:2]\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "    neurons = sess.neurons_stable.get_neuron_type(\"pyr\")\n",
    "    wake = sess.brainstates.label_slice([\"AW\", \"QW\"]).set_labels(\"WK\").merge_neighbors()\n",
    "\n",
    "    pcorr_pre_maze, pre_maze_labels = ev_utils.get_pcorr(neurons, pre_maze_epochs)\n",
    "    pre_maze_df = pd.DataFrame(pcorr_pre_maze, columns=pre_maze_labels)\n",
    "\n",
    "    zt_starts = np.arange(post[0], post[0] + 7.5 * 3600, 300)\n",
    "    zt_stops = zt_starts + 900\n",
    "    zt_labels = np.arange(len(zt_starts)).astype(\"str\")\n",
    "    zt_epochs = sess.paradigm.from_array(zt_starts, zt_stops, zt_labels)\n",
    "\n",
    "    pcorr_zt, _ = ev_utils.get_pcorr(neurons, zt_epochs, sub_epochs=wake)\n",
    "    zt_df = pd.DataFrame(data=pcorr_zt, columns=zt_labels.astype(\"int\"))\n",
    "\n",
    "    df = pd.concat([pre_maze_df, zt_df], axis=1)\n",
    "    df[\"session\"] = s\n",
    "    df[\"grp\"] = sess.tag\n",
    "    pcorr_df.append(df)\n",
    "\n",
    "pcorr_df = pd.concat(pcorr_df, ignore_index=True)\n",
    "\n",
    "subjects.GroupData().save(pcorr_df, \"pairwise_correlations_WAKE\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise correlations (explained variance) by sleep onset in each session\n",
    "As in the paper we are emphasising comparison between normal sleep and recovery sleep, it makes more sense to have the explained variance curves aligned by the start of NREM rich period. So each session will have different begining time for explained variance curves. In addition add bootstrapping.\n",
    "In addition have separate curves for waking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NRK note**: from below, i appears that BG defined the beginning of this \"NREM rich period\" criteria as the first NREM epoch lasting at last 2 minutes (120 seconds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "sd_paper"
    ]
   },
   "outputs": [],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "\n",
    "pcorr_df = []\n",
    "for s, sess in enumerate(tqdm(sessions)):\n",
    "    pre_maze_epochs = sess.get_zt_epochs()[:2]\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "    neurons = sess.neurons_stable.get_neuron_type(\"pyr\")\n",
    "    nrem = sess.brainstates[\"NREM\"]\n",
    "    good_nrem = (\n",
    "        sess.brainstates.label_slice([\"NREM\"])\n",
    "        .time_slice(*post, strict=False)\n",
    "        .duration_slice(min_dur=120)\n",
    "    )\n",
    "    nrem_onset = good_nrem[0].flatten()[0]\n",
    "\n",
    "    pcorr_pre_maze, pre_maze_labels = ev_utils.get_pcorr(neurons, pre_maze_epochs)\n",
    "    pre_maze_df = pd.DataFrame(pcorr_pre_maze, columns=pre_maze_labels)\n",
    "\n",
    "    zt_starts = np.arange(nrem_onset, post[0] + 7.5 * 3600, 300)\n",
    "    zt_stops = zt_starts + 900\n",
    "    zt_labels = np.arange(len(zt_starts)).astype(\"str\")\n",
    "    zt_epochs = sess.paradigm.from_array(zt_starts, zt_stops, zt_labels)\n",
    "\n",
    "    pcorr_zt, _ = ev_utils.get_pcorr(neurons, zt_epochs, sub_epochs=nrem)\n",
    "    zt_df = pd.DataFrame(data=pcorr_zt, columns=zt_labels.astype(\"int\"))\n",
    "\n",
    "    df = pd.concat([pre_maze_df, zt_df], axis=1)\n",
    "    df[\"session\"] = s\n",
    "    df[\"grp\"] = sess.tag\n",
    "    pcorr_df.append(df)\n",
    "\n",
    "pcorr_df = pd.concat(pcorr_df, ignore_index=True)\n",
    "\n",
    "subjects.GroupData().save(pcorr_df, \"pairwise_correlations_aligned_by_NREM_onset\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate pairwise correlations (explained variance) for WAKE\n",
    "Similar to NREM ev, here collect pairwise correlations restricted to wake periods in POST for all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "sd_paper"
    ]
   },
   "outputs": [],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "\n",
    "pcorr_df = []\n",
    "for s, sess in enumerate(tqdm(sessions)):\n",
    "    pre_maze_epochs = sess.get_zt_epochs()[:2]\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "    neurons = sess.neurons_stable.get_neuron_type(\"pyr\")\n",
    "    wake = sess.brainstates.label_slice([\"AW\", \"QW\"]).set_labels(\"WK\").merge_neighbors()\n",
    "\n",
    "    pcorr_pre_maze, pre_maze_labels = ev_utils.get_pcorr(neurons, pre_maze_epochs)\n",
    "    pre_maze_df = pd.DataFrame(pcorr_pre_maze, columns=pre_maze_labels)\n",
    "\n",
    "    zt_starts = np.arange(post[0], post[0] + 7.5 * 3600, 300)\n",
    "    zt_stops = zt_starts + 900\n",
    "    zt_labels = np.arange(len(zt_starts)).astype(\"str\")\n",
    "    zt_epochs = sess.paradigm.from_array(zt_starts, zt_stops, zt_labels)\n",
    "\n",
    "    pcorr_zt, _ = ev_utils.get_pcorr(neurons, zt_epochs, sub_epochs=wake)\n",
    "    zt_df = pd.DataFrame(data=pcorr_zt, columns=zt_labels.astype(\"int\"))\n",
    "\n",
    "    df = pd.concat([pre_maze_df, zt_df], axis=1)\n",
    "    df[\"session\"] = s\n",
    "    df[\"grp\"] = sess.tag\n",
    "    pcorr_df.append(df)\n",
    "\n",
    "pcorr_df = pd.concat(pcorr_df, ignore_index=True)\n",
    "\n",
    "subjects.GroupData().save(pcorr_df, \"pairwise_correlations_aligned_by_WAKE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDF 6C: Correlation between amount of QW and AW vs EV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "\n",
    "wake_df = []\n",
    "for s, sess in enumerate(sessions):\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "    aw = sess.brainstates.label_slice([\"AW\"])\n",
    "    qw = sess.brainstates.label_slice([\"QW\"])\n",
    "\n",
    "    zt_epochs = sess.get_zt_epochs(include_pre=False, include_maze=False)\n",
    "\n",
    "    for e in zt_epochs.itertuples():\n",
    "        aw_duration = aw.time_slice(e.start, e.stop, strict=False).durations.sum()\n",
    "        qw_duration = qw.time_slice(e.start, e.stop, strict=False).durations.sum()\n",
    "        # e_df = pd.DataFrame({\"duration\": e_duration}, index=[0])\n",
    "        e_dur = e.stop - e.start\n",
    "        e_df = pd.DataFrame(\n",
    "            {\"aw_dur\": [aw_duration / e_dur], \"qw_dur\": [qw_duration / e_dur]}\n",
    "        )\n",
    "        e_df[\"zt\"] = e.label\n",
    "        e_df[\"session\"] = s\n",
    "        e_df[\"name\"] = sess.animal.name + sess.animal.day\n",
    "        e_df[\"grp\"] = sess.tag\n",
    "        wake_df.append(e_df)\n",
    "\n",
    "wake_df = pd.concat(wake_df, ignore_index=True)\n",
    "ev_df = subjects.GroupData().ev_in_chunks\n",
    "\n",
    "ev_df = pd.merge(ev_df, wake_df, on=[\"zt\", \"session\", \"name\", \"grp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = subjects.SdFig().fig_supp()\n",
    "\n",
    "for i, zt in enumerate([\"0-2.5\", \"2.5-5\", \"5-7.5\"]):\n",
    "    df = ev_df[(ev_df.grp == \"SD\") & (ev_df.zt == zt)]\n",
    "    ax = fig.subplot(fig.gs[0, i])\n",
    "\n",
    "    x = df[\"aw_dur\"].values\n",
    "    y = df[\"ev\"].values\n",
    "    linfit = stats.linregress(x, y)\n",
    "\n",
    "    ax.scatter(x, y, s=2, c=\"r\")\n",
    "    ax.plot(x, linfit.slope * x + linfit.intercept, color=\"gray\", lw=1, alpha=0.7)\n",
    "    ax.set_title(f\"r = {np.round(linfit.rvalue,2)}, p = {np.round(linfit.pvalue,3)}\")\n",
    "\n",
    "for i, zt in enumerate([\"0-2.5\", \"2.5-5\", \"5-7.5\"]):\n",
    "    df = ev_df[(ev_df.grp == \"SD\") & (ev_df.zt == zt)]\n",
    "    ax = fig.subplot(fig.gs[2, i])\n",
    "\n",
    "    x = df[\"qw_dur\"].values\n",
    "    y = df[\"ev\"].values\n",
    "    linfit = stats.linregress(x, y)\n",
    "\n",
    "    ax.scatter(x, y, s=2, c=\"r\")\n",
    "    ax.plot(x, linfit.slope * x + linfit.intercept, color=\"gray\", lw=1, alpha=0.7)\n",
    "    ax.set_title(f\"r = {np.round(linfit.rvalue,2)}, p = {np.round(linfit.pvalue,3)}\")\n",
    "\n",
    "fig.savefig(subjects.figpath_sd / \"qw_aw_EV_corr\", format=\"svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
