{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from neuropy import plotting\n",
    "from tqdm.notebook import tqdm\n",
    "from neuropy.core import Epoch\n",
    "from neuropy.utils.mathutil import min_max_scaler\n",
    "from neuropy import plotting\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import subjects"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooled dataframe across all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "\n",
    "replay_df = []\n",
    "for sub, sess in enumerate(sessions):\n",
    "    neurons = sess.neurons_stable.get_neuron_type([\"pyr\", \"mua\"])\n",
    "    neurons = neurons[neurons.firing_rate <= 10]\n",
    "\n",
    "    df = sess.replay_filtered.to_dataframe()\n",
    "    df.drop(\"posterior\", axis=1, inplace=True)\n",
    "    df.rename(columns=dict(label=\"zt\"), inplace=True)\n",
    "    df[\"name\"] = sess.name\n",
    "    df[\"grp\"] = sess.tag\n",
    "    wcorr_pre, wcorr_maze, radon_pre = [\n",
    "        (f := df.groupby(\"zt\")).get_group(\"PRE\").wcorr,\n",
    "        f.get_group(\"MAZE\").wcorr,\n",
    "        f.get_group(\"MAZE\").radon,\n",
    "        # pd.concat([f.get_group(\"PRE\"),f.get_group('MAZE')]).radon,\n",
    "    ]\n",
    "\n",
    "    df[\"wcorr_rel_pre\"] = df.wcorr / wcorr_pre.mean()\n",
    "    df[\"wcorr_zsc_pre\"] = (df.wcorr - wcorr_pre.median()) / (\n",
    "        wcorr_pre.quantile(0.75) - wcorr_pre.quantile(0.25)\n",
    "    )\n",
    "    df[\"wcorr_rel_maze\"] = df.wcorr / wcorr_maze.mean()\n",
    "\n",
    "    df[\"radon_zsc_pre\"] = (df.radon - radon_pre.median()) / (\n",
    "        radon_pre.quantile(0.75) - radon_pre.quantile(0.25)\n",
    "    )\n",
    "    df[\"radon_rel_pre\"] = df.radon / radon_pre.mean()\n",
    "    df[\"abs_wcorr\"] = np.abs(df[\"wcorr\"])\n",
    "\n",
    "    replay_df.append(df)\n",
    "\n",
    "\n",
    "replay_df = pd.concat(replay_df, ignore_index=True)\n",
    "\n",
    "# subjects.GroupData().save(replay_df, \"replay_mua\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significant replay events using wcorr and jump distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "grpby_kw = dict(by=[\"grp\", \"name\", \"zt\"], sort=False)\n",
    "bool_indx = (\n",
    "    (replay_df.wcorr_perc >= 90)\n",
    "    | (replay_df.wcorr_perc <= 10)\n",
    "    # (replay_df.wcorr >= 0.5)\n",
    ") & (replay_df.jd_perc <= 10)\n",
    "\n",
    "df_sig = replay_df[bool_indx].groupby(**grpby_kw).count()\n",
    "prop = df_sig / replay_df.groupby(**grpby_kw).count()\n",
    "prop = prop.reset_index().iloc[:, :7].rename(columns=dict(wcorr=\"prop\"))\n",
    "# prop = prop[prop.zt != \"MAZE\"]\n",
    "# sns.stripplot(data=df_sig.reset_index(), x=\"zt\", y=\"wcorr\", hue=\"grp\", dodge=True)\n",
    "sns.stripplot(data=prop, x=\"zt\", y=\"prop\", hue=\"grp\", dodge=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot measures in individual sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(7, 2)\n",
    "\n",
    "meas = \"radon\"\n",
    "for g, grp in enumerate([\"NSD\", \"SD\"]):\n",
    "    grp_df = replay_df[replay_df.grp == grp]\n",
    "    sessions = grp_df.session.unique()\n",
    "\n",
    "    for s, sess in enumerate(sessions):\n",
    "        sess_df = grp_df[grp_df.session == sess]\n",
    "        mean_pre = sess_df[sess_df.zt == \"PRE\"][meas].mean()\n",
    "\n",
    "        ax = axs[s, g]\n",
    "        sns.violinplot(data=sess_df, x=\"zt\", y=meas, color=subjects.colors_sd()[g], ax=ax)\n",
    "        ax.axhline(mean_pre)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot measures pooled across all sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters import violinplot\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "\n",
    "# bool_indx = (\n",
    "#     (replay_df.wcorr_perc_shuffle >= 95) | (replay_df.wcorr_perc_shuffle <=5)\n",
    "# ) & (replay_df.jd_perc_shuffle <= 10)\n",
    "# df = replay_df[bool_indx]\n",
    "\n",
    "violinplot(data=replay_df, x=\"zt\", y=\"radon_rel_pre\", stat_anot=True, stat_test=\"Kruskal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statannotations.Annotator import Annotator\n",
    "from subjects import stat_kw\n",
    "from plotters import violinplot\n",
    "\n",
    "fig = plotting.Fig(grid=(6, 4), fontsize=7)\n",
    "\n",
    "# sns.violinplot(data=wcorr_df,x='zt',y='score',hue='grp',split=True)\n",
    "# df = radon_df[~radon_df.name.isin(['RatUDay2'])]\n",
    "# df = radon_df[radon_df.n_neurons>=80]\n",
    "# df = radon_df[radon_df.speed>=00]\n",
    "\n",
    "ax = fig.subplot(fig.gs[0])\n",
    "plot_kw = dict(\n",
    "    data=replay_df, x=\"zt\", y=\"radon_zsc_pre\", hue=\"grp\", hue_order=[\"NSD\", \"SD\"], ax=ax\n",
    ")\n",
    "violinplot(**plot_kw)\n",
    "orders = replay_df.zt.unique()\n",
    "\n",
    "# Within groups\n",
    "for i, g in enumerate([\"NSD\", \"SD\"]):\n",
    "    pairs2 = [((\"0-2.5\", g), (\"5-7.5\", g)), ((\"2.5-5\", g), (\"5-7.5\", g))]\n",
    "    annotator = Annotator(pairs=pairs2, **plot_kw, order=orders)\n",
    "    annotator.configure(test=\"Kruskal\", **stat_kw, color=subjects.colors_sd(1)[i])\n",
    "    annotator.apply_and_annotate()\n",
    "    # annotator.apply_test().annotate(line_offset_to_group=k)\n",
    "    annotator.reset_configuration()\n",
    "\n",
    "\n",
    "fig.savefig(subjects.figpath_sd / \"radon_dist_stat\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cummulative distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters import violinplot\n",
    "\n",
    "# --- violinplot -----\n",
    "# a = replay_df[replay_df.pval < 0.05]\n",
    "# sig_counts = a.groupby([\"grp\", \"session\", \"zt\"]).count()\n",
    "# all_counts = replay_df.groupby([\"grp\", \"session\", \"zt\"]).count()\n",
    "\n",
    "# sig_df = (sig_counts / all_counts).reset_index()\n",
    "\n",
    "# _, ax = plt.subplots()\n",
    "\n",
    "# df1 = replay_df[replay_df.perc > 95 ].groupby([\"zt\", \"grp\", \"session\"]).count()\n",
    "# df2 = replay_df.groupby([\"zt\", \"grp\", \"session\"]).count()\n",
    "# df = (df1 / df2).reset_index()\n",
    "# violinplot(data=replay_df, x=\"zt\", y=\"perc\", stat_anot=True, stat_test=\"Kruskal\")\n",
    "\n",
    "\n",
    "# --- CDF plotting each epoch separately -----\n",
    "_, axs = plt.subplots(1, 5, sharey=True)\n",
    "\n",
    "zts = replay_df.zt.unique()\n",
    "\n",
    "plot_kw = dict(\n",
    "    x=\"perc\",\n",
    "    hue=\"grp\",\n",
    "    stat=\"probability\",\n",
    "    common_bins=True,\n",
    "    binwidth=5,\n",
    "    common_norm=False,\n",
    "    cumulative=True,\n",
    "    fill=False,\n",
    "    element=\"poly\",\n",
    ")\n",
    "\n",
    "ax = axs[0]\n",
    "sns.histplot(\n",
    "    data=replay_df[replay_df.zt == \"PRE\"],\n",
    "    **plot_kw,\n",
    "    ax=ax,\n",
    "    palette=subjects.colors_sd(1),\n",
    ")\n",
    "ax.legend(\"\", frameon=False)\n",
    "val1 = replay_df[(replay_df.grp == \"SD\") & (replay_df.zt == \"PRE\")].perc.values\n",
    "val2 = replay_df[(replay_df.grp == \"NSD\") & (replay_df.zt == \"PRE\")].perc.values\n",
    "htest = stats.ks_2samp(val1, val2)\n",
    "# p = np.format_float_scientific(htest.pvalue,precision=2)\n",
    "p = htest.pvalue\n",
    "sig_text = \"n.s\" if p > 0.05 else \"*\"\n",
    "ax.text(25, 0.6, sig_text, color=\"g\")\n",
    "ax.set_title(\"PRE\")\n",
    "\n",
    "\n",
    "for i, zt in enumerate(zts[1:]):\n",
    "    ax = axs[i + 1]\n",
    "    yvals = [0.8, 0.7]\n",
    "    for i1, g in enumerate([\"NSD\", \"SD\"]):\n",
    "        val1 = replay_df[(replay_df.grp == g) & (replay_df.zt == \"PRE\")].perc.values\n",
    "        val2 = replay_df[(replay_df.grp == g) & (replay_df.zt == zt)].perc.values\n",
    "        htest = stats.ks_2samp(val1, val2, alternative=\"greater\")\n",
    "        # p = np.format_float_scientific(htest.pvalue,precision=2)\n",
    "        p = htest.pvalue\n",
    "        sig_text = \"n.s\" if p > 0.05 else \"*\"\n",
    "        ax.text(25, yvals[i1], sig_text, color=subjects.colors_sd()[i1])\n",
    "\n",
    "    sns.histplot(\n",
    "        data=replay_df[replay_df.zt == \"PRE\"],\n",
    "        **plot_kw,\n",
    "        ax=ax,\n",
    "        palette=subjects.colors_sd(1),\n",
    "        ls=\"--\",\n",
    "    )\n",
    "    sns.histplot(\n",
    "        data=replay_df[replay_df.zt == zt],\n",
    "        **plot_kw,\n",
    "        ax=ax,\n",
    "        palette=subjects.colors_sd(1),\n",
    "    )\n",
    "    val1 = replay_df[(replay_df.grp == \"SD\") & (replay_df.zt == zt)].perc.values\n",
    "    val2 = replay_df[(replay_df.grp == \"NSD\") & (replay_df.zt == zt)].perc.values\n",
    "    htest = stats.ks_2samp(val1, val2, alternative=\"greater\")\n",
    "    # p = np.format_float_scientific(htest.pvalue,precision=2)\n",
    "    p = htest.pvalue\n",
    "    sig_text = \"n.s\" if p > 0.05 else \"*\"\n",
    "    ax.text(25, 0.6, sig_text, color=\"g\")\n",
    "\n",
    "    ax.legend(\"\", frameon=False)\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_title(zt)\n",
    "    # ax.set_yscale('log')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jump distance vs Wcorr histogram (Silva2015 style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "# sessions = subjects.nsd.pf_sess + subjects.sd.pf_sess\n",
    "\n",
    "grp_all, name_all, zt_all, wcorr_all, jd_all = [], [], [], [], []\n",
    "for sub, sess in enumerate(sessions):\n",
    "    neurons = sess.neurons_stable.get_neuron_type([\"pyr\", \"mua\"])\n",
    "    neurons = neurons[neurons.firing_rate <= 10]\n",
    "\n",
    "    replay_pbe = sess.replay_pbe_mua_column_max\n",
    "    metadata = replay_pbe.metadata\n",
    "    up_shuffle_measures = metadata[\"up_shuffle_measures\"]\n",
    "    down_shuffle_measures = metadata[\"down_shuffle_measures\"]\n",
    "    # shuffle_measures = np.vstack([up_shuffle_measures, down_shuffle_measures])\n",
    "\n",
    "    # ---- Filtering by good PBEs ---------\n",
    "    pbe_filter = sess.pbe_filters.to_dataframe()\n",
    "    good_bool = pbe_filter.is_rpl & pbe_filter.is_5units & pbe_filter.is_rest\n",
    "    good_bool = good_bool.values\n",
    "    replay_pbe = replay_pbe[good_bool]\n",
    "    # shuffle_measures = shuffle_measures[:, :, good_bool]\n",
    "    up_shuffle_measures = up_shuffle_measures[:, :, good_bool]\n",
    "    down_shuffle_measures = down_shuffle_measures[:, :, good_bool]\n",
    "\n",
    "    replay_pbe_df = replay_pbe.to_dataframe()\n",
    "    starts = replay_pbe.starts\n",
    "\n",
    "    replay_pbe_df.loc[:, \"down_wcorr\"] *= -1\n",
    "    measure_names = [\"wcorr\", \"jd\"]\n",
    "    up_measures = replay_pbe_df.loc[:, [\"up_\" + _ for _ in measure_names]].to_numpy()\n",
    "    down_measures = replay_pbe_df.loc[:, [\"down_\" + _ for _ in measure_names]].to_numpy()\n",
    "\n",
    "    best_bool = np.abs(up_measures[:, 0]) > np.abs(down_measures[:, 0])\n",
    "    measures = np.zeros_like(up_measures)\n",
    "    measures[best_bool] = up_measures[best_bool]\n",
    "    measures[~best_bool] = down_measures[~best_bool]\n",
    "\n",
    "    shuffle_measures = np.zeros_like(up_shuffle_measures)\n",
    "    shuffle_measures[:, :, best_bool] = up_shuffle_measures[:, :, best_bool]\n",
    "    shuffle_measures[:, :, ~best_bool] = down_shuffle_measures[:, :, ~best_bool]\n",
    "\n",
    "    epochs = sess.get_zt_epochs()\n",
    "    starts_bool, _, starts_labels = epochs.contains(starts)\n",
    "    measures = measures[starts_bool]\n",
    "    shuffle_measures = shuffle_measures[:, :, starts_bool]\n",
    "\n",
    "    wcorr = measures[:, 0][np.newaxis, :]\n",
    "    jd = measures[:, 1][np.newaxis, :]\n",
    "\n",
    "    n_pbes = measures.shape[0]\n",
    "    grp_all.append([sess.tag] * n_pbes)\n",
    "    name_all.append([sess.name] * n_pbes)\n",
    "    zt_all.append(starts_labels)\n",
    "    wcorr_all.append(np.abs(np.vstack((wcorr, shuffle_measures[:, 0, :]))))\n",
    "    jd_all.append(np.vstack((jd, shuffle_measures[:, 1, :])))\n",
    "\n",
    "\n",
    "grp_all = np.concatenate(grp_all)\n",
    "name_all = np.concatenate(name_all)\n",
    "zt_all = np.concatenate(zt_all)\n",
    "wcorr_all = np.hstack(wcorr_all)\n",
    "jd_all = np.hstack(jd_all)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "cmap = mcolors.ListedColormap([\"red\", \"blue\"])\n",
    "\n",
    "divnorm = mcolors.TwoSlopeNorm(vmin=0.001, vcenter=0.05, vmax=1)\n",
    "bounds = [0.001, 0.05, 1]\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "# _,axs = plt.subplots(7,10,sharex=True,sharey=True)\n",
    "fig = plotting.Fig(grid=(7, 2))\n",
    "\n",
    "zts = [\"PRE\", \"MAZE\", \"0-2.5\", \"2.5-5\", \"5-7.5\"]\n",
    "\n",
    "bins = np.arange(0, 1.1, 0.1)\n",
    "n_bins = len(bins) - 1\n",
    "\n",
    "\n",
    "def get_chist(x, y):\n",
    "    bins = np.arange(0, 1.1, 0.1)\n",
    "    n_bins = len(bins) - 1\n",
    "    hist_zt = np.histogram2d(x, y, bins=[bins, bins])[0]\n",
    "    cumsum_hist = np.zeros_like(hist_zt)\n",
    "    for row in range(n_bins):\n",
    "        for col in range(n_bins):\n",
    "            cumsum_hist[row, col] = hist_zt[-(row + 1) :, : col + 1].sum()\n",
    "\n",
    "    return cumsum_hist\n",
    "\n",
    "\n",
    "k = 0\n",
    "for g, grp in enumerate([\"NSD\", \"SD\"]):\n",
    "    names = np.unique(name_all[grp_all == grp])\n",
    "    for name in names:\n",
    "        subfig = fig.add_subfigure(fig.gs[k])\n",
    "        axs = subfig.subplots(1, 5, sharex=True, sharey=True)\n",
    "\n",
    "        for i, zt in enumerate(zts):\n",
    "            indx = (grp_all == grp) & (zt_all == zt) & (name_all == name)\n",
    "            jd = jd_all[0, indx]\n",
    "            wcorr = wcorr_all[0, indx]\n",
    "            real_dist = get_chist(wcorr, jd)\n",
    "\n",
    "            sh_jd = jd_all[1:, indx]\n",
    "            sh_wcorr = wcorr_all[1:, indx]\n",
    "            pval = np.zeros_like(real_dist)\n",
    "\n",
    "            for sh_i in range(sh_wcorr.shape[0]):\n",
    "                jd_ = sh_jd[sh_i]\n",
    "                wcorr_ = sh_wcorr[sh_i]\n",
    "                sh_dist = get_chist(wcorr_, jd_)\n",
    "\n",
    "                pval += (sh_dist >= real_dist).astype(\"float\")\n",
    "\n",
    "            pval = pval / sh_wcorr.shape[0]\n",
    "\n",
    "            ax = axs[i]\n",
    "            im = ax.pcolormesh(bins, bins, np.flipud(pval), cmap=cmap, norm=norm)\n",
    "            cb = plt.colorbar(im, ax=ax)\n",
    "\n",
    "        k += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# divnorm = mcolors.TwoSlopeNorm(vmin=0.001, vcenter=0.01, vmax=1)\n",
    "\n",
    "cmap = mcolors.ListedColormap([\"red\", \"pink\", \"blue\"])\n",
    "bounds = [0.001, 0.01, 0.05, 1]\n",
    "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "fig = plotting.Fig(grid=(9, 6), fontsize=7)\n",
    "subfig = fig.add_subfigure(fig.gs[:2, :4])\n",
    "axs = subfig.subplots(2, 5, sharex=True, sharey=True)\n",
    "\n",
    "zts = [\"PRE\", \"MAZE\", \"0-2.5\", \"2.5-5\", \"5-7.5\"]\n",
    "\n",
    "bins = np.arange(0, 1.1, 0.1)\n",
    "n_bins = len(bins) - 1\n",
    "\n",
    "\n",
    "def get_chist(x, y):\n",
    "    bins = np.arange(0, 1.1, 0.1)\n",
    "    n_bins = len(bins) - 1\n",
    "    hist_zt = np.histogram2d(x, y, bins=[bins, bins])[0]\n",
    "    cumsum_hist = np.zeros_like(hist_zt)\n",
    "    for row in range(n_bins):\n",
    "        for col in range(n_bins):\n",
    "            cumsum_hist[row, col] = hist_zt[-(row + 1) :, : col + 1].sum()\n",
    "\n",
    "    return cumsum_hist\n",
    "\n",
    "\n",
    "for i, zt in enumerate(zts):\n",
    "    for g, grp in enumerate([\"NSD\", \"SD\"]):\n",
    "        indx = (grp_all == grp) & (zt_all == zt)\n",
    "        jd = jd_all[0, indx]\n",
    "        wcorr = wcorr_all[0, indx]\n",
    "\n",
    "        real_dist = get_chist(wcorr, jd)\n",
    "        # real_dist = np.histogram2d(wcorr,jd,bins=[bins,bins])[0]\n",
    "        # real_dist = real_dist/real_dist.sum()\n",
    "\n",
    "        sh_jd = jd_all[1:, indx]\n",
    "        sh_wcorr = wcorr_all[1:, indx]\n",
    "\n",
    "        pval = np.zeros_like(real_dist)\n",
    "        for sh_i in range(sh_wcorr.shape[0]):\n",
    "            jd_ = sh_jd[sh_i]\n",
    "            wcorr_ = sh_wcorr[sh_i]\n",
    "\n",
    "            sh_dist = get_chist(wcorr_, jd_)\n",
    "\n",
    "            pval += (sh_dist >= real_dist).astype(\"float\")\n",
    "\n",
    "        pval = (pval + 1) / (sh_wcorr.shape[0] + 1)\n",
    "\n",
    "        ax = axs[g, i]\n",
    "        im = ax.pcolormesh(\n",
    "            bins, bins, np.flipud(pval), cmap=cmap, norm=norm, rasterized=True\n",
    "        )\n",
    "        # im = ax.pcolormesh(bins,bins,real_dist,cmap='jet',vmin=0,vmax=0.1)\n",
    "        if grp == \"NSD\":\n",
    "            ax.set_title(zt)\n",
    "\n",
    "ax.set_xlabel(\"Mean jump distance\")\n",
    "yticks = [0, 0.3, 0.6, 0.9]\n",
    "ax.set_yticks(yticks, [f\">{_}\" for _ in yticks[::-1]])\n",
    "xticks = [0.2, 0.5, 0.8]\n",
    "ax.set_xticks(xticks, [f\"<{_}\" for _ in xticks])\n",
    "\n",
    "cax = fig.subplot(fig.gs[4])\n",
    "cax.set_axis_off()\n",
    "cb = plt.colorbar(im, ax=cax)\n",
    "\n",
    "fig.savefig(subjects.figpath_sd / \"max_jump_distance\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compared neuron_id vs column_cycle shuffles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.sd.ratRday2\n",
    "\n",
    "replay_df = []\n",
    "for sub, sess in enumerate(sessions):\n",
    "    neurons = sess.neurons_stable.get_neuron_type([\"pyr\", \"mua\"])\n",
    "    neurons = neurons[neurons.firing_rate <= 10]\n",
    "\n",
    "    replay_pbe = sess.replay_pbe_mua\n",
    "    starts = replay_pbe.starts\n",
    "    replay_pbe_df = replay_pbe.to_dataframe()\n",
    "    up_wcorr = replay_pbe_df[\"up_wcorr\"].values\n",
    "    down_wcorr = replay_pbe_df[\"down_wcorr\"].values\n",
    "    id_metadata = replay_pbe.metadata\n",
    "    id_shuffle_measures = np.vstack(\n",
    "        [id_metadata[\"up_shuffle_measures\"], id_metadata[\"down_shuffle_measures\"]]\n",
    "    )\n",
    "\n",
    "    replay_column = sess.replay_pbe_mua_column\n",
    "    column_metadata = replay_column.metadata\n",
    "    column_shuffle_measures = np.vstack(\n",
    "        [\n",
    "            column_metadata[\"up_shuffle_measures\"],\n",
    "            column_metadata[\"down_shuffle_measures\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    best_bool = np.abs(up_wcorr) > np.abs(down_wcorr)\n",
    "    wcorr = np.zeros_like(up_wcorr)\n",
    "    wcorr[best_bool] = up_wcorr[best_bool]\n",
    "    wcorr[~best_bool] = down_wcorr[~best_bool]\n",
    "\n",
    "    id_perc_shuffle = np.array(\n",
    "        [\n",
    "            stats.percentileofscore(id_shuffle_measures[:, 0, i], wcorr[i], kind=\"strict\")\n",
    "            for i in range(len(wcorr))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    column_perc_shuffle = np.array(\n",
    "        [\n",
    "            stats.percentileofscore(\n",
    "                column_shuffle_measures[:, 0, i], wcorr[i], kind=\"strict\"\n",
    "            )\n",
    "            for i in range(len(wcorr))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    epochs = sess.get_zt_epochs()\n",
    "    starts_bool, _, starts_labels = epochs.contains(starts)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        dict(\n",
    "            zt=starts_labels,\n",
    "            id_perc=id_perc_shuffle[starts_bool],\n",
    "            col_perc=column_perc_shuffle[starts_bool],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(1, 2)\n",
    "\n",
    "sns.violinplot(data=df, x=\"zt\", y=\"id_perc\", ax=axs[0])\n",
    "sns.violinplot(data=df, x=\"zt\", y=\"col_perc\", ax=axs[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpness of posterior comparison between NSD and SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = subjects.nsd.ratJday2[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example figures for sd_paper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chosen by percentile\n",
    "- All possible measures are pooled across sessions and best replays within epoch are displayed\n",
    "- Possible criterias: replays at 95th percentile of radon score or wcorr, at 5th percentile of jump distance and that has traversed maximum distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "\n",
    "replay_df = []\n",
    "for sub, sess in enumerate(sessions):\n",
    "    df = sess.replay_filtered.to_dataframe()\n",
    "    df.rename({\"label\": \"zt\"}, inplace=True, axis=1)\n",
    "    df[\"grp\"] = sess.tag\n",
    "    replay_df.append(df)\n",
    "\n",
    "replay_df = pd.concat(replay_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay_funcs import get_distance\n",
    "\n",
    "_, axs = plt.subplots(2, 10)\n",
    "\n",
    "zts = replay_df.zt.unique()\n",
    "\n",
    "examples_df = []\n",
    "for g, grp in enumerate([\"NSD\", \"SD\"]):\n",
    "    for i, zt in enumerate(zts):\n",
    "        df = replay_df[(replay_df.zt == zt) & (replay_df.grp == grp)].reset_index(\n",
    "            drop=True\n",
    "        )\n",
    "        scores = df.jd.values\n",
    "        # velocity = df.velocity.values\n",
    "        percentile = np.array(\n",
    "            [stats.percentileofscore(scores, _, kind=\"strict\") for _ in scores]\n",
    "        )\n",
    "        indx = percentile < 10\n",
    "        posteriors = df[indx][\"posterior\"].to_list()\n",
    "        dx = 1 / posteriors[0].shape[0]\n",
    "        distance = np.array([np.abs(get_distance(_)) for _ in posteriors]) * dx\n",
    "        sort_ind = np.argsort(distance)[::-1]\n",
    "\n",
    "        chosen_posteriors = [\n",
    "            posteriors[sort_ind[0]],\n",
    "            posteriors[sort_ind[1]],\n",
    "            # posteriors[distance.argmax()],\n",
    "            # posteriors[distance.argmin()],\n",
    "        ]\n",
    "\n",
    "        cmap = \"binary\" if grp == \"NSD\" else \"Reds\"\n",
    "\n",
    "        for i1, p in enumerate(chosen_posteriors):\n",
    "            p_enh = np.apply_along_axis(\n",
    "                np.convolve, axis=0, arr=p, v=np.ones(2 * 4 + 1), mode=\"same\"\n",
    "            )\n",
    "\n",
    "            ax = axs[g, 2 * i + i1]\n",
    "            ax.pcolormesh(p_enh, cmap=cmap)\n",
    "\n",
    "            df = pd.DataFrame(\n",
    "                dict(\n",
    "                    zt=zt,\n",
    "                    jd=[np.abs(np.diff(np.argmax(p, axis=0))).mean()],\n",
    "                    posterior=[p],\n",
    "                    grp=grp,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            examples_df.append(df)\n",
    "\n",
    "examples_df = pd.concat(examples_df, ignore_index=True)\n",
    "\n",
    "# subjects.GroupData().save(examples_df, \"replay_examples\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proportion of continuous trajectory vs Explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpdata = subjects.GroupData()\n",
    "cont_events = grpdata.replay_continuous_events\n",
    "cont_events = cont_events[~cont_events.zt.isin([\"PRE\", \"MAZE\"])].reset_index(drop=True)\n",
    "ev_pooled = grpdata.ev_in_chunks\n",
    "\n",
    "data = cont_events.merge(\n",
    "    ev_pooled, how=\"left\", left_on=[\"name\", \"zt\"], right_on=[\"name\", \"zt\"]\n",
    ")\n",
    "\n",
    "fig = plotting.Fig(grid=(7, 5))\n",
    "\n",
    "for g, grp in enumerate([\"NSD\", \"SD\"]):\n",
    "    for i, zt in enumerate([\"0-2.5\", \"2.5-5\", \"5-7.5\"]):\n",
    "        ax = fig.subplot(fig.gs[g, i])\n",
    "\n",
    "        e_dt = data[(data.zt == zt) & (data.grp_x == grp)].reset_index(drop=True)\n",
    "        x = e_dt.ev_diff.values\n",
    "        y = e_dt.prop.values\n",
    "        linfit = stats.linregress(x, y)\n",
    "        corr = linfit.rvalue\n",
    "        pval = linfit.pvalue\n",
    "\n",
    "        # ax.scatter(x,y,c=subjects.colors_sd(1)[g])\n",
    "        sns.regplot(\n",
    "            data=e_dt,\n",
    "            x=\"ev_diff\",\n",
    "            y=\"prop\",\n",
    "            ax=ax,\n",
    "            color=subjects.colors_sd(1)[g],\n",
    "            ci=None,\n",
    "        )\n",
    "        ax.set_title(f\"r={corr.round(2)}, p={pval.round(2)}\")\n",
    "        # ax.axline((0,0),slope=linfit.slope)\n",
    "\n",
    "\n",
    "fig.savefig(subjects.figpath_sd / \"prop_ev_scatter\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('data_analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cce1618081139d19eb1ee8d40815d94a2de4f62e1efb20d9406ddb60628c36ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
