{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import scipy.signal as sg\n",
    "import matplotlib.pyplot as plt\n",
    "from neuropy import plotting\n",
    "import subjects\n",
    "\n",
    "\n",
    "def get_jump_dist(arr):\n",
    "    # arr = np.apply_along_axis(\n",
    "    #         np.convolve, axis=0, arr=arr, v=np.ones(2 * 4 + 1), mode=\"same\"\n",
    "    #     )\n",
    "    mean_jd = np.mean(np.abs(np.diff(np.argmax(arr, axis=0))))\n",
    "    std_jd = np.std(np.abs(np.diff(np.argmax(arr, axis=0))))\n",
    "    return mean_jd, std_jd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jump distance distribution SD vs NSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "\n",
    "jump_df = []\n",
    "for sub, sess in enumerate(sessions):\n",
    "    neurons = sess.neurons_stable.get_neuron_type([\"pyr\", \"mua\"])\n",
    "    neurons = neurons[neurons.firing_rate <= 10]\n",
    "\n",
    "    replay_pbe = sess.replay_radon_mua\n",
    "    replay_pbe_df = replay_pbe.to_dataframe()\n",
    "    metadata = replay_pbe.metadata\n",
    "    starts = replay_pbe.starts\n",
    "\n",
    "    pbe_filter = sess.pbe_filters.to_dataframe()\n",
    "    # good_bool = pbe_filter.is_rpl & pbe_filter.is_5units & pbe_filter.is_rest\n",
    "\n",
    "    up_posteriors = metadata[\"up_posterior\"]\n",
    "    down_posteriors = metadata[\"down_posterior\"]\n",
    "\n",
    "    up_score = replay_pbe_df[\"up_score\"].values\n",
    "    down_score = replay_pbe_df[\"down_score\"].values\n",
    "\n",
    "    wcorr = np.maximum(np.abs(up_score), np.abs(down_score))\n",
    "\n",
    "    posteriors = [up_posteriors, down_posteriors]\n",
    "    posteriors = [\n",
    "        posteriors[np.argmax([up_score[i], down_score[i]])][i]\n",
    "        for i in range(len(up_score))\n",
    "    ]\n",
    "\n",
    "    dx = 1 / posteriors[0].shape[0]\n",
    "    # dx=2\n",
    "    jump_dist = np.array([get_jump_dist(_)[0] for _ in posteriors]) * dx\n",
    "    # jump_dist = jump_dist[good_bool]\n",
    "    # starts = starts[good_bool]\n",
    "\n",
    "    epochs = sess.get_zt_epochs()\n",
    "    starts_bool, _, starts_labels = epochs.contains(starts)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        dict(\n",
    "            zt=starts_labels,\n",
    "            score=jump_dist[starts_bool],\n",
    "            n_neurons=neurons.n_neurons,\n",
    "            method=\"jump\",\n",
    "            session=sub,\n",
    "            name=sess.animal.name + sess.animal.day,\n",
    "            grp=sess.tag,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    score_pre, score_maze = [\n",
    "        (f := df.groupby(\"zt\")).get_group(\"PRE\").score.values,\n",
    "        f.get_group(\"MAZE\").score.values,\n",
    "    ]\n",
    "\n",
    "    perc_rel_pre = [\n",
    "        stats.percentileofscore(score_pre, _, kind=\"strict\") for _ in df.score\n",
    "    ]\n",
    "\n",
    "    df[\"score_rel_pre\"] = df.score / score_pre.mean()\n",
    "    df[\"score_rel_maze\"] = df.score / score_maze.mean()\n",
    "    df[\"perc_rel_pre\"] = perc_rel_pre\n",
    "\n",
    "    jump_df.append(df)\n",
    "\n",
    "jump_df = pd.concat(jump_df, ignore_index=True)\n",
    "subjects.GroupData().save(jump_df, \"replay_jumpdist_mua\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotters import violinplot\n",
    "\n",
    "_, ax = plt.subplots(1, 1)\n",
    "violinplot(data=jump_df, x=\"zt\", y=\"score\", stat_anot=True)\n",
    "# sns.stripplot(data=df,x='zt',y='jump',hue='grp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(4, 5, sharex=\"row\", sharey=\"row\")\n",
    "\n",
    "nbins = 20\n",
    "xbins = np.linspace(0, 300, nbins)\n",
    "ybins = np.linspace(0, 1, nbins)\n",
    "\n",
    "rw_df = jump_df\n",
    "zts = rw_df.zt.unique()\n",
    "\n",
    "for i, zt in enumerate(zts[:1]):\n",
    "    df = rw_df[(rw_df.zt == zt)]\n",
    "\n",
    "    # ax=axs[0,i]\n",
    "    # sns.histplot(data=df,x='radon',y='wcorr',hue='grp',ax=ax)\n",
    "\n",
    "    hist_pre = []\n",
    "    for g, grp in enumerate([\"NSD\", \"SD\"]):\n",
    "        x = df[df.grp == grp].jump.values\n",
    "        y = df[df.grp == grp].wcorr.values\n",
    "\n",
    "        score_hist = np.histogram2d(x, y, bins=[xbins, ybins])[0]\n",
    "        hist_pre.append(score_hist / np.sum(score_hist))\n",
    "\n",
    "\n",
    "for i, zt in enumerate(zts):\n",
    "    df = rw_df[(rw_df.zt == zt)]\n",
    "\n",
    "    # ax=axs[0,i]\n",
    "    # sns.histplot(data=df,x='radon',y='wcorr',hue='grp',ax=ax)\n",
    "\n",
    "    hist_all = []\n",
    "    for g, grp in enumerate([\"NSD\", \"SD\"]):\n",
    "        x = df[df.grp == grp].jump.values\n",
    "        y = df[df.grp == grp].wcorr.values\n",
    "\n",
    "        score_hist = np.histogram2d(x, y, bins=[xbins, ybins])[0]\n",
    "        norm_hist = score_hist / np.sum(score_hist)\n",
    "        hist_all.append(norm_hist)\n",
    "\n",
    "        ax = axs[g, i]\n",
    "        # hist_diff = hist_all[0]-hist_all[1]\n",
    "        ax.pcolormesh(xbins, ybins, norm_hist, cmap=\"jet\", vmin=-0.01, vmax=0.01)\n",
    "\n",
    "        ax = axs[3, i]\n",
    "        sns.regplot(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            color=subjects.colors_sd()[g],\n",
    "            ax=ax,\n",
    "            scatter=False,\n",
    "            scatter_kws=dict(s=2),\n",
    "        )\n",
    "\n",
    "    axs[2, i].pcolormesh(\n",
    "        xbins, ybins, hist_all[0] - hist_all[1], cmap=\"jet\", vmin=-0.002, vmax=0.002\n",
    "    )\n",
    "\n",
    "    # ax=axs[3,i]\n",
    "    # ax.scatter(x,y,s=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jump distance (speed) power law\n",
    "- are jump distances more brownian for sleep deprivation vs regular sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "\n",
    "\n",
    "def get_motion(arr):\n",
    "    y = np.argmax(arr, axis=0) * 2\n",
    "    t = np.arange(arr.shape[1]) * 0.02\n",
    "    dt = np.abs(t[np.newaxis, :] - t[:, np.newaxis])\n",
    "    dy = np.abs(y[np.newaxis, :] - y[:, np.newaxis])\n",
    "\n",
    "    indx = np.tril_indices(dy.shape[0], k=-1)\n",
    "\n",
    "    return dy[indx], dt[indx]\n",
    "\n",
    "\n",
    "speed_df = []\n",
    "for sub, sess in enumerate(sessions):\n",
    "    starts = sess.replay_pbe.starts\n",
    "    replay_pbe = sess.replay_wcorr_mua.to_dataframe()\n",
    "\n",
    "    pbe_filter = sess.pbe_filters.to_dataframe()\n",
    "\n",
    "    good_bool = (\n",
    "        pbe_filter.is_rpl\n",
    "        & pbe_filter.is_5neurons\n",
    "        # & pbe_filter.is_lowtheta\n",
    "        & pbe_filter.is_rest\n",
    "    )\n",
    "\n",
    "    metadata = sess.replay_wcorr_mua.metadata\n",
    "    up_posteriors = metadata[\"up_posterior\"]\n",
    "    down_posteriors = metadata[\"down_posterior\"]\n",
    "\n",
    "    up_wcorr = replay_pbe[\"up_score\"].values\n",
    "    down_wcorr = -replay_pbe[\"down_score\"].values\n",
    "\n",
    "    posteriors = [up_posteriors, down_posteriors]\n",
    "    posteriors = [\n",
    "        posteriors[np.argmax([np.abs(up_wcorr[i]), np.abs(down_wcorr[i])])][i]\n",
    "        for i in range(len(up_wcorr))\n",
    "    ]\n",
    "\n",
    "    motion_metric = motion_metric.T\n",
    "\n",
    "    epochs = sess.get_zt_epochs()\n",
    "\n",
    "    for i, e in enumerate(epochs.itertuples()):\n",
    "        indx = (starts > e.start) & (starts < e.stop) & good_bool\n",
    "        motion_metric = np.hstack(\n",
    "            [np.vstack(get_motion(_)) for i, _ in enumerate(posteriors) if indx[i]]\n",
    "        ).T\n",
    "        df = pd.DataFrame(\n",
    "            dict(\n",
    "                zt=e.label,\n",
    "                ddist=motion_metric[:, 0],\n",
    "                dt=motion_metric[:, 1],\n",
    "                session=sub,\n",
    "                grp=sess.tag,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        speed_df.append(df)\n",
    "\n",
    "\n",
    "speed_df = pd.concat(speed_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(1, 5, sharey=True)\n",
    "\n",
    "zts = speed_df.zt.unique()\n",
    "\n",
    "for i, zt in enumerate(zts):\n",
    "    df = speed_df[speed_df.zt == zt]\n",
    "    ax = axs[i]\n",
    "    sns.lineplot(\n",
    "        data=df,\n",
    "        x=\"dt\",\n",
    "        y=\"ddist\",\n",
    "        hue=\"grp\",\n",
    "        ax=ax,\n",
    "        palette=subjects.colors_sd(),\n",
    "        err_style=\"bars\",\n",
    "    )\n",
    "\n",
    "    slopes = []\n",
    "    for g, grp in enumerate([\"NSD\", \"SD\"]):\n",
    "        grp_df = df[df.grp == grp]\n",
    "        t = grp_df.dt.values\n",
    "        dy = grp_df.ddist.values\n",
    "\n",
    "        bins = np.arange(0.001, 0.07, 0.02)\n",
    "        mean_dist = stats.binned_statistic(t, dy, bins=bins)[0]\n",
    "        bin_centers = bins[:-1] + 0.01\n",
    "\n",
    "        linfit = stats.linregress(np.log10(bin_centers), np.log10(mean_dist))\n",
    "        slopes.append(linfit.slope)\n",
    "\n",
    "    ax.text(0.03, 150, f\"{slopes[0].round(2),slopes[1].round(2)}\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.legend(\"\", frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0.001, 0.07, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "ax.plot(bin_centers, mean_dist, \".\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('data_analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cce1618081139d19eb1ee8d40815d94a2de4f62e1efb20d9406ddb60628c36ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
