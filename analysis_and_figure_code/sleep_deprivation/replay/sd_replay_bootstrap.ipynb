{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.extend(['/home/nkinsky/Documents/GitHub/NeuroPy'])\n",
    "sys.path.extend(['/home/nkinsky/Documents/GitHubPrivate/pythonprogs/DataPaths/'])\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import scipy.signal as sg\n",
    "import matplotlib.pyplot as plt\n",
    "from neuropy import plotting\n",
    "from plotters import Plotter\n",
    "import stats_utils\n",
    "import subjects\n",
    "from copy import deepcopy\n",
    "\n",
    "from neuropy.core.epoch import Epoch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap continuous trajectory replay proportion/number\n",
    "- For sd_paper fig4, where we compare proportion of significant continuous trajectory events, that can be substituted by bootstrap distribution.\n",
    "- One way of doing that will be randomly sampling events with replacement and calculate how many of the selected events are significant trajectory events. While initially seems like a reasonable measure, it may backfire for sessions which have low proportion of significant events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Sessions = 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n",
      "/home/nkinsky/Documents/GitHub/NeuroPy/neuropy/core/epoch.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  epochs.loc[:, \"label\"] = epochs[\"label\"].astype(\"str\")\n"
     ]
    }
   ],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "\n",
    "# Change up jump distance threshold if needed\n",
    "jump_thresh = 40\n",
    "assert jump_thresh in [20, 40]\n",
    "save_append = \"\" if jump_thresh == 40 else f\"_jumpthresh{jump_thresh}\"\n",
    "\n",
    "cont_df = []\n",
    "for s, sess in enumerate(sessions):\n",
    "    # cont_replay_df = sess.replay_filtered.to_dataframe()\n",
    "    cont_replay_df = sess.replay_filtered.to_dataframe() if jump_thresh == 40 else getattr(sess, f\"replay_filtered{jump_thresh}jd\").to_dataframe()\n",
    "    # all_replay_df = sess.replay_pbe_mua.to_dataframe()\n",
    "\n",
    "    all_pbe_df = sess.pbe_filters.to_dataframe()\n",
    "    good_pbe = (all_pbe_df.is_rpl & all_pbe_df.is_5units & all_pbe_df.is_rest).values\n",
    "\n",
    "    good_pbe_df = all_pbe_df.loc[good_pbe, [\"start\", \"stop\"]].reset_index(drop=True)\n",
    "    is_cont = np.isin(good_pbe_df.start, cont_replay_df.start)\n",
    "\n",
    "    # Add in brainstate\n",
    "    bs_df = sess.brainstates.to_dataframe()\n",
    "    nrem_epochs = Epoch(bs_df[bs_df.label == \"NREM\"])\n",
    "    is_nrem, _, _ = nrem_epochs.contains(good_pbe_df.start)\n",
    "    wake_epochs = Epoch(bs_df.loc[(bs_df.label == \"QW\") | (bs_df.label == \"AW\"), :])\n",
    "    is_wake, _, _ = wake_epochs.contains(good_pbe_df.start)\n",
    "\n",
    "    zt_epochs = sess.get_zt_epochs()\n",
    "\n",
    "    for e in zt_epochs.itertuples():\n",
    "        indx = (good_pbe_df.start >= e.start) & (good_pbe_df.stop <= e.stop)\n",
    "        e_df = pd.DataFrame(\n",
    "            dict(is_cont=is_cont[indx], zt=e.label, session=s, grp=sess.tag, brainstate=\"\")\n",
    "        )\n",
    "        e_df.loc[is_nrem[indx], \"brainstate\"] = \"NREM\"\n",
    "        e_df.loc[is_wake[indx], \"brainstate\"] = \"WAKE\"\n",
    "\n",
    "        cont_df.append(e_df)\n",
    "\n",
    "cont_df = pd.concat(cont_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_cont</th>\n",
       "      <th>zt</th>\n",
       "      <th>session</th>\n",
       "      <th>grp</th>\n",
       "      <th>brainstate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>PRE</td>\n",
       "      <td>0</td>\n",
       "      <td>NSD</td>\n",
       "      <td>WAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>PRE</td>\n",
       "      <td>0</td>\n",
       "      <td>NSD</td>\n",
       "      <td>WAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>PRE</td>\n",
       "      <td>0</td>\n",
       "      <td>NSD</td>\n",
       "      <td>WAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>PRE</td>\n",
       "      <td>0</td>\n",
       "      <td>NSD</td>\n",
       "      <td>WAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>PRE</td>\n",
       "      <td>0</td>\n",
       "      <td>NSD</td>\n",
       "      <td>WAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136784</th>\n",
       "      <td>False</td>\n",
       "      <td>5-7.5</td>\n",
       "      <td>12</td>\n",
       "      <td>SD</td>\n",
       "      <td>NREM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136785</th>\n",
       "      <td>True</td>\n",
       "      <td>5-7.5</td>\n",
       "      <td>12</td>\n",
       "      <td>SD</td>\n",
       "      <td>NREM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136786</th>\n",
       "      <td>False</td>\n",
       "      <td>5-7.5</td>\n",
       "      <td>12</td>\n",
       "      <td>SD</td>\n",
       "      <td>NREM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136787</th>\n",
       "      <td>False</td>\n",
       "      <td>5-7.5</td>\n",
       "      <td>12</td>\n",
       "      <td>SD</td>\n",
       "      <td>NREM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136788</th>\n",
       "      <td>False</td>\n",
       "      <td>5-7.5</td>\n",
       "      <td>12</td>\n",
       "      <td>SD</td>\n",
       "      <td>NREM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136789 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        is_cont     zt  session  grp brainstate\n",
       "0         False    PRE        0  NSD       WAKE\n",
       "1         False    PRE        0  NSD       WAKE\n",
       "2         False    PRE        0  NSD       WAKE\n",
       "3         False    PRE        0  NSD       WAKE\n",
       "4         False    PRE        0  NSD       WAKE\n",
       "...         ...    ...      ...  ...        ...\n",
       "136784    False  5-7.5       12   SD       NREM\n",
       "136785     True  5-7.5       12   SD       NREM\n",
       "136786    False  5-7.5       12   SD       NREM\n",
       "136787    False  5-7.5       12   SD       NREM\n",
       "136788    False  5-7.5       12   SD       NREM\n",
       "\n",
       "[136789 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save proportions by brainstate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only NREM and WAKE epochs (get rid of noise and REM)\n",
    "cont_df_bs = cont_df[(cont_df.brainstate == \"NREM\") | (cont_df.brainstate == \"WAKE\")]\n",
    "cont_df_bs = cont_df_bs.groupby([\"grp\", \"brainstate\", \"session\", \"zt\"]).mean().reset_index()\n",
    "cont_df_bs = cont_df_bs.rename(columns={\"is_cont\": \"prop\"})\n",
    "\n",
    "subjects.GroupData().save(cont_df_bs, f\"replay_continuous_events_brainstate{save_append}\")\n",
    "cont_df_bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save numbers by brainstate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### KEY FLAG HERE - set to True if doing brainstate analysis, else set to False\n",
    "by_brainstate = True\n",
    "bs_append = \"_bs\" if by_brainstate else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuous_replay_number_bs saved\n"
     ]
    }
   ],
   "source": [
    "### Continuous replay number\n",
    "\n",
    "# Original code w/o brainstate\n",
    "if not by_brainstate:\n",
    "    number_df = cont_df.drop(columns=[\"brainstate\"]).groupby([\"grp\", \"session\", \"zt\"], sort=False).sum().reset_index()\n",
    "else: \n",
    "    number_df = cont_df.groupby([\"brainstate\", \"grp\", \"session\", \"zt\"], sort=False).sum().reset_index()\n",
    "\n",
    "subjects.GroupData().save(number_df, f\"continuous_replay_number{save_append}{bs_append}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_replay_number_bs saved\n"
     ]
    }
   ],
   "source": [
    "### Total number of candidate events\n",
    "# Original code w/o brainstate\n",
    "if not by_brainstate:\n",
    "    number_df = cont_df.drop(columns=[\"brainstate\"]).groupby([\"grp\", \"session\", \"zt\"], sort=False).count().reset_index()\n",
    "else:\n",
    "    number_df = cont_df.groupby([\"brainstate\", \"grp\", \"session\", \"zt\"], sort=False).count().reset_index()\n",
    "\n",
    "subjects.GroupData().save(number_df, f\"candidate_replay_number{save_append}{bs_append}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- bootstrapping absolute numbers--------\n",
    "# use this one!\n",
    "func = (\n",
    "    lambda df: df.drop(columns=[\"brainstate\"]).groupby([\"grp\", \"zt\", \"session\"], sort=False)\n",
    "    .sum()\n",
    "    # .reset_index()\n",
    "    .groupby([\"grp\", \"zt\"], sort=False)\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Don't use this one - we want the mean number of events across all animals since we have different #s of sessions in each group\n",
    "# func = lambda df: df.drop(columns=[\"brainstate\"]).groupby([\"grp\", \"zt\"], sort=False).sum().reset_index()\n",
    "\n",
    "boot_df = stats_utils.bootstrap_resample(\n",
    "    cont_df, level=\"both\", n_iter=10000, n_jobs=8, apply=func\n",
    ")\n",
    "subjects.GroupData().save(boot_df, f\"continuous_replay_number_bootstrap{save_append}\")\n",
    "\n",
    "# ---- bootstrapping proportion --------\n",
    "## proportion of events pooled across sampled sessions, not mean of proportions\n",
    "\n",
    "# func = lambda df: df.drop(columns=[\"brainstate\"]).groupby([\"grp\", \"zt\"], sort=False).mean().reset_index()\n",
    "\n",
    "# boot_df = stats_utils.bootstrap_resample(\n",
    "#     cont_df, level=\"both\", n_iter=10000, n_jobs=8, apply=func\n",
    "# ).drop(columns=[\"session\"])\n",
    "# subjects.GroupData().save(boot_df, f\"continuous_replay_proportion_bootstrap{save_append}\")\n",
    "\n",
    "\n",
    "# ---- bootstrapping candidate numbers\n",
    "# if by_brainstate:\n",
    "#     func = lambda df: df.drop(columns=[\"brainstate\"]).groupby([\"grp\", \"zt\"], sort=False).mean().reset_index()\n",
    "# else:\n",
    "#     func = lambda df: df.groupby([\"grp\", \"zt\"], sort=False).mean().reset_index()\n",
    "# boot_df = stats_utils.bootstrap_resample(\n",
    "#     number_df, level=\"both\", n_iter=10000, n_jobs=8, apply=func\n",
    "# ).drop(columns=[\"session\"])\n",
    "# subjects.GroupData().save(boot_df, f\"candidate_replay_number_bootstrap{save_append}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap by brain state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running bootstraps for NSD group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10000/10000 [00:55<00:00, 180.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running bootstraps for SD group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10000/10000 [01:21<00:00, 123.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuous_replay_WAKE_number_bootstrap saved\n",
      "Running bootstraps for NSD group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10000/10000 [00:52<00:00, 189.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running bootstraps for SD group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10000/10000 [00:33<00:00, 297.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuous_replay_NREM_number_bootstrap saved\n"
     ]
    }
   ],
   "source": [
    "for state_name in [\"WAKE\", \"NREM\"]:\n",
    "    state_cont_df = cont_df[cont_df.brainstate == state_name]\n",
    "    state_number_df = number_df[number_df.brainstate == state_name]\n",
    "\n",
    "    # # ---- bootstrapping proportion --------\n",
    "    # ## proportion of events pooled across sampled sessions, not mean of proportions\n",
    "    # func = lambda df: df.drop(columns=[\"brainstate\"]).groupby([\"grp\", \"zt\"], sort=False).mean().reset_index()\n",
    "    \n",
    "    # boot_df = stats_utils.bootstrap_resample(\n",
    "    #     state_cont_df, level=\"both\", n_iter=10000, n_jobs=8, apply=func\n",
    "    # ).drop(columns=[\"session\"])\n",
    "    # subjects.GroupData().save(boot_df, f\"continuous_replay_{state_name}_proportion_bootstrap\")\n",
    "\n",
    "    # ---- bootstraping absolute numbers--------\n",
    "    # use this one!\n",
    "    func = (\n",
    "        lambda df: df.drop(columns=[\"brainstate\"])\n",
    "        .groupby([\"grp\", \"zt\", \"session\"], sort=False)\n",
    "        .sum()\n",
    "        # .reset_index()\n",
    "        .groupby([\"grp\", \"zt\"], sort=False)\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "    ## Don't use this one - we want the mean number of events across all animals since we have different #s of sessions in each group\n",
    "    ## func = lambda df: df.drop(columns=[\"brainstate\"]).groupby([\"grp\", \"zt\"], sort=False).sum().reset_index()\n",
    "    \n",
    "    boot_df = stats_utils.bootstrap_resample(\n",
    "        state_cont_df, level=\"both\", n_iter=10000, n_jobs=8, apply=func\n",
    "    )\n",
    "    subjects.GroupData().save(boot_df, f\"continuous_replay_{state_name}_number_bootstrap\")\n",
    "\n",
    "    # ---- bootstrapping candidate numbers\n",
    "\n",
    "    # func = lambda df: df.drop(columns=[\"brainstate\"]).groupby([\"grp\", \"zt\"], sort=False).mean().reset_index()\n",
    "    # boot_df = stats_utils.bootstrap_resample(\n",
    "    #     state_number_df, level=\"both\", n_iter=10000, n_jobs=8, apply=func\n",
    "    # ).drop(columns=[\"session\"])\n",
    "    # subjects.GroupData().save(boot_df, f\"candidate_replay_{state_name}_number_bootstrap\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the absolute number\n",
    "\n",
    "\n",
    "fig = plotting.Fig(5, 5)\n",
    "\n",
    "ax = fig.subplot(fig.gs[0, 0])\n",
    "df = cont_df.groupby([\"grp\", \"session\", \"zt\"], sort=False).sum().reset_index()\n",
    "p1 = Plotter(data=df, x=\"zt\", y=\"is_cont\", hue=\"grp\", hue_order=[\"NSD\", \"SD\"], ax=ax)\n",
    "p1.stripbarplot_sd().stat_anot_sd(\n",
    "    stat_across=\"t-test_welch\",\n",
    "    alpha_across=0.05,\n",
    "    stat_within=\"t-test_paired\",\n",
    "    alpha_within=0.05,\n",
    "    fontsize=5,\n",
    ")\n",
    "ax = fig.subplot(fig.gs[0, 2])\n",
    "boot_number_df = subjects.GroupData().continuous_replay_number_bootstrap\n",
    "p2 = Plotter(\n",
    "    data=boot_number_df, x=\"zt\", y=\"is_cont\", hue=\"grp\", hue_order=[\"NSD\", \"SD\"], ax=ax\n",
    ")\n",
    "p2.violinplot_sd(palette=subjects.colors_sd()).stat_anot_sd(\n",
    "    stat_across=stats_utils.get_bootstrap_prob,\n",
    "    alpha_across=0.025,\n",
    "    stat_within=stats_utils.get_bootstrap_prob_paired,\n",
    "    alpha_within=0.025,\n",
    "    fontsize=5,\n",
    ")\n",
    "\n",
    "# ax = fig.subplot(fig.gs[3, 0])\n",
    "# df = cont_df.groupby([\"grp\", \"session\", \"zt\"], sort=False).mean().reset_index()\n",
    "# p2 = Plotter(data=df, x=\"zt\", y=\"is_cont\", hue=\"grp\", hue_order=[\"NSD\", \"SD\"], ax=ax)\n",
    "# p2.stripbarplot_sd()\n",
    "\n",
    "fig.savefig(subjects.figpath_sd / \"trajectory_replay_number_and_bootstrap\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap the continuous trajectory PBE duration\n",
    "- calculate mean bootstrap duration for PBEs that have continuous trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"jump_thresh\" in locals():\n",
    "    save_append = \"\" if jump_thresh == 40 else f\"_jumpthresh{jump_thresh}\"\n",
    "    \n",
    "pbe_duration = getattr(subjects.GroupData(), f\"continuous_replay_PBE_duration{save_append}\")\n",
    "\n",
    "# ---- bootstraping absolute numbers--------\n",
    "func = lambda df: df.groupby([\"grp\", \"zt\"], sort=False).mean().reset_index()\n",
    "\n",
    "boot_df = stats_utils.bootstrap_resample(\n",
    "    pbe_duration, level=\"both\", n_iter=10000, n_jobs=8, apply=func\n",
    ").drop(columns=\"session\")\n",
    "\n",
    "subjects.GroupData().save(boot_df, f\"continuous_replay_PBE_duration_bootstrap{save_append}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running bootstraps for NSD group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10000/10000 [00:36<00:00, 272.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running bootstraps for SD group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10000/10000 [00:43<00:00, 228.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuous_replay_WAKE_PBE_duration_bootstrap saved\n",
      "Running bootstraps for NSD group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10000/10000 [00:31<00:00, 315.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running bootstraps for SD group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 10000/10000 [00:23<00:00, 423.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuous_replay_NREM_PBE_duration_bootstrap saved\n"
     ]
    }
   ],
   "source": [
    "# by brainstate\n",
    "if \"jump_thresh\" in locals():\n",
    "    save_append = \"\" if jump_thresh == 40 else f\"_jumpthresh{jump_thresh}\"\n",
    "    \n",
    "pbe_duration = getattr(subjects.GroupData(), f\"continuous_replay_PBE_duration{save_append}_bs\")\n",
    "\n",
    "for state_name in [\"WAKE\", \"NREM\"]:\n",
    "    \n",
    "    state_dur_df = pbe_duration[pbe_duration.brainstate == state_name]\n",
    "    # ---- bootstraping absolute numbers--------\n",
    "    func = lambda df: df.drop(columns=[\"brainstate\"]).groupby([\"grp\", \"zt\"], sort=False).mean().reset_index()\n",
    "    \n",
    "    boot_df = stats_utils.bootstrap_resample(\n",
    "        state_dur_df, level=\"both\", n_iter=10000, n_jobs=8, apply=func\n",
    "    ).drop(columns=\"session\")\n",
    "    \n",
    "    subjects.GroupData().save(boot_df, f\"continuous_replay_{state_name}_PBE_duration_bootstrap{save_append}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbe_duration_1h = subjects.GroupData().continuous_replay_PBE_duration_1h_blocks\n",
    "\n",
    "# ---- bootstraping absolute numbers--------\n",
    "func = lambda df: df.groupby([\"grp\", \"zt\"], sort=False).mean().reset_index()\n",
    "\n",
    "boot_df = stats_utils.bootstrap_resample(\n",
    "    pbe_duration_1h, level=\"both\", n_iter=10000, n_jobs=8, apply=func\n",
    ").drop(columns=\"session\")\n",
    "\n",
    "subjects.GroupData().save(boot_df, \"continuous_replay_PBE_duration_1h_blocks_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plotting.Fig(5, 5)\n",
    "ax = fig.subplot(fig.gs[0])\n",
    "\n",
    "p1 = Plotter(\n",
    "    data=boot_df, x=\"zt\", y=\"pbe_duration\", hue=\"grp\", hue_order=[\"NSD\", \"SD\"], ax=ax\n",
    ")\n",
    "p1.violinplot_sd(palette=subjects.colors_sd()).stat_anot_sd(\n",
    "    stat_across=stats_utils.get_bootstrap_prob,\n",
    "    alpha_across=0.025,\n",
    "    stat_within=stats_utils.get_bootstrap_prob_paired,\n",
    "    alpha_within=0.025,\n",
    ")\n",
    "\n",
    "fig.savefig(subjects.figpath_sd / \"trajectory_replay_PBE_duration_bootstrap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1h block) Bootstrap continuous trajectory replay proportion/number\n",
    "- For sd_paper fig4, where we compare proportion of significant continuous trajectory events, that can be substituted by bootstrap distribution.\n",
    "- One way of doing that will be randomly sampling events with replacement and calculate how many of the selected events are significant trajectory events. While initially seems like a reasonable measure, it may backfire for sessions which have low proportion of significant events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "\n",
    "cont_df = []\n",
    "for s, sess in enumerate(sessions):\n",
    "    cont_replay_df = sess.replay_filtered.to_dataframe()\n",
    "    # all_replay_df = sess.replay_pbe_mua.to_dataframe()\n",
    "\n",
    "    all_pbe_df = sess.pbe_filters.to_dataframe()\n",
    "    good_pbe = (all_pbe_df.is_rpl & all_pbe_df.is_5units & all_pbe_df.is_rest).values\n",
    "\n",
    "    good_pbe_df = all_pbe_df.loc[good_pbe, [\"start\", \"stop\"]].reset_index(drop=True)\n",
    "    is_cont = np.isin(good_pbe_df.start, cont_replay_df.start)\n",
    "\n",
    "    zt_epochs = sess.get_zt_1h()\n",
    "\n",
    "    for e in zt_epochs.itertuples():\n",
    "        indx = (good_pbe_df.start >= e.start) & (good_pbe_df.stop <= e.stop)\n",
    "        e_df = pd.DataFrame(\n",
    "            dict(is_cont=is_cont[indx], zt=e.label, session=s, grp=sess.tag)\n",
    "        )\n",
    "\n",
    "        cont_df.append(e_df)\n",
    "\n",
    "cont_df = pd.concat(cont_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_df = cont_df.groupby([\"grp\", \"session\", \"zt\"], sort=False).sum().reset_index()\n",
    "\n",
    "subjects.GroupData().save(number_df, \"continuous_replay_number_1h_blocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NRK Sanity check / unit test code to illustrate resampling at both levels for boostrapping below\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "# Inputs/parameters\n",
    "df = deepcopy(cont_df)\n",
    "level=\"both\"\n",
    "apply = lambda df: df.groupby([\"grp\", \"zt\"], sort=False).mean().reset_index()\n",
    "\n",
    "# Code copied from stats_utils.boostrap_resample\n",
    "sess_ids = df[\"session\"].unique()\n",
    "n_sess = len(sess_ids)\n",
    "# print(sess_ids)\n",
    "if level in {\"session\", \"both\"}:\n",
    "    # bootstrap session_ids\n",
    "    rng = np.random.default_rng()\n",
    "    sess_ids = rng.choice(sess_ids, size=n_sess, replace=True)\n",
    "    # sess_ids = [12]*13  # uncomment to test what happens if you only grab one type of sessions\n",
    "\n",
    "new_df = []\n",
    "print(f\"#NSD sessions = {n_NSD}\")\n",
    "for i, idx in enumerate(sess_ids):\n",
    "    idx_df = df[df.session == idx].copy()  # df of variables for that session\n",
    "    idx_df.loc[:, \"session\"] = i  # make selected session independent\n",
    "\n",
    "    if level in {\"both\", \"samples\"}:\n",
    "        # bootstrap second level - grab equal numbers of events in each zt group\n",
    "        if \"zt\" in idx_df.columns:\n",
    "            idx_df = (\n",
    "                idx_df.groupby([\"zt\"], sort=False)\n",
    "                .apply(pd.DataFrame.sample, frac=1, replace=True, ignore_index=True)\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "        else:\n",
    "            idx_df = idx_df.sample(frac=1, replace=True, ignore_index=True)\n",
    "\n",
    "    new_df.append(idx_df)\n",
    "new_df = pd.concat(new_df, ignore_index=True)\n",
    "\n",
    "if apply is not None:\n",
    "    assert callable(apply), \"apply can only be a function\"\n",
    "    new_df = apply(new_df)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- bootstraping proportion --------\n",
    "## proportion of events pooled across sampled sessions, not mean of proportions\n",
    "func = lambda df: df.groupby([\"grp\", \"zt\"], sort=False).mean().reset_index()\n",
    "\n",
    "boot_df = stats_utils.bootstrap_resample(\n",
    "    cont_df, level=\"both\", n_iter=10000, n_jobs=8, apply=func\n",
    ").drop(columns=[\"session\"])\n",
    "subjects.GroupData().save(boot_df, \"continuous_replay_proportion_1h_blocks_bootstrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---- bootstraping absolute numbers--------\n",
    "func = (\n",
    "    lambda df: df.groupby([\"grp\", \"zt\", \"session\"], sort=False)\n",
    "    .sum()\n",
    "    # .reset_index()\n",
    "    .groupby([\"grp\", \"zt\"], sort=False)\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "# func = lambda df: df.groupby([\"grp\", \"zt\"], sort=False).sum().reset_index()\n",
    "\n",
    "boot_df = stats_utils.bootstrap_resample(\n",
    "    number_df, level=\"both\", n_iter=10000, n_jobs=8, apply=func\n",
    ")\n",
    "subjects.GroupData().save(boot_df, \"continuous_replay_number_1h_blocks_bootstrap\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute number using only the last hour of the PRE block to match POST block lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "\n",
    "cont_df = []\n",
    "for s, sess in enumerate(sessions):\n",
    "    cont_replay_df = sess.replay_filtered.to_dataframe()\n",
    "    # all_replay_df = sess.replay_pbe_mua.to_dataframe()\n",
    "\n",
    "    all_pbe_df = sess.pbe_filters.to_dataframe()\n",
    "    good_pbe = (all_pbe_df.is_rpl & all_pbe_df.is_5units & all_pbe_df.is_rest).values\n",
    "\n",
    "    good_pbe_df = all_pbe_df.loc[good_pbe, [\"start\", \"stop\"]].reset_index(drop=True)\n",
    "    is_cont = np.isin(good_pbe_df.start, cont_replay_df.start)\n",
    "\n",
    "    zt_epochs = sess.get_zt_1h(pre_length=1)\n",
    "\n",
    "    for e in zt_epochs.itertuples():\n",
    "        indx = (good_pbe_df.start >= e.start) & (good_pbe_df.stop <= e.stop)\n",
    "        e_df = pd.DataFrame(\n",
    "            dict(is_cont=is_cont[indx], zt=e.label, session=s, grp=sess.tag)\n",
    "        )\n",
    "\n",
    "        cont_df.append(e_df)\n",
    "\n",
    "cont_df = pd.concat(cont_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_df = cont_df.groupby([\"grp\", \"session\", \"zt\"], sort=False).sum().reset_index()\n",
    "\n",
    "subjects.GroupData().save(number_df, \"continuous_replay_number_1h_blocks_1hpre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- bootstraping absolute numbers--------\n",
    "func = (\n",
    "    lambda df: df.groupby([\"grp\", \"zt\", \"session\"], sort=False)\n",
    "    .sum()\n",
    "    # .reset_index()\n",
    "    .groupby([\"grp\", \"zt\"], sort=False)\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "boot_df = stats_utils.bootstrap_resample(\n",
    "    number_df, level=\"both\", n_iter=10000, n_jobs=8, apply=func\n",
    ")\n",
    "subjects.GroupData().save(boot_df, \"continuous_replay_number_1h_blocks_1hpre_bootstrap\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
