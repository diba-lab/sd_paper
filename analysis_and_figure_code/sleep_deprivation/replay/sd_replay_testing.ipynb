{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import subjects\n",
    "from joblib import Parallel, delayed\n",
    "from neuropy import plotting\n",
    "from neuropy.analyses import Decode1d, Pf1D\n",
    "from neuropy.analyses.decoders import radon_transform\n",
    "from neuropy.core import Epoch\n",
    "from neuropy.utils import signal_process\n",
    "from neuropy.utils.mathutil import min_max_scaler\n",
    "from neuropy.utils.position_util import run_direction\n",
    "from scipy import stats\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backup of replay files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "\n",
    "# for s, sess in enumerate(sessions):\n",
    "    \n",
    "#     sess.replay_pbe.save(sess.filePrefix.with_suffix('.bak.06-13-2022.pbe.replay'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize decoding in one session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.nsd.ratNday2\n",
    "for sub, sess in enumerate(sessions):\n",
    "    maze = sess.paradigm[\"maze\"].flatten()\n",
    "    post = sess.paradigm[\"post\"].flatten()\n",
    "    neurons = sess.neurons.get_neuron_type(neuron_type=\"pyr\")\n",
    "    pos = sess.maze\n",
    "    # pos.t_start = pos.t_start - 0.5\n",
    "    forward = sess.maze_run[\"up\"]\n",
    "\n",
    "    pf = Pf1D(\n",
    "        neurons=neurons,\n",
    "        position=pos,\n",
    "        speed_thresh=5,\n",
    "        sigma=4,\n",
    "        grid_bin=2,\n",
    "        epochs=forward,\n",
    "        frate_thresh=0.1,\n",
    "    )\n",
    "    pf_neurons = neurons.get_by_id(pf.neuron_ids)\n",
    "    epochs = sess.pbe.time_slice(post[0], post[0] + 2 * 3600)\n",
    "    decode = Decode1d(\n",
    "        neurons=pf_neurons,\n",
    "        ratemap=pf,\n",
    "        epochs=epochs,\n",
    "        bin_size=0.02,\n",
    "        score_method=\"wcorr\",\n",
    "        n_jobs=6,\n",
    "    )\n",
    "    decode.calculate_shuffle_score(n_iter=200, method=\"neuron_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode.plot_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfuncs import plot_in_bokeh\n",
    "import bokeh.plotting as bplot\n",
    "\n",
    "measure = decode.sequence_score \n",
    "# measure[np.isnan(measure)] = 0\n",
    "# bplot.output_file(subjects.figpath_sd/'test_wake_decoding.html')\n",
    "bplot.output_notebook()\n",
    "p = plot_in_bokeh(\n",
    "    x=epochs.starts / 3600,\n",
    "    y=measure,\n",
    "    img_arr=decode.posterior,\n",
    "    color_by=measure,\n",
    "    palette=\"jet\",\n",
    "    size=10,\n",
    ")\n",
    "# p.line(pos.time,pos.x/350 + 0.2,line_width=2,color='black')\n",
    "bplot.show(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save radon scores as separate epoch file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sessions = subjects.pf_sess()\n",
    "sessions = subjects.sd.ratVday2\n",
    "\n",
    "radon_df = []\n",
    "for sub, sess in enumerate(tqdm(sessions)):\n",
    "\n",
    "    replay_pbe = sess.replay_pbe.to_dataframe()\n",
    "    metadata = sess.replay_pbe.metadata\n",
    "    starts = sess.replay_pbe.starts\n",
    "    stops = sess.replay_pbe.stops\n",
    "\n",
    "    posteriors = [metadata[\"up_posterior\"], metadata[\"down_posterior\"]]\n",
    "\n",
    "    r_score,velocity = [],[]\n",
    "    for p in posteriors:\n",
    "        results = Parallel(n_jobs=6)(\n",
    "            delayed(radon_transform)(epoch, nlines=20000, dt=0.02, dx=2, neighbours=8)\n",
    "            for epoch in p\n",
    "        )\n",
    "        score, v, intercept = np.asarray(results).T\n",
    "        r_score.append(score)\n",
    "        velocity.append(v)\n",
    "\n",
    "    epoch_df = pd.DataFrame(\n",
    "        dict(\n",
    "            start=starts,\n",
    "            stop=stops,\n",
    "            up_radon_score=r_score[0],\n",
    "            up_velocity = velocity[0],\n",
    "            down_radon_score=r_score[1],\n",
    "            down_velocity = velocity[1],\n",
    "            label='pbe',\n",
    "        )\n",
    "    )\n",
    "    Epoch(epochs=epoch_df).save(sess.filePrefix.with_suffix('.pbe.radon'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test radon score distribution with varying neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sessions = subjects.pf_sess()\n",
    "sess = subjects.sd.ratUday1[0]\n",
    "replay_pbe = sess.replay_radon.to_dataframe()\n",
    "pbe_epochs = sess.replay_radon.flatten()\n",
    "neurons = sess.neurons_stable.get_neuron_type(['pyr','mua'])\n",
    "n_spikes = [np.histogram(_,bins=pbe_epochs)[0][::2] for _ in neurons.spiketrains]\n",
    "fire_bool = (np.array(n_spikes)>0).sum(axis=0)>=5\n",
    "replay_pbe = replay_pbe[fire_bool]\n",
    "\n",
    "metadata = sess.replay_radon.metadata\n",
    "starts = replay_pbe.start.values\n",
    "posteriors = metadata[\"up_posterior\"]\n",
    "posteriors = [posteriors[_] for _ in np.where(fire_bool)[0]]\n",
    "\n",
    "score_df = []\n",
    "for e in [\"pre\", \"maze\"]:\n",
    "    period = sess.paradigm[e].flatten()\n",
    "\n",
    "    if e == \"post\":\n",
    "        period = [period[0], period[0] + 2 * 3600]\n",
    "\n",
    "    indx = np.where((starts > period[0]) & (starts < period[1]))[0]\n",
    "    e_posteriors = [posteriors[_] for _ in indx]\n",
    "\n",
    "    for i, neigh in enumerate([8, 25]):\n",
    "        results = Parallel(n_jobs=6)(\n",
    "            delayed(radon_transform)(\n",
    "                epoch, nlines=6000, dt=0.02, dx=2, neighbours=neigh\n",
    "            )\n",
    "            for epoch in e_posteriors\n",
    "        )\n",
    "        score, v, intercept = np.asarray(results).T\n",
    "\n",
    "        score_df.append(pd.DataFrame(dict(n=neigh, score=score, zt=e)))\n",
    "\n",
    "score_df = pd.concat(score_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots()\n",
    "\n",
    "sns.violinplot(data=score_df,x='n',y='score',hue='zt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test radon score with and without normalizing posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scale_post(arr):\n",
    "    return (arr - arr.min()) / (arr.max() - arr.min())\n",
    "\n",
    "\n",
    "# sessions = subjects.pf_sess()\n",
    "sess = subjects.sd.ratUday1[0]\n",
    "replay_pbe = sess.replay_radon.to_dataframe()\n",
    "pbe_epochs = sess.replay_radon.flatten()\n",
    "neurons = sess.neurons_stable.get_neuron_type([\"pyr\", \"mua\"])\n",
    "n_spikes = [np.histogram(_, bins=pbe_epochs)[0][::2] for _ in neurons.spiketrains]\n",
    "fire_bool = (np.array(n_spikes) > 0).sum(axis=0) >= 5\n",
    "replay_pbe = replay_pbe[fire_bool]\n",
    "\n",
    "metadata = sess.replay_radon.metadata\n",
    "starts = replay_pbe.start.values\n",
    "posteriors = metadata[\"up_posterior\"]\n",
    "posteriors = [posteriors[_] for _ in np.where(fire_bool)[0]]\n",
    "\n",
    "score_df = []\n",
    "for e in [\"pre\", \"maze\"]:\n",
    "    period = sess.paradigm[e].flatten()\n",
    "\n",
    "    if e == \"post\":\n",
    "        period = [period[0], period[0] + 2 * 3600]\n",
    "\n",
    "    indx = np.where((starts > period[0]) & (starts < period[1]))[0]\n",
    "    e_posteriors = [posteriors[_] for _ in indx]\n",
    "\n",
    "    for norm in [True, False]:\n",
    "\n",
    "        if norm:\n",
    "            p = [scale_post(_) for _ in e_posteriors]\n",
    "        else:\n",
    "            p = e_posteriors\n",
    "        \n",
    "        results = Parallel(n_jobs=6)(\n",
    "            delayed(radon_transform)(epoch, nlines=6000, dt=0.02, dx=2, neighbours=8)\n",
    "            for epoch in p\n",
    "        )\n",
    "        score, v, intercept = np.asarray(results).T\n",
    "\n",
    "        score_df.append(pd.DataFrame(dict(score=score, norm=norm, zt=e)))\n",
    "\n",
    "score_df = pd.concat(score_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "# sns.violinplot(\n",
    "#     data=score_df[score_df.norm == True],\n",
    "#     x=\"zt\",\n",
    "#     y=\"score\",\n",
    "#     hue=\"norm\",\n",
    "#     inner=\"quartile\",\n",
    "# )\n",
    "\n",
    "ax.pcolormesh(p[100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test radon score with varying place field peak frate thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sess = subjects.sd.ratUday1[0]\n",
    "period = sess.paradigm[\"maze\"].flatten()\n",
    "starts = sess.replay_wcorr.starts\n",
    "\n",
    "neurons = sess.neurons_stable.get_neuron_type([\"pyr\"])\n",
    "# neurons = neurons[neurons.firing_rate<=10]\n",
    "\n",
    "maze_pos = sess.maze\n",
    "# maze_run= run_direction(maze_pos,min_distance=30,sigma=0.2,speed_thresh=(8,None))\n",
    "\n",
    "peak_frates = [0.3,0.5,1]\n",
    "epochs = sess.get_zt_epochs()\n",
    "# epochs = epochs[:3]\n",
    "\n",
    "score_df = []\n",
    "for b in peak_frates:\n",
    "    pf = Pf1D(\n",
    "        neurons=neurons,\n",
    "        position=sess.maze,\n",
    "        sigma=4,\n",
    "        grid_bin=2,\n",
    "        epochs=sess.maze_run[\"up\"],\n",
    "        frate_thresh=b,\n",
    "    )\n",
    "    pf_neurons = neurons.get_by_id(pf.neuron_ids)\n",
    "    print(pf_neurons.n_neurons)\n",
    "\n",
    "    for e in epochs.itertuples():\n",
    "        pbe_bool = (starts > e.start) & (starts < e.stop)\n",
    "        pbe_epochs = sess.replay_wcorr[pbe_bool]\n",
    "\n",
    "        decode = Decode1d(\n",
    "            neurons=pf_neurons,\n",
    "            ratemap=pf,\n",
    "            epochs=pbe_epochs,\n",
    "            bin_size=0.02,\n",
    "            n_jobs=6,\n",
    "        )\n",
    "        radon = decode.get_radon_transform(nlines=5000,margin=16)[0]\n",
    "        score_df.append(pd.DataFrame(dict(frate_thresh=b, zt=e.label, score=radon)))\n",
    "\n",
    "score_df = pd.concat(score_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots()\n",
    "\n",
    "sns.violinplot(data=score_df,x='zt',y='score',hue='frate_thresh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test radon score with varying track binning size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sess = subjects.sd.ratUday4[0]\n",
    "period = sess.paradigm[\"maze\"].flatten()\n",
    "starts = sess.replay_wcorr.starts\n",
    "\n",
    "neurons = sess.neurons_stable.get_neuron_type([\"pyr\",'mua'])\n",
    "neurons = neurons[neurons.firing_rate<=10]\n",
    "\n",
    "maze_pos = sess.maze\n",
    "# maze_run= run_direction(maze_pos,min_distance=30,sigma=0.2,speed_thresh=(8,None))\n",
    "\n",
    "grid_binsz = [2,2.5,4]\n",
    "epochs = sess.get_zt_epochs()\n",
    "# epochs = epochs[:3]\n",
    "\n",
    "score_df = []\n",
    "for b in grid_binsz:\n",
    "    pf = Pf1D(\n",
    "        neurons=neurons,\n",
    "        position=sess.maze,\n",
    "        sigma=4.5,\n",
    "        grid_bin=b,\n",
    "        epochs=sess.maze_run[\"up\"],\n",
    "        frate_thresh=1,\n",
    "    )\n",
    "    pf_neurons = neurons.get_by_id(pf.neuron_ids)\n",
    "\n",
    "    for e in epochs.itertuples():\n",
    "        pbe_bool = (starts > e.start) & (starts < e.stop)\n",
    "        pbe_epochs = sess.replay_wcorr[pbe_bool]\n",
    "\n",
    "        decode = Decode1d(\n",
    "            neurons=pf_neurons,\n",
    "            ratemap=pf,\n",
    "            epochs=pbe_epochs,\n",
    "            bin_size=0.02,\n",
    "            n_jobs=6,\n",
    "        )\n",
    "        radon = decode.get_radon_transform(nlines=5000,margin=16)[0]\n",
    "        score_df.append(pd.DataFrame(dict(binsz=b, zt=e.label, score=radon)))\n",
    "\n",
    "score_df = pd.concat(score_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots()\n",
    "\n",
    "sns.violinplot(data=score_df,x='zt',y='score',hue='binsz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test radon score with varying binning size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = subjects.sd.ratRday2[0]\n",
    "period = sess.paradigm[\"maze\"].flatten()\n",
    "starts = sess.replay_wcorr.starts\n",
    "\n",
    "neurons = sess.neurons_stable.get_neuron_type(['pyr'])\n",
    "# neurons = neurons[neurons.firing_rate<=10] \n",
    "\n",
    "maze_pos = sess.maze\n",
    "# maze_run= run_direction(maze_pos,min_distance=30,sigma=0.2,speed_thresh=(8,None))\n",
    "pf = Pf1D(\n",
    "    neurons=neurons,\n",
    "    position=sess.maze,\n",
    "    sigma=4,\n",
    "    grid_bin=2,\n",
    "    epochs=sess.maze_run[\"up\"],\n",
    "    frate_thresh=0.3,\n",
    ")\n",
    "pf_neurons = neurons.get_by_id(pf.neuron_ids)\n",
    "\n",
    "\n",
    "bin_sizes = [0.02]\n",
    "epochs = sess.get_zt_epochs()\n",
    "# epochs = epochs[:3]\n",
    "\n",
    "score_df = []\n",
    "for e in epochs.itertuples():\n",
    "    pbe_bool = (starts > e.start) & (starts < e.stop)\n",
    "    pbe_epochs = sess.replay_wcorr[pbe_bool]\n",
    "    for b in bin_sizes:\n",
    "        decode = Decode1d(\n",
    "            neurons=pf_neurons,\n",
    "            ratemap=pf,\n",
    "            epochs=pbe_epochs,\n",
    "            bin_size=b,\n",
    "            score_method=\"radon_transform\",\n",
    "            radon_kw=dict(nlines=5000, decode_margin=16),\n",
    "            n_jobs=6,\n",
    "        )\n",
    "        score_df.append(pd.DataFrame(dict(binsz=b, zt=e.label, score=decode.score)))\n",
    "\n",
    "score_df = pd.concat(score_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots()\n",
    "\n",
    "sns.violinplot(data=score_df,x='binsz',y='score',hue='zt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test radon score with varying number of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = subjects.sd.ratNday1[0]\n",
    "period = sess.paradigm[\"maze\"].flatten()\n",
    "starts = sess.replay_pbe.starts\n",
    "\n",
    "neurons = sess.neurons\n",
    "maze_pos = sess.maze\n",
    "# maze_run= run_direction(maze_pos,min_distance=30,sigma=0.2,speed_thresh=(8,None))\n",
    "pf = Pf1D(\n",
    "    neurons=neurons,\n",
    "    position=sess.maze,\n",
    "    sigma=4,\n",
    "    grid_bin=2,\n",
    "    epochs=sess.maze_run[\"up\"],\n",
    "    frate_thresh=0.3,\n",
    ")\n",
    "pf_neurons = neurons.get_by_id(pf.neuron_ids)\n",
    "\n",
    "\n",
    "# nlines = np.arange(2000,30000,10000)\n",
    "nlines = [5000]\n",
    "epochs = sess.get_zt_epochs()\n",
    "epochs = epochs[2]\n",
    "\n",
    "score_df = []\n",
    "for e in epochs.itertuples():\n",
    "    pbe_bool = (starts > e.start) & (starts < e.stop)\n",
    "    pbe_epochs = sess.pbe[pbe_bool]\n",
    "    for nl in nlines:\n",
    "        decode = Decode1d(\n",
    "            neurons=pf_neurons,\n",
    "            ratemap=pf,\n",
    "            epochs=pbe_epochs,\n",
    "            bin_size=0.02,\n",
    "            score_method=\"radon_transform\",\n",
    "            radon_kw=dict(nlines=nl, decode_margin=16),\n",
    "            n_jobs=6,\n",
    "        )\n",
    "        decode.calculate_shuffle_score(method=\"neuron_id\", n_iter=10)\n",
    "        score_df.append(pd.DataFrame(dict(nlines=nl, zt=e.label, score=decode.score,shuffle_score=decode.shuffle_score.mean(axis=0))))\n",
    "\n",
    "\n",
    "score_df = pd.concat(score_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots()\n",
    "\n",
    "# sns.violinplot(data=score_df,x='nlines',y='score',inner='quartile')\n",
    "sns.violinplot(data=score_df,x='nlines',y='score')\n",
    "sns.violinplot(data=score_df,x='nlines',y='shuffle_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test radon score with and without normalizing place fields firing rates\n",
    "- normalized place fields improves the radon score across the board, but the increase for PRE is higher compared to MAZE and POST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = subjects.nsd.ratNday2[0]\n",
    "period = sess.paradigm[\"maze\"].flatten()\n",
    "starts = sess.replay_pbe.starts\n",
    "\n",
    "neurons = sess.neurons_stable.get_neuron_type(['pyr','mua'])\n",
    "maze_pos = sess.maze\n",
    "# maze_run= run_direction(maze_pos,min_distance=30,sigma=0.2,speed_thresh=(8,None))\n",
    "pf = Pf1D(\n",
    "    neurons=neurons,\n",
    "    position=sess.maze,\n",
    "    sigma=4,\n",
    "    grid_bin=2,\n",
    "    epochs=sess.maze_run[\"up\"],\n",
    "    frate_thresh=0.3,\n",
    ")\n",
    "pf_neurons = neurons.get_by_id(pf.neuron_ids)\n",
    "og_tc = pf.tuning_curves.copy()\n",
    "norm_tc = min_max_scaler(og_tc) \n",
    "\n",
    "epochs = sess.get_zt_epochs()\n",
    "epochs = epochs[:3]\n",
    "\n",
    "# score_df = []\n",
    "# for e in epochs.itertuples():\n",
    "#     pbe_bool = (starts > e.start) & (starts < e.stop)\n",
    "#     pbe_epochs = sess.pbe[pbe_bool]\n",
    "#     for norm in [False,True]:\n",
    "\n",
    "#         if norm:\n",
    "#             pf.tuning_curves = norm_tc \n",
    "#         else:\n",
    "#             pf.tuning_curves = og_tc\n",
    "\n",
    "#         decode = Decode1d(\n",
    "#             neurons=pf_neurons,\n",
    "#             ratemap=pf,\n",
    "#             epochs=pbe_epochs,\n",
    "#             bin_size=0.02,\n",
    "#             score_method=\"radon_transform\",\n",
    "#             radon_kw=dict(nlines=5000, decode_margin=16),\n",
    "#             n_jobs=6,\n",
    "#         )\n",
    "#         score_df.append(pd.DataFrame(dict(norm=norm, zt=e.label, score=decode.score)))\n",
    "\n",
    "# score_df = pd.concat(score_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots()\n",
    "\n",
    "sns.violinplot(data=score_df,x='zt',y='score',hue='norm',split=True,inner='quartile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots()\n",
    "\n",
    "posteriors = sess.replay_radon_mua.metadata[\"up_posterior\"]\n",
    "stacked_posteriors = np.hstack(posteriors)\n",
    "stacked_posteriors = np.apply_along_axis(\n",
    "        np.convolve, axis=0, arr=stacked_posteriors, v=np.ones(2 * 4 + 1), mode=\"same\"\n",
    "    )\n",
    "\n",
    "n_bins = np.array([_.shape[1] for _ in posteriors]).cumsum()\n",
    "\n",
    "ax.imshow(\n",
    "    stacked_posteriors,\n",
    "    aspect=\"auto\",\n",
    "    cmap=\"binary\",\n",
    "    interpolation=\"none\",\n",
    "    vmax=0.8,\n",
    "    origin=\"lower\",\n",
    ")\n",
    "ax.vlines(n_bins, 0, 160)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_posts = np.hstack([posteriors[_] for _ in range(2862,2864)])\n",
    "epochs = sess.replay_radon_mua[2862:2864].as_array()\n",
    "t = np.concatenate([np.arange(e[0],e[1],0.02)[:-1]+0.01 for e in epochs])\n",
    "y = np.arange(new_posts.shape[0]) \n",
    "\n",
    "_,ax = plt.subplots()\n",
    "ax.pcolormesh(t,y,new_posts,cmap='binary',shading='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test radon score including smaller duration PBEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sess = subjects.nsd.ratNday2[0]\n",
    "period = sess.paradigm[\"maze\"].flatten()\n",
    "\n",
    "neurons = sess.neurons_stable.get_neuron_type(['pyr','mua'])\n",
    "neurons = neurons[neurons.firing_rate<=10]\n",
    "maze_pos = sess.maze\n",
    "# maze_run= run_direction(maze_pos,min_distance=30,sigma=0.2,speed_thresh=(8,None))\n",
    "pf = Pf1D(\n",
    "    neurons=neurons,\n",
    "    position=sess.maze,\n",
    "    sigma=4,\n",
    "    grid_bin=2,\n",
    "    epochs=sess.maze_run[\"down\"],\n",
    "    frate_thresh=0.3,\n",
    ")\n",
    "pf_neurons = neurons.get_by_id(pf.neuron_ids)\n",
    "og_tc = pf.tuning_curves.copy()\n",
    "norm_tc = min_max_scaler(og_tc) \n",
    "\n",
    "decode_epochs = sess.pbe\n",
    "epochs = sess.get_zt_epochs()\n",
    "# epochs = epochs[:3]\n",
    "\n",
    "score_df = []\n",
    "\n",
    "for short in [False,True]:\n",
    "    if short:\n",
    "        smth_mua = sess.mua.get_smoothed(sigma=0.02)\n",
    "        pbe_epochs = detect_pbe_epochs(smth_mua,duration=(0.08,0.5))\n",
    "    else:\n",
    "        pbe_epochs = decode_epochs\n",
    "\n",
    "    starts = pbe_epochs.starts\n",
    "    print(len(starts))\n",
    "\n",
    "    for e in epochs.itertuples():\n",
    "        pbe_bool = (starts > e.start) & (starts < e.stop)\n",
    "        e_epochs = pbe_epochs[pbe_bool]\n",
    "\n",
    "        decode = Decode1d(\n",
    "            neurons=pf_neurons,\n",
    "            ratemap=pf,\n",
    "            epochs=e_epochs,\n",
    "            bin_size=0.02,\n",
    "            # score_method=\"wcorr\",\n",
    "            score_method=\"radon_transform\",\n",
    "            radon_kw=dict(nlines=7000, decode_margin=16),\n",
    "            n_jobs=6,\n",
    "        )\n",
    "        score_df.append(pd.DataFrame(dict(short=short, zt=e.label, score=decode.score)))\n",
    "\n",
    "score_df = pd.concat(score_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots()\n",
    "\n",
    "sns.violinplot(data=score_df,x='zt',y='score',hue='short',split=True,inner='quartile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots()\n",
    "\n",
    "sns.violinplot(data=score_df,x='zt',y='score',hue='short',split=True,inner='quartile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test radon score on smoothed spiketrains\n",
    "- joblib parallel for radon transform uses a lot of memory (>30 GB) when used on smoothed spiketrain with gaussian kernel of sd 30 ms. Works fine for 5 ms and 10 ms gaussian kernels. Most likely it is because of spikecounts are float64 instead of integer.\n",
    "- It works fine for wcorr. For gaussian kernels 5,10 and 30 ms, changes in scores were observed across all epochs while keeping relative differences same. Compared to no smoothing, wcorr values decreased for 5 ms but increased for 10 and 30. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = subjects.sd.ratVday2[0]\n",
    "period = sess.paradigm[\"maze\"].flatten()\n",
    "\n",
    "neurons = sess.neurons_stable.get_neuron_type(['pyr','mua'])\n",
    "neurons = neurons[neurons.firing_rate<=10]\n",
    "maze_pos = sess.maze\n",
    "# maze_run= run_direction(maze_pos,min_distance=30,sigma=0.2,speed_thresh=(8,None))\n",
    "pf = Pf1D(\n",
    "    neurons=neurons,\n",
    "    position=sess.maze,\n",
    "    sigma=4,\n",
    "    grid_bin=2,\n",
    "    epochs=sess.maze_run[\"down\"],\n",
    "    frate_thresh=0.3,\n",
    ")\n",
    "pf_neurons = neurons.get_by_id(pf.neuron_ids)\n",
    "\n",
    "pbe_epochs = sess.pbe\n",
    "starts = pbe_epochs.starts\n",
    "epochs = sess.get_zt_epochs()\n",
    "epochs = epochs[:3]\n",
    "\n",
    "score_df = []\n",
    "\n",
    "# memory error for 0.03 in randon transform\n",
    "for sig in [None,0.005,0.01]:\n",
    "    print(sig)\n",
    "    for e in epochs.itertuples():\n",
    "        pbe_bool = (starts > e.start) & (starts < e.stop)\n",
    "        e_epochs = pbe_epochs[pbe_bool]\n",
    "\n",
    "        decode = Decode1d(\n",
    "            neurons=pf_neurons,\n",
    "            ratemap=pf,\n",
    "            epochs=e_epochs,\n",
    "            bin_size=0.02,\n",
    "            # sigma=sig, # has been removed from Decode1d\n",
    "            # score_method=\"wcorr\",\n",
    "            score_method=\"radon_transform\",\n",
    "            radon_kw=dict(nlines=7000, decode_margin=16),\n",
    "            n_jobs=6,\n",
    "        )\n",
    "        score_df.append(pd.DataFrame(dict(sigma=str(sig), zt=e.label, score=decode.score)))\n",
    "\n",
    "score_df = pd.concat(score_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots()\n",
    "\n",
    "sns.violinplot(data=score_df,x='zt',y='score',hue='sigma',inner='quartile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test radon/wcorr scores with and without merging PBEs\n",
    "- While visualizing the posterior maps, some replay trajectory appeared to continue over multiple events. Some of these 'continuing' trajectory events were temporally close to each other. So here I tested if I merge close PBE events such ones which are 30 or 50 ms apart. It had marginal effect on total disribution, as number of such merges were very few.\n",
    "- Even though the increase was very small, it was the most for MAZE epoch.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = subjects.sd.ratRday2[0]\n",
    "period = sess.paradigm[\"maze\"].flatten()\n",
    "\n",
    "neurons = sess.neurons_stable.get_neuron_type(['pyr','mua'])\n",
    "maze_pos = sess.maze\n",
    "# maze_run= run_direction(maze_pos,min_distance=30,sigma=0.2,speed_thresh=(8,None))\n",
    "pf = Pf1D(\n",
    "    neurons=neurons,\n",
    "    position=sess.maze,\n",
    "    sigma=4,\n",
    "    grid_bin=2,\n",
    "    epochs=sess.maze_run[\"up\"],\n",
    "    frate_thresh=0.3,\n",
    ")\n",
    "pf_neurons = neurons.get_by_id(pf.neuron_ids)\n",
    "og_tc = pf.tuning_curves.copy()\n",
    "norm_tc = min_max_scaler(og_tc) \n",
    "\n",
    "decode_epochs = sess.pbe\n",
    "epochs = sess.get_zt_epochs()\n",
    "# epochs = epochs[:3]\n",
    "\n",
    "score_df = []\n",
    "\n",
    "for merge in [False,True]:\n",
    "    if merge:\n",
    "        pbe_epochs = decode_epochs.merge(dt=0.05)\n",
    "    else:\n",
    "        pbe_epochs = decode_epochs\n",
    "\n",
    "    starts = pbe_epochs.starts\n",
    "    print(len(starts))\n",
    "\n",
    "    for e in epochs.itertuples():\n",
    "        pbe_bool = (starts > e.start) & (starts < e.stop)\n",
    "        e_epochs = pbe_epochs[pbe_bool]\n",
    "\n",
    "        decode = Decode1d(\n",
    "            neurons=pf_neurons,\n",
    "            ratemap=pf,\n",
    "            epochs=e_epochs,\n",
    "            bin_size=0.02,\n",
    "            score_method=\"wcorr\",\n",
    "            # score_method=\"radon_transform\",\n",
    "            # radon_kw=dict(nlines=7000, decode_margin=16),\n",
    "            n_jobs=6,\n",
    "        )\n",
    "        score_df.append(pd.DataFrame(dict(merge=merge, zt=e.label, score=decode.score)))\n",
    "\n",
    "score_df = pd.concat(score_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots()\n",
    "\n",
    "sns.violinplot(data=score_df,x='zt',y='score',hue='merge',split=True,inner='quartile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if various measures for jump distance are calculated correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = subjects.sd.ratNday1[0]\n",
    "\n",
    "neurons = sess.neurons_stable.get_neuron_type([\"pyr\", \"mua\"])\n",
    "neurons = neurons[neurons.firing_rate <= 10]\n",
    "maze_pos = sess.maze\n",
    "\n",
    "pf = Pf1D(\n",
    "    neurons=neurons,\n",
    "    position=sess.maze,\n",
    "    sigma=4,\n",
    "    grid_bin=2,\n",
    "    epochs=sess.maze_run[\"down\"],\n",
    "    frate_thresh=0.3,\n",
    ")\n",
    "pf_neurons = neurons.get_by_id(pf.neuron_ids)\n",
    "\n",
    "pbe_epochs = sess.pbe\n",
    "starts = pbe_epochs.starts\n",
    "\n",
    "period = sess.paradigm[\"maze\"].flatten()\n",
    "pbe_bool = (starts > period[0]) & (starts < period[1])\n",
    "e_epochs = pbe_epochs[pbe_bool]\n",
    "\n",
    "decode = Decode1d(\n",
    "    neurons=pf_neurons, ratemap=pf, epochs=e_epochs, bin_size=0.02, n_jobs=6\n",
    ")\n",
    "wcorr1,mean_jd = decode.get_wcorr(jump_stat='mean')\n",
    "wcorr2,max_jd = decode.get_wcorr(jump_stat='max')\n",
    "wcorr3,median_jd = decode.get_wcorr(jump_stat='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test jump distance calculation for shuffles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = subjects.sd.ratRday2[0]\n",
    "period = sess.paradigm[\"maze\"].flatten()\n",
    "\n",
    "neurons = sess.neurons_stable.get_neuron_type([\"pyr\", \"mua\"])\n",
    "neurons = neurons[neurons.firing_rate <= 10]\n",
    "maze_pos = sess.maze\n",
    "\n",
    "pf = Pf1D(\n",
    "    neurons=neurons,\n",
    "    position=sess.maze,\n",
    "    sigma=4,\n",
    "    grid_bin=2,\n",
    "    epochs=sess.maze_run[\"down\"],\n",
    "    frate_thresh=0.3,\n",
    ")\n",
    "pf_neurons = neurons.get_by_id(pf.neuron_ids)\n",
    "\n",
    "pbe_epochs = sess.pbe\n",
    "starts = pbe_epochs.starts\n",
    "epochs = sess.get_zt_epochs()\n",
    "epochs = epochs[:3]\n",
    "\n",
    "score_df = []\n",
    "\n",
    "pbe_bool = (starts > period[0]) & (starts < period[1])\n",
    "e_epochs = pbe_epochs[pbe_bool]\n",
    "\n",
    "decode = Decode1d(\n",
    "    neurons=pf_neurons, ratemap=pf, epochs=e_epochs, bin_size=0.02, n_jobs=6\n",
    ")\n",
    "wcorr,jd = decode.get_wcorr(jump_distance=True)\n",
    "# radon_score,vel,intercept = decode.get_radon_transform(nlines=5000,margin=16)\n",
    "# shuffled_measures = decode.get_shuffled_wcorr(n_iter=100,jump_distance=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots()\n",
    "\n",
    "jd_bins = np.linspace(0,1,100)\n",
    "shuffle_jd = shuffled_measures[:,0,:].flatten()\n",
    "\n",
    "hist_shuffle = np.histogram(np.abs(shuffle_jd),jd_bins)[0]\n",
    "hist_events = np.histogram(np.abs(wcorr),jd_bins)[0]\n",
    "ax.plot(hist_shuffle/hist_shuffle.sum())\n",
    "ax.plot(hist_events/hist_events.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test continuous trajectory length with respect to shuffles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from replay_funcs import get_max_length\n",
    "from neuropy.analyses.decoders import column_shift\n",
    "\n",
    "sess = subjects.nsd.ratNday2[0]\n",
    "replay_df = sess.replay_filtered.to_dataframe()\n",
    "posteriors = replay_df['posterior'].to_list()\n",
    "\n",
    "arr = posteriors[2557]\n",
    "length = get_max_length(arr)\n",
    "\n",
    "sh_lengths = np.zeros(1000) \n",
    "for i in range(1000):\n",
    "    sh_lengths[i] = get_max_length(column_shift(arr))\n",
    "\n",
    "bins = np.arange(11)\n",
    "hist_sh = np.histogram(sh_lengths,bins)[0]\n",
    "\n",
    "_,axs = plt.subplots(1,2)\n",
    "axs[0].pcolormesh(arr)\n",
    "axs[1].plot(bins[:-1],hist_sh)\n",
    "axs[1].axvline(length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scratch code for pooled randon transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = [_.shape[1] for _ in decode.posterior[:60]]\n",
    "post = np.hstack(decode.posterior[:60])\n",
    "arr = post\n",
    "nlines = 10000\n",
    "dt = 1\n",
    "dx = 1\n",
    "neighbours = 1\n",
    "t = np.concatenate([np.arange(0, _) for _ in nbins])\n",
    "max_t = max(nbins)\n",
    "nt = len(t)\n",
    "tmid = (nt + 1) / 2 - 1\n",
    "\n",
    "pos = np.arange(arr.shape[0])\n",
    "npos = len(pos)\n",
    "pmid = (npos + 1) / 2 - 1\n",
    "\n",
    "# using convolution to sum neighbours\n",
    "arr = np.apply_along_axis(\n",
    "    np.convolve, axis=0, arr=arr, v=np.ones(2 * neighbours + 1), mode=\"same\"\n",
    ")\n",
    "\n",
    "# exclude stationary events by choosing phi little below 90 degree\n",
    "# NOTE: angle of line is given by (90-phi), refer Kloosterman 2012\n",
    "phi = np.random.uniform(low=-np.pi / 2, high=np.pi / 2, size=nlines)\n",
    "diag_len = np.sqrt((max_t - 1) ** 2 + (npos - 1) ** 2)\n",
    "rho = np.random.uniform(low=-diag_len / 2, high=diag_len / 2, size=nlines)\n",
    "\n",
    "rho_mat = np.tile(rho, (nt, 1)).T\n",
    "phi_mat = np.tile(phi, (nt, 1)).T\n",
    "t_mat = np.tile(t, (nlines, 1))\n",
    "posterior = np.zeros((nlines, nt))\n",
    "\n",
    "y_line = ((rho_mat - (t_mat - tmid) * np.cos(phi_mat)) / np.sin(phi_mat)) + pmid\n",
    "y_line = np.rint(y_line).astype(\"int\")\n",
    "\n",
    "# if line falls outside of array in a given bin, replace that with median posterior value of that bin across all positions\n",
    "t_out = np.where((y_line < 0) | (y_line > npos - 1))\n",
    "t_in = np.where((y_line >= 0) & (y_line <= npos - 1))\n",
    "posterior[t_out] = np.median(arr[:, t_out[1]], axis=0)\n",
    "posterior[t_in] = arr[y_line[t_in], t_in[1]]\n",
    "\n",
    "# old_settings = np.seterr(all=\"ignore\")\n",
    "posterior_mean = np.nanmean(posterior, axis=1)\n",
    "\n",
    "best_line = np.argmax(posterior_mean)\n",
    "score = posterior_mean[best_line]\n",
    "best_phi, best_rho = phi[best_line], rho[best_line]\n",
    "time_mid, pos_mid = nt * dt / 2, npos * dx / 2\n",
    "\n",
    "velocity = dx / (dt * np.tan(best_phi))\n",
    "intercept = (\n",
    "    (dx * time_mid) / (dt * np.tan(best_phi))\n",
    "    + (best_rho / np.sin(best_phi)) * dx\n",
    "    + pos_mid\n",
    ")\n",
    "# np.seterr(**old_settings)\n",
    "\n",
    "# return score, -velocity, intercept\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal order of spiking activity compared between every pair of PBE (NSD vs SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = subjects.pf_sess()\n",
    "\n",
    "pair_corr = []\n",
    "for s, sess in enumerate(sessions):\n",
    "\n",
    "    neurons = sess.neurons_stable.get_neuron_type(\"pyr\")\n",
    "    pbe_all = sess.pbe.flatten()\n",
    "    n_spikes = [np.histogram(_,bins=pbe_all)[0][::2] for _ in neurons.spiketrains]\n",
    "    spk_bool = (np.array(n_spikes)>0).sum(axis=0)\n",
    "    good_pbes = spk_bool>5\n",
    "    pbe_all = sess.pbe[good_pbes]\n",
    "\n",
    "    epochs = sess.get_zt_epochs()\n",
    "    epochs = epochs['2.5-5']\n",
    "    for e in epochs.itertuples():\n",
    "\n",
    "        pbe = pbe_all.time_slice(e.start, e.stop)\n",
    "        pbe_bins = pbe.flatten()\n",
    "        pbe_durs = pbe.durations\n",
    "        pbe_starts = pbe.starts\n",
    "\n",
    "        mean_spike = np.array(\n",
    "            [\n",
    "                stats.binned_statistic(_, _, bins=pbe_bins,statistic='median')[0][::2]\n",
    "                for _ in neurons.spiketrains\n",
    "            ]\n",
    "        )\n",
    "        norm_spike = (mean_spike - pbe_starts[np.newaxis, :]) / pbe_durs\n",
    "        df = pd.DataFrame(data=norm_spike)\n",
    "        pbe_corr = np.asarray(df.corr(method='spearman'))\n",
    "        np.fill_diagonal(pbe_corr,0)\n",
    "        pbe_corr_flat = pbe_corr[np.tril_indices_from(pbe_corr,k=-1)]\n",
    "        pbe_corr_flat = pbe_corr_flat[~np.isnan(pbe_corr_flat)]\n",
    "    \n",
    "        pair_corr.append(pd.DataFrame(dict(corr=pbe_corr_flat,zt=e.label,grp=sess.tag)))\n",
    "\n",
    "pair_corr = pd.concat(pair_corr,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy import plotting\n",
    "_,axs = plt.subplots(1,4)\n",
    "\n",
    "for i,p in enumerate([0,116,1331,1320]):\n",
    "    e = pbe[p].flatten()\n",
    "    plotting.plot_raster(neurons.time_slice(*e),ax=axs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n",
    "_,ax = plt.subplots()\n",
    "\n",
    "# mat = pbe_corr.copy()\n",
    "# mat[np.isnan(mat)] = 0\n",
    "# mat = gaussian_filter(mat,sigma=2)\n",
    "sns.violinplot(data=pair_corr,x='zt',y='corr',hue='grp',split=True)\n",
    "# ax.imshow(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test different shuffling procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.decoders import wcorr\n",
    "import pingouin as pg\n",
    "\n",
    "sessions = subjects.nsd.ratVday1\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "def rand_circ_shift(arr):\n",
    "    ny,nx = arr.shape[0],arr.shape[1]\n",
    "    shifts = rng.integers(-ny,ny,nx,endpoint=True)\n",
    "    rand_arr = [np.roll(arr[:,i],shifts[i]) for i in range(nx)]\n",
    "    return np.array(rand_arr).T\n",
    "\n",
    "dcorr_df = []\n",
    "for s, sess in enumerate(sessions):\n",
    "\n",
    "    neurons = sess.neurons_stable.get_neuron_type('pyr') \n",
    "    # spikes = np.concatenate(neurons.spiketrains)\n",
    "    pbe_epochs = sess.pbe.flatten()\n",
    "\n",
    "    # fire_bool = [np.all(np.histogram(spikes,bins=np.arange(_[0],_[1]))[0]>0)]\n",
    "    n_spikes = [np.histogram(_,bins=pbe_epochs)[0][::2] for _ in neurons.spiketrains]\n",
    "    fire_bool = (np.array(n_spikes)>0).sum(axis=0)>5\n",
    "\n",
    "    starts = sess.replay_pbe.starts[fire_bool]\n",
    "    up_posterior = sess.replay_pbe.metadata[\"up_posterior\"]\n",
    "    up_posterior = [up_posterior[i] for i in range(len(fire_bool)) if fire_bool[i]]\n",
    "    shuffles = sess.replay_pbe.metadata['up_shuffle_score'][:,fire_bool]\n",
    "\n",
    "\n",
    "    # evt_indx = [3298,3800]\n",
    "    evt_indx = rng.choice(len(starts),5)\n",
    "\n",
    "    _,axs = plt.subplots(len(evt_indx),2,**dict(constrained_layout=True))\n",
    "\n",
    "    bins = np.arange(-1,1,0.01)\n",
    "    for i,indx in enumerate(evt_indx):  \n",
    "        arr=up_posterior[indx]\n",
    "        corr = wcorr(arr)\n",
    "        rand_corr = [wcorr(rand_circ_shift(arr)) for _ in range(1000)]\n",
    "\n",
    "        pos_dist = np.histogram(rand_corr,bins)[0]\n",
    "        id_dist = np.histogram(shuffles[:,indx],bins)[0]\n",
    "\n",
    "        axs[i,0].pcolormesh(arr,cmap='binary')\n",
    "        axs[i,0].set_title(indx)\n",
    "        axs[i,1].plot(bins[:-1],pos_dist,color='r')\n",
    "        axs[i,1].plot(bins[:-1],id_dist,color='g')\n",
    "        axs[i,1].axvline(corr,color='k')\n",
    "        axs[i,1].set_title(corr.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,2,3,4]\n",
    "\n",
    "a[[True,False,True,False]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test simple linear regression for posteriors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.decoders import wcorr\n",
    "import pingouin as pg\n",
    "\n",
    "sessions = subjects.pf_sess()\n",
    "\n",
    "def linfit(arr):\n",
    "    # pos = np.argmax(arr,axis=0)*2\n",
    "    pos_mat = np.tile(np.arange(arr.shape[0])[:,np.newaxis],(1,arr.shape[1]))\n",
    "    pos = np.average(pos_mat,axis=0,weights=arr)*2\n",
    "    t = np.arange(arr.shape[1])*0.02\n",
    "    fit = stats.linregress(t,pos)\n",
    "    ss_res = ((pos - (fit.slope*t + fit.intercept))**2).sum()\n",
    "    ss_tot = ((pos - pos.mean())**2).sum()\n",
    "    r2 = 1 - (ss_res/ss_tot)\n",
    "    return fit.rvalue, r2\n",
    "\n",
    "\n",
    "score_df = []\n",
    "for s, sess in enumerate(sessions):\n",
    "\n",
    "    starts = sess.replay_wcorr_mua.starts\n",
    "    up_posterior = sess.replay_pbe.metadata[\"up_posterior\"]\n",
    "    down_posterior = sess.replay_pbe.metadata[\"down_posterior\"]\n",
    "    shuffles = sess.replay_pbe.metadata['up_shuffle_score']\n",
    "\n",
    "    up_corr,up_r2 = np.array([linfit(_) for _ in up_posterior]).T\n",
    "    down_corr,down_r2 = np.array([linfit(_) for _ in down_posterior]).T\n",
    "\n",
    "    best_bool = up_r2 > down_r2\n",
    "    corr = np.zeros(len(starts))\n",
    "    corr[best_bool] = up_corr[best_bool]\n",
    "    corr[~best_bool] = -down_corr[~best_bool]\n",
    "\n",
    "    r2 = np.zeros(len(starts))\n",
    "    r2[best_bool] = up_r2[best_bool]\n",
    "    r2[~best_bool] = down_r2[~best_bool]\n",
    "\n",
    "\n",
    "\n",
    "    epochs = sess.get_zt_epochs()\n",
    "    pre = epochs['PRE'].flatten()\n",
    "    pre_indx = (starts > pre[0]) & (starts < pre[1])\n",
    "    mean_pre = r2[pre_indx].mean()\n",
    "\n",
    "    for i, e in enumerate(epochs.itertuples()):\n",
    "        indx = (starts > e.start) & (starts < e.stop)\n",
    "\n",
    "        df = pd.DataFrame(\n",
    "            dict(\n",
    "                zt=e.label,\n",
    "                corr = np.abs(corr[indx]),\n",
    "                r2=r2[indx]/mean_pre,\n",
    "                session=s,\n",
    "                grp=sess.tag,\n",
    "            )\n",
    "        )\n",
    "        score_df.append(df)\n",
    "    \n",
    "score_df = pd.concat(score_df,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots()\n",
    "\n",
    "sns.violinplot(data= score_df,x='zt',y='corr',hue='grp',split=True,inner='quartile',scale_hue=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cce1618081139d19eb1ee8d40815d94a2de4f62e1efb20d9406ddb60628c36ae"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('data_analysis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
