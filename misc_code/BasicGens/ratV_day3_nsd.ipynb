{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RatV Day3NSD recording info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: /data/Clustering/sessions/RatV/RatVDay3NSD/RatV_Day3NSD_2021-10-07_08-10-12.xml \n",
      "# channels: 259\n",
      "sampling rate: 30000\n",
      "lfp Srate (downsampled): 1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subjects\n",
    "\n",
    "sess = subjects.nsd.ratVday3[0] # add your subject session\n",
    "print(sess.recinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animal metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core import animal\n",
    "\n",
    "d = {'name':'hello','tag':'ser'}\n",
    "\n",
    "an = animal.Animal(d) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probe configuration\n",
    "- Add text for details about the probes that were used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple 8 shank probe with same layout across all shanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from neuropy.core import Shank, Probe, ProbeGroup\n",
    "from neuropy.plotting import plot_probe\n",
    "\n",
    "shanks = []\n",
    "channel_groups = sess.recinfo.channel_groups\n",
    "for i in range(8):\n",
    "\n",
    "    shank = Shank.auto_generate(\n",
    "        columns=2,\n",
    "        contacts_per_column=8,\n",
    "        xpitch=15,\n",
    "        ypitch=30,\n",
    "        y_shift_per_column=[0, -15],\n",
    "        channel_id=np.append(\n",
    "            channel_groups[i][::2][::-1], channel_groups[i][1::2][::-1]\n",
    "        ),\n",
    "    )\n",
    "    shanks.append(shank)\n",
    "    shank.set_disconnected_channels(sess.recinfo.skipped_channels)\n",
    "\n",
    "probe1 = Probe(shanks)\n",
    "\n",
    "shanks = []\n",
    "for i in range(8,16):\n",
    "\n",
    "    shank = Shank.auto_generate(\n",
    "        columns=2,\n",
    "        contacts_per_column=8,\n",
    "        xpitch=15,\n",
    "        ypitch=30,\n",
    "        y_shift_per_column=[0, -15],\n",
    "        channel_id=np.append(\n",
    "            channel_groups[i][::2][::-1], channel_groups[i][1::2][::-1]\n",
    "        ),\n",
    "    )\n",
    "    shanks.append(shank)\n",
    "    shank.set_disconnected_channels(sess.recinfo.skipped_channels)\n",
    "\n",
    "probe2 = Probe(shanks)\n",
    "probe2.move((probe1.x_max+500,0))\n",
    "\n",
    "prbgrp = ProbeGroup()\n",
    "prbgrp.add_probe(probe1)\n",
    "prbgrp.add_probe(probe2)\n",
    "\n",
    "prbgrp.save(sess.filePrefix.with_suffix(\".probegroup.npy\"))\n",
    "plot_probe(prbgrp,channel_id=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Probemap for spyking circus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils import probe_util\n",
    "\n",
    "probe_util.write_spyking_circus(\n",
    "    file=sess.filePrefix.with_suffix(\".prb\"), prb=sess.probegroup, combine_shanks=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental paradigm\n",
    "A typical experiment involves multiple epochs such pre sleep, running on track and then another sleep epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neuropy.core import Epoch\n",
    "\n",
    "datetime_data = pd.read_csv(sess.filePrefix.with_suffix('.datetime.csv'))\n",
    "durations = datetime_data.nFrames/sess.recinfo.dat_sampling_rate\n",
    "epochs = pd.DataFrame(\n",
    "    {\n",
    "        \"start\": [0,10136,13354,45527],\n",
    "        \"stop\": [10135,13353,45526,47948],\n",
    "        \"label\": [\"pre\", \"maze\",'post','re-maze'],\n",
    "    }\n",
    ")\n",
    "\n",
    "paradigm = Epoch(epochs=epochs)\n",
    "paradigm.save(sess.filePrefix.with_suffix(\".paradigm.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durations.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paradigm.durations/3600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neurons\n",
    "- import spiketrains from Phy\n",
    "- estimate neuron types such pyramidal, interneuron etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing spiketrains from Phy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.io import PhyIO\n",
    "from neuropy.core import Neurons\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "cluster_path = Path(\n",
    "    \"/home/bapung/Documents/ClusteringHub/spykcirc/RatV/RatVDay3NSD/RatV_Day3NSD_2021-10-07_08-10-12-1.GUI\"\n",
    ")\n",
    "chan_grps = sess.recinfo.channel_groups\n",
    "phy_data = PhyIO(cluster_path)\n",
    "spiketrains = phy_data.spiketrains\n",
    "peak_chans = phy_data.peak_channels\n",
    "waveforms = phy_data.waveforms\n",
    "shank_id = sess.probegroup.get_shank_id_for_channels(peak_chans)\n",
    "\n",
    "neuron_type_id = phy_data.cluster_info.q.values\n",
    "neuron_type = np.ones(len(neuron_type_id), dtype=\"U5\")\n",
    "neuron_type[neuron_type_id < 4] = \"pyr\"\n",
    "neuron_type[neuron_type_id == 6] = \"mua\"\n",
    "neuron_type[neuron_type_id == 8] = \"inter\"\n",
    "\n",
    "\n",
    "neurons = Neurons(\n",
    "    np.array(spiketrains, dtype=object),\n",
    "    t_stop=sess.eegfile.duration,\n",
    "    sampling_rate=phy_data.sampling_rate,\n",
    "    peak_channels=peak_chans,\n",
    "    waveforms=np.array(waveforms, dtype=\"object\"),\n",
    "    neuron_type=neuron_type,\n",
    "    shank_ids=np.array(shank_id).astype(int),\n",
    "    metadata={'cluster_path':str(cluster_path)}\n",
    ")\n",
    "\n",
    "neurons.save(sess.filePrefix.with_suffix(\".neurons\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from neuropy.plotting import plot_raster\n",
    "\n",
    "plot_raster(neurons,color='jet',add_vert_jitter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BinnedSpiketrain and Mua objects using Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mua =sess.neurons.get_mua()\n",
    "mua.save(sess.filePrefix.with_suffix(\".mua.npy\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy import plotting\n",
    "smth_mua = sess.mua.get_smoothed(sigma=0.02)\n",
    "plotting.plot_mua(smth_mua)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect epochs\n",
    "Here we will various types of epochs which typical for hippocampal recordings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifacts\n",
    "A typical session will have some artifacts that may negatively influence many analyses. Using a simple zscore measure, we can identify epochs where signal is above some threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy import analyses \n",
    "\n",
    "signal = sess.eegfile.get_signal([1,192])\n",
    "artifact_epochs = analyses.detect_artifact_epochs(signal, thresh=7,edge_cutoff=2)\n",
    "artifact_epochs.save(sess.filePrefix.with_suffix(\".artifact.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from neuropy import plotting\n",
    "signal = sess.eegfile.get_signal([1])\n",
    "plotting.plot_artifact_epochs(sess.artifact, signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export for spyking circus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.io import SpykingCircusIO\n",
    "\n",
    "SpykingCircusIO.write_epochs(sess.filePrefix.with_suffix('.dead'),sess.artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ripple\n",
    "To detect ripples one also needs probegroup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses import oscillations\n",
    "\n",
    "signal = sess.eegfile.get_signal()\n",
    "ripple_epochs = oscillations.detect_ripple_epochs(\n",
    "    signal, sess.probegroup, freq_band=(125,250),ignore_epochs=sess.artifact\n",
    ")\n",
    "ripple_epochs.save(sess.filePrefix.with_suffix(\".ripple.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses import detect_pbe_epochs\n",
    "\n",
    "pbe = detect_pbe_epochs(smth_mua)\n",
    "pbe.filename = sess.filePrefix.with_suffix('.pbe')\n",
    "pbe.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign position data\n",
    "- Position aligned using TTL signal in .dat/.eeg file (3 May 2022)\n",
    "- Position cell has now been moved to hfuncs (4 May 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.io import OptitrackIO\n",
    "from neuropy.core import Position\n",
    "from pathlib import Path\n",
    "\n",
    "opti_folder = sess.filePrefix.parent / 'position'\n",
    "opti_data = OptitrackIO(dirname=opti_folder,scale_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfuncs import position_alignment\n",
    "\n",
    "ttl_signal = sess.eegfile.get_signal(258)\n",
    "datetime_csv = sess.filePrefix.with_suffix('.datetime.csv')\n",
    "position = position_alignment(opti_data,datetime_csv,ttl_signal,fs=30000)\n",
    "# position.save(sess.filePrefix.with_suffix('.position'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linearize position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils import position_util\n",
    "\n",
    "for e in ['maze','re-maze']:\n",
    "    maze = sess.paradigm[e].flatten()\n",
    "    maze_pos = sess.position.time_slice(maze[0],maze[1])\n",
    "    linear_pos = position_util.linearize_position(maze_pos)\n",
    "    e = e.replace('-','')\n",
    "    linear_pos.save(sess.filePrefix.with_suffix(f'.{e}.linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(maze_pos.time,maze_pos.y)\n",
    "plt.plot(linear_pos.time,linear_pos.x)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cce1618081139d19eb1ee8d40815d94a2de4f62e1efb20d9406ddb60628c36ae"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('data_analysis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
