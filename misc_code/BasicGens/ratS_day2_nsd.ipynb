{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RatS Day2NSD recording info\n",
    "- No timestamps were deleted after concatenating .dat files from various folders of open-ephys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: /data/Clustering/sessions/RatS/Day2NSD/RatS-Day2NSD-2020-11-27_10-22-29.xml \n",
      "# channels: 195\n",
      "sampling rate: 30000\n",
      "lfp Srate (downsampled): 1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import subjects\n",
    "\n",
    "sess = subjects.nsd.ratSday2[0]\n",
    "print(sess.recinfo)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set probe configuration\n",
    "- RatS_Day2NSD has two probes: 64chan-6shanks cambridge neurotech and 128chan-8shanks diagnostic biochips.\n",
    "- Channel 51 on 64chan probe is skull eeg channel located above prefrontal cortex. This channel was a little buggy, the signal quality kept varying.\n",
    "- The cambridge neurotech probe also has accelerometer data in channels: 192, 193, 194"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from neuropy.core import Shank, Probe, ProbeGroup\n",
    "from neuropy.plotting import plot_probe\n",
    "\n",
    "shanks = []\n",
    "channel_groups = sess.recinfo.channel_groups\n",
    "badchans = sess.recinfo.skipped_channels\n",
    "\n",
    "#--- cambridge probe -----------\n",
    "for i in range(6):\n",
    "    chans = channel_groups[i]\n",
    "\n",
    "    if len(chans)==10:\n",
    "        n_cont = 5\n",
    "        y_shift = [0,7.5]\n",
    "    if len(chans)==11:\n",
    "        n_cont = [6,5]\n",
    "        y_shift = [0,7.5]\n",
    "    if len(chans)==9:\n",
    "        n_cont = [5,4]\n",
    "        y_shift = [0,7,5]\n",
    "\n",
    "    shank = Shank.auto_generate(\n",
    "        columns=2,\n",
    "        contacts_per_column=n_cont,\n",
    "        xpitch=16.5,\n",
    "        ypitch=15,\n",
    "        y_shift_per_column=y_shift,\n",
    "        channel_id=np.append(\n",
    "            channel_groups[i][1::2][::-1], channel_groups[i][::2][::-1]\n",
    "        ),\n",
    "    )\n",
    "    shank.set_disconnected_channels(sess.recinfo.skipped_channels)\n",
    "    shanks.append(shank)\n",
    "\n",
    "probe1 = Probe(shanks)\n",
    "\n",
    "shanks = []\n",
    "for i in range(6,14):\n",
    "\n",
    "    shank = Shank.auto_generate(\n",
    "        columns=2,\n",
    "        contacts_per_column=8,\n",
    "        xpitch=15,\n",
    "        ypitch=15,\n",
    "        y_shift_per_column=[0, -7.5],\n",
    "        channel_id=np.append(\n",
    "            channel_groups[i][::2][::-1], channel_groups[i][1::2][::-1]\n",
    "        ),\n",
    "    )\n",
    "    shank.set_disconnected_channels(sess.recinfo.skipped_channels)\n",
    "    shanks.append(shank)\n",
    "\n",
    "\n",
    "probe2 = Probe(shanks)\n",
    "probe2.move((probe1.x_max+500,0))\n",
    "\n",
    "prbgrp = ProbeGroup()\n",
    "prbgrp.add_probe(probe1)\n",
    "prbgrp.add_probe(probe2)\n",
    "\n",
    "prbgrp.filename = sess.filePrefix.with_suffix(\".probegroup.npy\")\n",
    "# prbgrp.save()\n",
    "plot_probe(prbgrp,channel_id=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create epochs for your experimental paradigm\n",
    "- RatS_Day2NSD had digitized noise in first ~2 hours of pre sleep. I somehow didn't notice that while recording, so the pre sleep is a lot shorter comapred to other animals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.paradigm.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neuropy.core import Epoch\n",
    "\n",
    "epochs = pd.DataFrame(\n",
    "    {\n",
    "        \"start\": [0, 2360, 6033, 36902],\n",
    "        \"stop\": [2358, 6031, 36899, 40233],\n",
    "        \"label\": [\"pre\", \"maze\", \"post\", \"re-maze\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "paradigm = Epoch(epochs=epochs)\n",
    "paradigm.filename = sess.filePrefix.with_suffix(\".paradigm.npy\")\n",
    "# paradigm.save()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect epochs\n",
    "Here we will various types of epochs which typical for hippocampal recordings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifacts epochs\n",
    "A typical session will have some artifacts that may negatively influence many analyses. Using a simple zscore measure, we can identify epochs where signal is above some threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/Clustering/sessions/RatS/Day2NSD/RatS-Day2NSD-2020-11-27_10-22-29.artifact.npy saved\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "signal should only have one trace",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m artifact_epochs\u001b[39m.\u001b[39mmetadata \u001b[39m=\u001b[39m metadata\n\u001b[1;32m     10\u001b[0m artifact_epochs\u001b[39m.\u001b[39msave(sess\u001b[39m.\u001b[39mfilePrefix\u001b[39m.\u001b[39mwith_suffix(\u001b[39m\"\u001b[39m\u001b[39m.artifact.npy\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m---> 11\u001b[0m plotting\u001b[39m.\u001b[39mplot_artifact_epochs(artifact_epochs, signal)\n",
      "File \u001b[0;32m~/Documents/Codes/NeuroPy/neuropy/plotting/epochs.py:219\u001b[0m, in \u001b[0;36mplot_artifact_epochs\u001b[0;34m(epochs, signal, downsample_factor)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_artifact_epochs\u001b[39m(epochs: Epoch, signal: Signal, downsample_factor: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m):\n\u001b[1;32m    202\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Plots artifact epochs against a signal\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \n\u001b[1;32m    204\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39m        [description]\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     \u001b[39massert\u001b[39;00m signal\u001b[39m.\u001b[39mn_channels \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msignal should only have one trace\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    221\u001b[0m     threshold \u001b[39m=\u001b[39m epochs\u001b[39m.\u001b[39mmetadata[\u001b[39m\"\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    222\u001b[0m     sig \u001b[39m=\u001b[39m signal\u001b[39m.\u001b[39mtraces\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "\u001b[0;31mAssertionError\u001b[0m: signal should only have one trace"
     ]
    }
   ],
   "source": [
    "from neuropy import analyses, plotting\n",
    "\n",
    "signal = sess.eegfile.get_signal([1, 189])\n",
    "artifact_epochs = analyses.detect_artifact_epochs(signal, thresh=10)\n",
    "metadata = artifact_epochs.metadata\n",
    "artifact_epochs = artifact_epochs.from_array(\n",
    "    artifact_epochs.starts - 0.2, artifact_epochs.stops + 0.2, \"artifact\"\n",
    ")\n",
    "artifact_epochs.metadata = metadata\n",
    "artifact_epochs.save(sess.filePrefix.with_suffix(\".artifact.npy\"))\n",
    "plotting.plot_artifact_epochs(artifact_epochs, signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2494.5536</td>\n",
       "      <td>2495.2824</td>\n",
       "      <td>artifact</td>\n",
       "      <td>0.7288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2521.7120</td>\n",
       "      <td>2522.3096</td>\n",
       "      <td>artifact</td>\n",
       "      <td>0.5976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2605.2784</td>\n",
       "      <td>2605.7680</td>\n",
       "      <td>artifact</td>\n",
       "      <td>0.4896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2617.3200</td>\n",
       "      <td>2617.7744</td>\n",
       "      <td>artifact</td>\n",
       "      <td>0.4544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2630.2232</td>\n",
       "      <td>2630.7456</td>\n",
       "      <td>artifact</td>\n",
       "      <td>0.5224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2685.1672</td>\n",
       "      <td>2687.3120</td>\n",
       "      <td>artifact</td>\n",
       "      <td>2.1448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2930.9016</td>\n",
       "      <td>2931.5312</td>\n",
       "      <td>artifact</td>\n",
       "      <td>0.6296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2960.5016</td>\n",
       "      <td>2963.1800</td>\n",
       "      <td>artifact</td>\n",
       "      <td>2.6784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3111.0912</td>\n",
       "      <td>3111.6640</td>\n",
       "      <td>artifact</td>\n",
       "      <td>0.5728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4410.7816</td>\n",
       "      <td>4411.1888</td>\n",
       "      <td>artifact</td>\n",
       "      <td>0.4072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4953.9176</td>\n",
       "      <td>4954.3464</td>\n",
       "      <td>artifact</td>\n",
       "      <td>0.4288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6268.4872</td>\n",
       "      <td>6268.9656</td>\n",
       "      <td>artifact</td>\n",
       "      <td>0.4784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19683.1080</td>\n",
       "      <td>19792.7384</td>\n",
       "      <td>artifact</td>\n",
       "      <td>109.6304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28676.0208</td>\n",
       "      <td>28699.4904</td>\n",
       "      <td>artifact</td>\n",
       "      <td>23.4696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>38550.8488</td>\n",
       "      <td>38551.5000</td>\n",
       "      <td>artifact</td>\n",
       "      <td>0.6512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40316.6984</td>\n",
       "      <td>40328.2384</td>\n",
       "      <td>artifact</td>\n",
       "      <td>11.5400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         start        stop     label  duration\n",
       "0    2494.5536   2495.2824  artifact    0.7288\n",
       "1    2521.7120   2522.3096  artifact    0.5976\n",
       "2    2605.2784   2605.7680  artifact    0.4896\n",
       "3    2617.3200   2617.7744  artifact    0.4544\n",
       "4    2630.2232   2630.7456  artifact    0.5224\n",
       "5    2685.1672   2687.3120  artifact    2.1448\n",
       "6    2930.9016   2931.5312  artifact    0.6296\n",
       "7    2960.5016   2963.1800  artifact    2.6784\n",
       "8    3111.0912   3111.6640  artifact    0.5728\n",
       "9    4410.7816   4411.1888  artifact    0.4072\n",
       "10   4953.9176   4954.3464  artifact    0.4288\n",
       "11   6268.4872   6268.9656  artifact    0.4784\n",
       "12  19683.1080  19792.7384  artifact  109.6304\n",
       "13  28676.0208  28699.4904  artifact   23.4696\n",
       "14  38550.8488  38551.5000  artifact    0.6512\n",
       "15  40316.6984  40328.2384  artifact   11.5400"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact_epochs.to_dataframe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ripple epochs\n",
    "To detect ripples one also needs probegroup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses import oscillations\n",
    "\n",
    "signal = sess.eegfile.get_signal()\n",
    "ripple_epochs = oscillations.detect_ripple_epochs(signal, sess.probegroup)\n",
    "ripple_epochs.filename = sess.filePrefix.with_suffix(\".ripple.npy\")\n",
    "ripple_epochs.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = sess.eegfile.get_signal(channel_id=[1, 2, 3, 4], t_start=1, t_stop=1.2)\n",
    "plotting.plot_signal_traces(signal)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing spiketrains from Phy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.io import PhyIO\n",
    "from neuropy.core import Neurons\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "cluster_path = Path(\n",
    "    \"/data/Clustering/sessions/RatS/Day2NSD/spykcirc/RatS-Day2NSD-2020-11-27_10-22-29-1.GUI\"\n",
    ")\n",
    "chan_grps = sess.recinfo.channel_groups\n",
    "phy_data = PhyIO(cluster_path)\n",
    "spiketrains = phy_data.spiketrains\n",
    "peak_chans = phy_data.peak_channels\n",
    "waveforms = phy_data.waveforms\n",
    "shank_id = sess.probegroup.get_shank_id_for_channels(peak_chans)\n",
    "\n",
    "# neuron_type_id = phy_data.cluster_info.q.values\n",
    "# neuron_type = np.ones(len(neuron_type_id), dtype=\"U5\")\n",
    "# neuron_type[neuron_type_id<4] = 'pyr'\n",
    "# neuron_type[neuron_type_id==6] = 'mua'\n",
    "# neuron_type[neuron_type_id==8] = 'inter'\n",
    "\n",
    "neurons = Neurons(\n",
    "    np.array(spiketrains, dtype=object),\n",
    "    t_stop=sess.eegfile.duration,\n",
    "    sampling_rate=phy_data.sampling_rate,\n",
    "    peak_channels=peak_chans,\n",
    "    waveforms=np.array(waveforms, dtype=\"object\"),\n",
    "    shank_ids=np.array(shank_id).astype(int),\n",
    "    neuron_type=sess.neurons.neuron_type,\n",
    ")\n",
    "\n",
    "neurons.filename = sess.filePrefix.with_suffix(\".neurons\")\n",
    "neurons.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from neuropy.plotting import plot_raster\n",
    "\n",
    "\n",
    "plt.plot(phy_data.peak_waveforms[0])\n",
    "plot_raster(neurons,color='jet',add_vert_jitter=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BinnedSpiketrain and Mua objects using Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mua = sess.neurons.get_mua()\n",
    "mua.filename = sess.filePrefix.with_suffix(\".mua.npy\")\n",
    "mua.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from neuropy import plotting\n",
    "smth_mua = sess.mua.get_smoothed(sigma=0.02)\n",
    "plotting.plot_mua(smth_mua)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses import detect_pbe_epochs\n",
    "\n",
    "pbe = detect_pbe_epochs(smth_mua)\n",
    "pbe.filename = sess.filePrefix.with_suffix(\".pbe\")\n",
    "pbe.save()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign position data\n",
    "- concatenated .dat file did not have any deleted timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.io import OptitrackIO\n",
    "from neuropy.core import Position\n",
    "from pathlib import Path\n",
    "\n",
    "opti_folder = sess.filePrefix.parent / \"position\"\n",
    "opti_data = OptitrackIO(dirname=opti_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti_data.datetime_starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ------- maze align corection ---------\n",
    "# Error estimated using TTL manually, spot-on with theta delta, This session does not have remaze position file\n",
    "t_error = [0, 0.1916, 0, 0, 0, 0]\n",
    "\n",
    "# ---- startimes of concatenated .dat files\n",
    "tracking_sRate = opti_data.sampling_rate\n",
    "rec_datetime = pd.read_csv(sess.filePrefix.with_suffix(\".datetime.csv\"))\n",
    "data_time = []\n",
    "for i, file_time in enumerate(rec_datetime[\"StartTime\"]):\n",
    "    sync_time = rec_datetime[\"sync_nframes\"][i] / rec_datetime[\"sync_rate\"][i]\n",
    "    tbegin = datetime.strptime(file_time, \"%Y-%m-%d_%H-%M-%S\") + pd.Timedelta(\n",
    "        t_error[i], unit=\"sec\"\n",
    "    )\n",
    "    nframes = rec_datetime[\"nFrames\"][i]\n",
    "    duration = pd.Timedelta(nframes / sess.recinfo.dat_sampling_rate, unit=\"sec\")\n",
    "    tend = tbegin + duration\n",
    "    trange = pd.date_range(\n",
    "        start=tbegin,\n",
    "        end=tend,\n",
    "        periods=int(duration.total_seconds() * tracking_sRate),\n",
    "    )\n",
    "    data_time.extend(trange)\n",
    "data_time = pd.to_datetime(data_time)\n",
    "\n",
    "# # ------- deleting intervals that were deleted from .dat file after concatenating\n",
    "# ndeletedintervals = rec_datetime.count()[\"deletedStart (minutes)\"]\n",
    "# for i in range(ndeletedintervals):\n",
    "#     tnoisy_begin = data_time[0] + pd.Timedelta(\n",
    "#         rec_datetime[\"deletedStart (minutes)\"][i], unit=\"m\"\n",
    "#     )\n",
    "#     tnoisy_end = data_time[0] + pd.Timedelta(\n",
    "#         rec_datetime[\"deletedEnd (minutes)\"][i], unit=\"m\"\n",
    "#     )\n",
    "\n",
    "#     del_index = np.where((data_time > tnoisy_begin) & (data_time < tnoisy_end))[\n",
    "#         0\n",
    "#     ]\n",
    "\n",
    "#     data_time = np.delete(data_time, del_index)\n",
    "\n",
    "x, y, z = opti_data.get_position_at_datetimes(data_time)\n",
    "traces = np.vstack((z, x, y))\n",
    "\n",
    "position = Position(traces=traces, t_start=0, sampling_rate=opti_data.sampling_rate)\n",
    "position.save(sess.filePrefix.with_suffix(\".position\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(opti_data.datetime_array,opti_data.z)\n",
    "plt.plot(sess.position.time, sess.position.x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linearize position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils import position_util\n",
    "from neuropy import plotting\n",
    "\n",
    "maze = sess.paradigm[\"maze\"].flatten()\n",
    "maze_pos = sess.position.time_slice(maze[0], maze[1])\n",
    "linear_pos = position_util.linearize_position(maze_pos)\n",
    "linear_pos.save(sess.filePrefix.with_suffix(\".maze.linear\"))\n",
    "\n",
    "\n",
    "fig = plotting.Fig(grid=(2, 4), size=(8.5, 5))\n",
    "\n",
    "ax = fig.subplot(fig.gs[0])\n",
    "ax.plot(maze_pos.x, maze_pos.y)\n",
    "\n",
    "ax = fig.subplot(fig.gs[0, 1:])\n",
    "ax.plot(maze_pos.time, maze_pos.x, \"r\")\n",
    "ax.plot(maze_pos.time, maze_pos.y, \"g\")\n",
    "ax.plot(linear_pos.time, linear_pos.x, \"k\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking position alignment with .dat file\n",
    "- Comparing theta power, speed and position to check if high theta periods are correlated with the speed of the animal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from neuropy.utils import signal_process\n",
    "\n",
    "signal = sess.eegfile.get_signal([158])\n",
    "spec = signal_process.SpectrogramBands(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(spec.time,spec.theta*1000)\n",
    "plt.plot(sess.position.time,sess.position.x)\n",
    "plt.plot(sess.position.time[1:],np.diff(sess.position.x)*100)\n",
    "# plt.xlim([1500,1600])\n",
    "plt.ylim([-400,400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "maze = sess.paradigm[\"maze1\"]\n",
    "\n",
    "pos_maze = sess.position.time_slice(maze[0], maze[1])\n",
    "t_spec = spec.time\n",
    "theta = spec.theta\n",
    "\n",
    "indices = (t_spec > maze[0]) & (t_spec < maze[1])\n",
    "t_spec_maze = t_spec[indices]\n",
    "theta_maze = theta[indices]\n",
    "theta_upsampled = np.interp(pos_maze.time[1:], t_spec_maze, theta_maze)\n",
    "\n",
    "xcorr = np.correlate(np.diff(pos_maze.x), theta_maze, mode=\"same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "xcorr_span = int(len(xcorr)/2)\n",
    "bins = np.linspace(-xcorr_span,xcorr_span,len(xcorr))\n",
    "plt.plot(theta_upsampled*50)\n",
    "plt.plot(np.diff(pos_maze.y))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cce1618081139d19eb1ee8d40815d94a2de4f62e1efb20d9406ddb60628c36ae"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('data_analysis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
