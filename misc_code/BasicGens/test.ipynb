{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Parallel.__init__() got an unexpected keyword argument 'return_as'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m i\n\u001b[1;32m     11\u001b[0m n_iter \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[1;32m     13\u001b[0m result \u001b[39m=\u001b[39m [\n\u001b[1;32m     14\u001b[0m     r\n\u001b[1;32m     15\u001b[0m     \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m tqdm(\n\u001b[0;32m---> 16\u001b[0m         joblib\u001b[39m.\u001b[39mParallel(return_as\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgenerator\u001b[39m\u001b[39m\"\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)(\n\u001b[1;32m     17\u001b[0m             joblib\u001b[39m.\u001b[39mdelayed(workload)(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_iter)\n\u001b[1;32m     18\u001b[0m         ),\n\u001b[1;32m     19\u001b[0m         total\u001b[39m=\u001b[39mn_iter,\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m ]\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "\u001b[0;31mTypeError\u001b[0m: Parallel.__init__() got an unexpected keyword argument 'return_as'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "def workload(i):\n",
    "    time.sleep(5)\n",
    "    return i\n",
    "\n",
    "\n",
    "n_iter = 4\n",
    "\n",
    "result = [\n",
    "    r\n",
    "    for r in tqdm(\n",
    "        joblib.Parallel(return_as=\"generator\", n_jobs=2)(\n",
    "            joblib.delayed(workload)(i) for i in range(n_iter)\n",
    "        ),\n",
    "        total=n_iter,\n",
    "    )\n",
    "]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statannotations.Annotator import Annotator\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "df = sns.load_dataset(\"tips\")\n",
    "x = \"day\"\n",
    "y = \"total_bill\"\n",
    "order = [\"Sun\", \"Mon\", \"Thur\", \"Fri\", \"Sat\"]\n",
    "_, ax = plt.subplots()\n",
    "ax = sns.boxplot(data=df, x=x, y=y, order=order)\n",
    "annot = Annotator(\n",
    "    ax,\n",
    "    [(\"Thur\", \"Fri\"), (\"Thur\", \"Sat\"), (\"Fri\", \"Sun\")],\n",
    "    data=df,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    order=order,\n",
    ")\n",
    "annot.configure(test=\"Mann-Whitney\", text_format=\"star\", loc=\"outside\", verbose=2)\n",
    "annot.apply_test()\n",
    "ax, test_results = annot.annotate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "\n",
    "file = Path(\"/data/Clustering/sessions/Hiro/wake_new/wake-behavior1.mat\")\n",
    "data = sio.loadmat(file)\n",
    "# f = h5py.File(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core import Neurons, Epoch\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "basepath = Path(\"/data/Clustering/sessions/Hiro/\")\n",
    "\n",
    "sessions = [\n",
    "    \"RoyMaze1\",\n",
    "    \"RoyMaze2\",\n",
    "    \"RoyMaze3\",\n",
    "    \"TedMaze1\",\n",
    "    \"TedMaze2\",\n",
    "    \"TedMaze3\",\n",
    "    \"KevinMaze1\",\n",
    "]\n",
    "spkdata = sio.loadmat(basepath / \"wake_new/wake-spikes.mat\")[\"spikes\"]\n",
    "statesdata = sio.loadmat(basepath / \"wake_new/wake-behavior1.mat\")[\"behavior\"]\n",
    "# prdigmdata = basepath/'wake_new/wake-behavior.mat'\n",
    "\n",
    "for i, name in enumerate(sessions):\n",
    "    sessdata = spkdata[name][0][0]\n",
    "    spiketrains = sessdata[\"time\"]\n",
    "    neuron_type_id = sessdata[\"quality\"]\n",
    "    neuron_type = np.ones(len(neuron_type_id), dtype=\"U5\")\n",
    "    neuron_type[neuron_type_id < 4] = \"pyr\"\n",
    "    # neuron_type[neuron_type_id == 6] = \"mua\"\n",
    "    neuron_type[neuron_type_id == 8] = \"inter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_spk[0][0][\"quality\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the number of neurons\n",
    "n_neurons = 20\n",
    "\n",
    "# Generate the neural activity\n",
    "n_timepoints = 1000\n",
    "spikes = np.random.poisson(10, size=(n_neurons, n_timepoints))\n",
    "\n",
    "# Define the spatial bins and occupancy\n",
    "n_bins = 20\n",
    "bin_centers = np.linspace(0, 1, n_bins)\n",
    "occupancy = np.random.uniform(0, 1, size=n_bins)\n",
    "occupancy = occupancy / np.sum(occupancy)\n",
    "\n",
    "# Define the place field centers and standard deviations\n",
    "place_field_centers = np.random.uniform(0, 1, size=n_neurons)\n",
    "place_field_stds = np.random.uniform(0.05, 0.15, size=n_neurons)\n",
    "\n",
    "# Calculate the firing rate maps\n",
    "firing_rate_maps = np.zeros((n_neurons, n_bins))\n",
    "for i in range(n_neurons):\n",
    "    firing_rate_maps[i] = stats.norm.pdf(\n",
    "        bin_centers, loc=place_field_centers[i], scale=place_field_stds[i]\n",
    "    )\n",
    "    firing_rate_maps[i] /= np.max(firing_rate_maps[i])\n",
    "\n",
    "# Calculate the likelihoods of the position given the spikes\n",
    "log_likelihoods = np.zeros(n_bins)\n",
    "for i in range(n_bins):\n",
    "    log_likelihood = 0\n",
    "    for j in range(n_neurons):\n",
    "        log_likelihood += spikes[j] * np.log(firing_rate_maps[j][i])\n",
    "        log_likelihood -= firing_rate_maps[j][i]\n",
    "    log_likelihoods[i] = log_likelihood\n",
    "\n",
    "# Calculate the posterior probabilities\n",
    "posterior_probs = np.exp(log_likelihoods) * occupancy\n",
    "posterior_probs /= np.sum(posterior_probs)\n",
    "\n",
    "# Decode the position of the animal\n",
    "decoded_position = np.sum(bin_centers * posterior_probs)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(spikes, aspect=\"auto\", cmap=\"gray_r\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Neuron\")\n",
    "plt.title(\"Neural Activity\")\n",
    "plt.subplot(122)\n",
    "plt.plot(bin_centers, occupancy, label=\"Occupancy\")\n",
    "for i in range(n_neurons):\n",
    "    plt.plot(bin_centers, firing_rate_maps[i], label=f\"Neuron {i+1}\")\n",
    "plt.plot(bin_centers, posterior_probs, label=\"Posterior\")\n",
    "plt.axvline(decoded_position, color=\"black\", linestyle=\"--\", label=\"Decoded Position\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Position\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.title(\"Decoding Results\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import scipy.signal as sg\n",
    "import matplotlib.pyplot as plt\n",
    "from neuropy import plotting\n",
    "import subjects\n",
    "import pint_pandas\n",
    "\n",
    "rpls = subjects.nsd.ratNday2[0].ripple\n",
    "\n",
    "# df = pd.DataFrame({\n",
    "#     \"start\": np.array([1, 2, 2, 3]).astype(float),\n",
    "#     \"stop\":np.array([1, 2, 2, 3]).astype(float),\n",
    "#     'label':'sd',\n",
    "# })\n",
    "\n",
    "# df = df.astype('pint[s]')\n",
    "# df1 = pd.DataFrame({\n",
    "#     \"start\": pd.Series(np.array([1, 2, 2, 3]).astype(float),dtype='pint[ms]'),\n",
    "#     \"stop\": pd.Series(np.array([1, 2, 2, 3]).astype(float),dtype='pint[ms]'\n",
    "#                                   ),\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "spike_train = pd.DataFrame(\n",
    "    {\"milliseconds\": np.random.random(200), \"Hertz\": np.random.random(200)}\n",
    ")\n",
    "curve = hv.Curve(spike_train, \"milliseconds\", \"Hertz\", label=\"Firing Rate\")\n",
    "spikes = hv.Spikes(spike_train, \"milliseconds\", [], label=\"Spike Train\")\n",
    "\n",
    "layout = curve + spikes\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.layouts import column\n",
    "from bokeh.models import ColumnDataSource, CustomJS, Slider\n",
    "from bokeh.plotting import figure, show\n",
    "import numpy as np\n",
    "\n",
    "data = np.random.random((10, 200))\n",
    "data = {str(k): data[k] for k in range(data.shape[0])}\n",
    "x = [x * 0.005 for x in range(0, 200)]\n",
    "y = x\n",
    "y2 = [_ + 0.2 for _ in y]\n",
    "\n",
    "source = ColumnDataSource(data=dict(x=x, y=y))\n",
    "source2 = ColumnDataSource(data=data)\n",
    "\n",
    "plot = figure(width=400, height=400, x_range=(0, 1), y_range=(0, 1))\n",
    "\n",
    "plot.line(x=\"x\", y=\"y\", source=source, line_width=3, line_alpha=0.6)\n",
    "\n",
    "callback = CustomJS(\n",
    "    args=dict(source=source, source2=data),\n",
    "    code=\"\"\"\n",
    "    const f = cb_obj.value\n",
    "    const x = source.data.x\n",
    "    // let extractColumn = (arr, column) => arr.map(x=>x[column])\n",
    "    const y = source2[f]\n",
    "    source.data = { x, y }\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "slider = Slider(start=0, end=9, value=1, step=1, title=\"power\")\n",
    "slider.js_on_change(\"value\", callback)\n",
    "\n",
    "layout = column(slider, plot)\n",
    "\n",
    "show(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import TextInput, RadioGroup\n",
    "from bokeh.plotting import show, column\n",
    "\n",
    "\n",
    "def my_text_input_handler(attr, old, new):\n",
    "    print(\"Previous label: \" + old)\n",
    "    print(\"Updated label: \" + new)\n",
    "\n",
    "\n",
    "text_input = TextInput(value=\"default\", title=\"Label:\")\n",
    "text_input.on_change(\"value\", my_text_input_handler)\n",
    "\n",
    "\n",
    "def my_radio_handler(new):\n",
    "    print(\"Radio button option \" + str(new) + \" selected.\")\n",
    "\n",
    "\n",
    "radio_group = RadioGroup(labels=[\"Option 1\", \"Option 2\", \"Option 3\"], active=0)\n",
    "radio_group.on_event(\"button_click\", my_radio_handler)\n",
    "\n",
    "show(text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" A weather chart for three cities using a csv file.\n",
    "This illustration demonstrates different interpretation of the same data\n",
    "with the distribution option.\n",
    ".. note::\n",
    "    This example needs the Scipy and Pandas package to run. See\n",
    "    ``README.md`` for more information.\n",
    "\"\"\"\n",
    "import datetime\n",
    "from os.path import dirname, join\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "from bokeh.io import curdoc\n",
    "from bokeh.layouts import column, row\n",
    "from bokeh.models import ColumnDataSource, DataRange1d, Select\n",
    "from bokeh.palettes import Blues4\n",
    "from bokeh.plotting import figure, show\n",
    "\n",
    "STATISTICS = [\n",
    "    \"record_min_temp\",\n",
    "    \"actual_min_temp\",\n",
    "    \"average_min_temp\",\n",
    "    \"average_max_temp\",\n",
    "    \"actual_max_temp\",\n",
    "    \"record_max_temp\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_dataset(src, name, distribution):\n",
    "    df = src[src.airport == name].copy()\n",
    "    del df[\"airport\"]\n",
    "    df[\"date\"] = pd.to_datetime(df.date)\n",
    "    # timedelta here instead of pd.DateOffset to avoid pandas bug < 0.18 (Pandas issue #11925)\n",
    "    df[\"left\"] = df.date - datetime.timedelta(days=0.5)\n",
    "    df[\"right\"] = df.date + datetime.timedelta(days=0.5)\n",
    "    df = df.set_index([\"date\"])\n",
    "    df.sort_index(inplace=True)\n",
    "    if distribution == \"Smoothed\":\n",
    "        window, order = 51, 3\n",
    "        for key in STATISTICS:\n",
    "            df[key] = savgol_filter(df[key], window, order)\n",
    "\n",
    "    return ColumnDataSource(data=df)\n",
    "\n",
    "\n",
    "def make_plot(source, title):\n",
    "    plot = figure(x_axis_type=\"datetime\", width=800, tools=\"\", toolbar_location=None)\n",
    "    plot.title.text = title\n",
    "\n",
    "    plot.quad(\n",
    "        top=\"record_max_temp\",\n",
    "        bottom=\"record_min_temp\",\n",
    "        left=\"left\",\n",
    "        right=\"right\",\n",
    "        color=Blues4[2],\n",
    "        source=source,\n",
    "        legend_label=\"Record\",\n",
    "    )\n",
    "    plot.quad(\n",
    "        top=\"average_max_temp\",\n",
    "        bottom=\"average_min_temp\",\n",
    "        left=\"left\",\n",
    "        right=\"right\",\n",
    "        color=Blues4[1],\n",
    "        source=source,\n",
    "        legend_label=\"Average\",\n",
    "    )\n",
    "    plot.quad(\n",
    "        top=\"actual_max_temp\",\n",
    "        bottom=\"actual_min_temp\",\n",
    "        left=\"left\",\n",
    "        right=\"right\",\n",
    "        color=Blues4[0],\n",
    "        alpha=0.5,\n",
    "        line_color=\"black\",\n",
    "        source=source,\n",
    "        legend_label=\"Actual\",\n",
    "    )\n",
    "\n",
    "    # fixed attributes\n",
    "    plot.xaxis.axis_label = None\n",
    "    plot.yaxis.axis_label = \"Temperature (F)\"\n",
    "    plot.axis.axis_label_text_font_style = \"bold\"\n",
    "    plot.x_range = DataRange1d(range_padding=0.0)\n",
    "    plot.grid.grid_line_alpha = 0.3\n",
    "\n",
    "    return plot\n",
    "\n",
    "\n",
    "def update_plot(attrname, old, new):\n",
    "    city = city_select.value\n",
    "    plot.title.text = \"Weather data for \" + cities[city][\"title\"]\n",
    "\n",
    "    src = get_dataset(df, cities[city][\"airport\"], distribution_select.value)\n",
    "    source.data.update(src.data)\n",
    "\n",
    "\n",
    "city = \"Austin\"\n",
    "distribution = \"Discrete\"\n",
    "\n",
    "cities = {\n",
    "    \"Austin\": {\n",
    "        \"airport\": \"AUS\",\n",
    "        \"title\": \"Austin, TX\",\n",
    "    },\n",
    "    \"Boston\": {\n",
    "        \"airport\": \"BOS\",\n",
    "        \"title\": \"Boston, MA\",\n",
    "    },\n",
    "    \"Seattle\": {\n",
    "        \"airport\": \"SEA\",\n",
    "        \"title\": \"Seattle, WA\",\n",
    "    },\n",
    "}\n",
    "\n",
    "city_select = Select(value=city, title=\"City\", options=sorted(cities.keys()))\n",
    "distribution_select = Select(\n",
    "    value=distribution, title=\"Distribution\", options=[\"Discrete\", \"Smoothed\"]\n",
    ")\n",
    "\n",
    "df = pd.read_csv(\"2015_weather.csv\")\n",
    "# df = pd.DataFrame(dict(airport=['BOS','SEA'],date=['2015-06-10','20']))\n",
    "source = get_dataset(df, cities[city][\"airport\"], distribution)\n",
    "plot = make_plot(source, \"Weather data for \" + cities[city][\"title\"])\n",
    "\n",
    "city_select.on_change(\"value\", update_plot)\n",
    "distribution_select.on_change(\"value\", update_plot)\n",
    "\n",
    "controls = column(city_select, distribution_select)\n",
    "\n",
    "# curdoc().add_root(row(plot, controls))\n",
    "# curdoc().title = \"Weather\"\n",
    "\n",
    "show(row(plot, controls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bokeh.io import show\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import ColorPicker, widgets\n",
    "from bokeh.plotting import figure\n",
    "\n",
    "x = np.arange(100)\n",
    "arr = np.random.random((5, 100))\n",
    "plot = figure(x_range=(0, 1), y_range=(0, 1), width=350, height=400)\n",
    "line = plot.line(x=x, y=arr[0], color=\"Green\", line_width=4)\n",
    "\n",
    "select = widgets.Select(title=\"Option:\", value=0, options=np.arange(5))\n",
    "\n",
    "select.js_link(\"value\", line.y, \"y\")\n",
    "# picker = ColorPicker(title=\"Line Color\")\n",
    "# picker.js_link('color', line.glyph, 'line_color')\n",
    "\n",
    "show(column(plot, select))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "file = \"/data/Clustering/sessions/RatU/BGU_SDROL/BGU_2021-08-09_SDROL.probe.npy\"\n",
    "\n",
    "data = np.load(file, allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import arange, linspace, pi, sin\n",
    "\n",
    "from bokeh.models import LinearAxis, Range1d\n",
    "from bokeh.plotting import figure, show\n",
    "\n",
    "x = arange(-2 * pi, 2 * pi, 0.2)\n",
    "y = sin(x)\n",
    "y2 = linspace(0, 100, len(x))\n",
    "\n",
    "p = figure(x_range=(-2 * pi, 2 * pi), y_range=(-1, 1))\n",
    "p.background_fill_color = \"#fafafa\"\n",
    "\n",
    "p.scatter(x, y, color=\"crimson\", size=8)\n",
    "p.yaxis.axis_label = \"red circles\"\n",
    "p.yaxis.axis_label_text_color = \"crimson\"\n",
    "\n",
    "p.extra_y_ranges[\"foo\"] = Range1d(0, 100)\n",
    "p.line(x, y2, color=\"navy\", y_range_name=\"foo\")\n",
    "\n",
    "ax2 = LinearAxis(y_range_name=\"foo\", axis_label=\"blue circles\")\n",
    "ax2.axis_label_text_color = \"navy\"\n",
    "p.add_layout(ax2, \"left\")\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules needed from Bokeh.\n",
    "from bokeh.io import output_file, show\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import LinearAxis, Range1d\n",
    "\n",
    "# Seting the params for the first figure.\n",
    "s1 = figure(x_axis_type=\"datetime\", tools=TOOLS, plot_width=1000, plot_height=600)\n",
    "\n",
    "# Setting the second y axis range name and range\n",
    "s1.extra_y_ranges = {\"foo\": Range1d(start=-100, end=200)}\n",
    "\n",
    "# Adding the second axis to the plot.\n",
    "s1.add_layout(LinearAxis(y_range_name=\"foo\"), \"right\")\n",
    "\n",
    "# Setting the rect glyph params for the first graph.\n",
    "# Using the default y range and y axis here.\n",
    "s1.rect(df_j.timestamp, mids, w, spans, fill_color=\"#D5E1DD\", line_color=\"black\")\n",
    "\n",
    "# Setting the rect glyph params for the second graph.\n",
    "# Using the aditional y range named \"foo\" and \"right\" y axis here.\n",
    "s1.rect(\n",
    "    df_j.timestamp,\n",
    "    ad_bar_coord,\n",
    "    w,\n",
    "    bar_span,\n",
    "    fill_color=\"#D5E1DD\",\n",
    "    color=\"green\",\n",
    "    y_range_name=\"foo\",\n",
    ")\n",
    "\n",
    "# Show the combined graphs with twin y axes.\n",
    "show(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import to_rgb\n",
    "from matplotlib.collections import PolyCollection\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "ax = sns.violinplot(\n",
    "    x=\"day\",\n",
    "    y=\"total_bill\",\n",
    "    hue=\"smoker\",\n",
    "    palette=[\".4\", \".7\"],\n",
    "    data=tips,\n",
    "    split=True,\n",
    "    inner=None,\n",
    ")\n",
    "# colors = sns.color_palette(\"Set2\")\n",
    "# for ind, violin in enumerate(ax.findobj(PolyCollection)):\n",
    "#     rgb = to_rgb(colors[ind // 2])\n",
    "#     if ind % 2 != 0:\n",
    "#         rgb = 0.5 + 0.5 * np.array(rgb)  # make whiter\n",
    "#     violin.set_facecolor(rgb)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import subjects\n",
    "\n",
    "sess = subjects.nsd.ratNday2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.ripple.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import PathPatch\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "tips[\"day\"] = pd.Categorical(tips[\"day\"])\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "ax = sns.violinplot(\n",
    "    data=tips,\n",
    "    x=\"day\",\n",
    "    y=\"total_bill\",\n",
    "    hue=\"smoker\",\n",
    "    inner=\"quartile\",\n",
    "    split=True,\n",
    "    scale=\"width\",\n",
    "    dodge=False,\n",
    ")\n",
    "sns.pointplot(\n",
    "    data=tips, x=\"day\", y=\"total_bill\", join=False, ci=None, color=\"yellow\", ax=ax\n",
    ")\n",
    "ax.legend_.remove()\n",
    "\n",
    "for p in ax.lines:\n",
    "    p.set_linestyle(\"-\")\n",
    "    p.set_linewidth(1)  # Sets the thickness of the quartile lines\n",
    "    p.set_color(\"white\")  # Sets the color of the quartile lines\n",
    "    p.set_alpha(1)\n",
    "\n",
    "for x, (day, violin) in enumerate(zip(tips[\"day\"].cat.categories, ax.collections)):\n",
    "    line = ax.hlines(\n",
    "        tips[tips[\"day\"] == day][\"total_bill\"].mean(),\n",
    "        x - 0.5,\n",
    "        x + 0.5,\n",
    "        color=\"black\",\n",
    "        ls=\":\",\n",
    "        lw=2,\n",
    "    )\n",
    "    patch = PathPatch(violin.get_paths()[0], transform=ax.transData)\n",
    "    line.set_clip_path(patch)  # clip the line by the form of the violin\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#999897\", \"#f07067\"] + [\"#424242\", \"#eb4034\"] * 2 + [\"#424242\", \"#48bdf7\"]\n",
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "tips = sns.load_dataset(\"tips\")\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "ax = sns.violinplot(\n",
    "    x=\"day\",\n",
    "    y=\"total_bill\",\n",
    "    hue=\"smoker\",\n",
    "    data=tips,\n",
    "    palette=\"muted\",\n",
    "    split=True,\n",
    "    inner=None,\n",
    "    linewidth=1,\n",
    ")\n",
    "\n",
    "sns.pointplot(\n",
    "    data=tips,\n",
    "    x=\"day\",\n",
    "    y=\"total_bill\",\n",
    "    hue=\"smoker\",\n",
    "    palette=[\"#ffff\", \"w\"],\n",
    "    dodge=0.3,\n",
    "    ci=None,\n",
    "    join=False,\n",
    "    markers=\".\",\n",
    "    scale=1,\n",
    ")\n",
    "\n",
    "ax.legend(\"\", frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "x = np.linspace(0, 3 * np.pi, 500)\n",
    "y = np.sin(x)\n",
    "dydx = np.cos(0.5 * (x[:-1] + x[1:]))  # first derivative\n",
    "\n",
    "# Create a set of line segments so that we can color them individually\n",
    "# This creates the points as a N x 1 x 2 array so that we can stack points\n",
    "# together easily to get the segments. The segments array for line collection\n",
    "# needs to be (numlines) x (points per line) x 2 (for x and y)\n",
    "points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, sharex=True, sharey=True)\n",
    "\n",
    "# Create a continuous norm to map from data points to colors\n",
    "norm = plt.Normalize(dydx.min(), dydx.max())\n",
    "lc = LineCollection(segments, cmap=\"viridis\", norm=norm)\n",
    "# Set the values used for colormapping\n",
    "lc.set_array(dydx)\n",
    "lc.set_linewidth(2)\n",
    "line = axs[0].add_collection(lc)\n",
    "fig.colorbar(line, ax=axs[0])\n",
    "\n",
    "# Use a boundary norm instead\n",
    "cmap = ListedColormap([\"r\", \"g\", \"b\"])\n",
    "norm = BoundaryNorm([-1, -0.5, 0.5, 1], cmap.N)\n",
    "lc = LineCollection(segments, cmap=cmap, norm=norm)\n",
    "lc.set_array(dydx)\n",
    "lc.set_linewidth(2)\n",
    "line = axs[1].add_collection(lc)\n",
    "fig.colorbar(line, ax=axs[1])\n",
    "\n",
    "axs[0].set_xlim(x.min(), x.max())\n",
    "axs[0].set_ylim(-1.1, 1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brokenaxes import brokenaxes\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import numpy as np\n",
    "\n",
    "sps1, sps2 = GridSpec(2, 1)\n",
    "\n",
    "bax = brokenaxes(xlims=((0.1, 0.3), (0.7, 0.8)), subplot_spec=sps1)\n",
    "x = np.linspace(0, 1, 100)\n",
    "bax.plot(x, np.sin(x * 30), ls=\":\", color=\"m\")\n",
    "\n",
    "x = np.random.poisson(3, 1000)\n",
    "bax = brokenaxes(xlims=((0, 2.5), (3, 6)), subplot_spec=sps2)\n",
    "bax.hist(x, histtype=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(19680801)\n",
    "\n",
    "pts = np.random.rand(30) * 0.2\n",
    "# Now let's make two outlier points which are far away from everything.\n",
    "pts[[3, 14]] += 0.8\n",
    "\n",
    "# If we were to simply plot pts, we'd lose most of the interesting\n",
    "# details due to the outliers. So let's 'break' or 'cut-out' the y-axis\n",
    "# into two portions - use the top (ax1) for the outliers, and the bottom\n",
    "# (ax2) for the details of the majority of our data\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "fig.subplots_adjust(hspace=0.05)  # adjust space between axes\n",
    "\n",
    "# plot the same data on both axes\n",
    "ax1.plot(pts)\n",
    "ax2.plot(pts)\n",
    "\n",
    "# zoom-in / limit the view to different portions of the data\n",
    "ax1.set_ylim(0.78, 1.0)  # outliers only\n",
    "ax2.set_ylim(0, 0.22)  # most of the data\n",
    "\n",
    "# hide the spines between ax and ax2\n",
    "ax1.spines.bottom.set_visible(False)\n",
    "ax2.spines.top.set_visible(False)\n",
    "ax1.xaxis.tick_top()\n",
    "ax1.tick_params(labeltop=False)  # don't put tick labels at the top\n",
    "ax2.xaxis.tick_bottom()\n",
    "\n",
    "# Now, let's turn towards the cut-out slanted lines.\n",
    "# We create line objects in axes coordinates, in which (0,0), (0,1),\n",
    "# (1,0), and (1,1) are the four corners of the axes.\n",
    "# The slanted lines themselves are markers at those locations, such that the\n",
    "# lines keep their angle and position, independent of the axes size or scale\n",
    "# Finally, we need to disable clipping.\n",
    "\n",
    "d = 0.5  # proportion of vertical to horizontal extent of the slanted line\n",
    "kwargs = dict(\n",
    "    marker=[(-1, -d), (1, d)],\n",
    "    markersize=12,\n",
    "    linestyle=\"none\",\n",
    "    color=\"k\",\n",
    "    mec=\"k\",\n",
    "    mew=1,\n",
    "    clip_on=False,\n",
    ")\n",
    "ax1.plot([0, 1], [0, 0], transform=ax1.transAxes, **kwargs)\n",
    "ax2.plot([0, 1], [1, 1], transform=ax2.transAxes, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from neuropy.io import NeuroscopeIO, BinarysignalIO\n",
    "\n",
    "file = Path(\n",
    "    \"/data/Clustering/sessions/RatA14d1LP/Rollipram/RatA14d1LP_Day1_2020-02-21_04-47-30.xml\"\n",
    ")\n",
    "recinfo = NeuroscopeIO(file)\n",
    "\n",
    "eegfile = BinarysignalIO(\n",
    "    recinfo.eeg_filename,\n",
    "    n_channels=recinfo.n_channels,\n",
    "    sampling_rate=recinfo.eeg_sampling_rate,\n",
    ")\n",
    "# write_filename = file.with_suffix('.maze.eeg')\n",
    "# eegfile.write_time_slice(write_filename,11824,16024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.figure import SubFigure\n",
    "\n",
    "# a = GridSpec(2,3)\n",
    "\n",
    "\n",
    "class MyFig(GridSpec):\n",
    "    def __init__(self, nrows, ncols, **kwargs):\n",
    "        super().__init__(nrows, ncols, **kwargs)\n",
    "\n",
    "\n",
    "# _,axs = plt.subplots(2,2,gridspec_kw=dict(height_ratios=[1,3]))\n",
    "\n",
    "# _,axs = plt.subplots(2,2)\n",
    "fig = plt.figure()\n",
    "gs = GridSpec(2, 2, figure=fig)\n",
    "\n",
    "\n",
    "def add_s(*args, **kwargs) -> mpl.figure.SubFigure:\n",
    "    return fig.add_subfigure(*args, **kwargs)\n",
    "\n",
    "\n",
    "subfig = add_s(gs[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = MyFig(2, 3)\n",
    "fig.add_subfigure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the PdfPages object to which we will save the pages:\n",
    "# The with statement makes sure that the PdfPages object is closed properly at\n",
    "# the end of the block, even if an Exception occurs.\n",
    "with PdfPages(\"multipage_pdf.pdf\") as pdf:\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.plot(range(7), [3, 1, 4, 1, 5, 9, 2], \"r-o\")\n",
    "    plt.title(\"Page One\")\n",
    "    pdf.savefig()  # saves the current figure into a pdf page\n",
    "    plt.close()\n",
    "\n",
    "    # if LaTeX is not installed or error caught, change to `False`\n",
    "    plt.rcParams[\"text.usetex\"] = False\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    x = np.arange(0, 5, 0.1)\n",
    "    plt.plot(x, np.sin(x), \"b-\")\n",
    "    plt.title(\"Page Two\")\n",
    "    pdf.attach_note(\"plot of sin(x)\")  # attach metadata (as pdf note) to page\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    plt.rcParams[\"text.usetex\"] = False\n",
    "    fig = plt.figure(figsize=(4, 5))\n",
    "    plt.plot(x, x**2, \"ko\")\n",
    "    plt.title(\"Page Three\")\n",
    "    pdf.savefig(fig)  # or you can pass a Figure object to pdf.savefig\n",
    "    plt.close()\n",
    "\n",
    "    # We can also set the file's metadata via the PdfPages object:\n",
    "    d = pdf.infodict()\n",
    "    d[\"Title\"] = \"Multipage PDF Example\"\n",
    "    d[\"Author\"] = \"Jouni K. Sepp\\xe4nen\"\n",
    "    d[\"Subject\"] = \"How to create a multipage pdf file and set its metadata\"\n",
    "    d[\"Keywords\"] = \"PdfPages multipage keywords author title subject\"\n",
    "    d[\"CreationDate\"] = datetime.datetime(2009, 11, 13)\n",
    "    d[\"ModDate\"] = datetime.datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import figure\n",
    "\n",
    "f = figure.Figure(constrained_layout=True, figsize=(8, 4))\n",
    "sf1, sf2 = f.subfigures(1, 2)\n",
    "\n",
    "axs = sf1.subplot_mosaic(\"AB;CD;CD;CD\")\n",
    "\n",
    "# axs[1:,0].plot([1,2,3])\n",
    "# sf1.add_gridspec()\n",
    "# sf1.add_subfigure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Generate fake data\n",
    "x = np.random.normal(size=1000)\n",
    "y = x * 3 + np.random.normal(size=1000)\n",
    "\n",
    "# Calculate the point density\n",
    "xy = np.vstack([x, y])\n",
    "z = gaussian_kde(xy, bw_method=50)(xy)\n",
    "\n",
    "# Sort the points by density, so that the densest points are plotted last\n",
    "idx = z.argsort()\n",
    "x, y, z = x[idx], y[idx], z[idx]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, c=z, s=50, cmap=\"Greys\", marker=\".\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "fig, axs = plt.subplot_mosaic(\n",
    "    [[\"a)\", \"c)\"], [\"b)\", \".\"], [\"d)\", \"d)\"]], constrained_layout=True\n",
    ")\n",
    "\n",
    "# axs['a)'].plot([1,2,3],[1,2,3])\n",
    "for label, ax in axs.items():\n",
    "    # label physical distance in and down:\n",
    "    trans = mtransforms.ScaledTranslation(10 / 72, -5 / 72, fig.dpi_scale_trans)\n",
    "    ax.text(\n",
    "        0.0,\n",
    "        1.0,\n",
    "        label,\n",
    "        transform=ax.transAxes + trans,\n",
    "        fontsize=\"medium\",\n",
    "        verticalalignment=\"top\",\n",
    "        fontfamily=\"serif\",\n",
    "        bbox=dict(facecolor=\"0.7\", edgecolor=\"none\", pad=3.0),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ephyviewer import mkQApp, MainViewer, TraceViewer\n",
    "import numpy as np\n",
    "from ephyviewer_position import PositionViewer\n",
    "import subjects\n",
    "\n",
    "position = subjects.sd.ratSday3[0].position.time_slice(10000, 12000)\n",
    "\n",
    "# you must first create a main Qt application (for event loop)\n",
    "app = mkQApp()\n",
    "\n",
    "# create fake 16 signals with 100000 at 10kHz\n",
    "sigs = position.traces.T\n",
    "sample_rate = position.sampling_rate\n",
    "t_start = 0.0\n",
    "\n",
    "# Create the main window that can contain several viewers\n",
    "win = MainViewer(debug=True, show_auto_scale=True)\n",
    "\n",
    "# create a viewer for signal with TraceViewer\n",
    "# TraceViewer normally accept a AnalogSignalSource but\n",
    "# TraceViewer.from_numpy is facitilty function to bypass that\n",
    "# view1 = TraceViewer.from_numpy(sigs, sample_rate, t_start, 'Signals')\n",
    "view1 = PositionViewer.from_numpy(sigs, sample_rate, t_start, \"Signals\")\n",
    "\n",
    "# Parameters can be set in script\n",
    "# view1.params['scale_mode'] = 'same_for_all'\n",
    "view1.params[\"display_labels\"] = True\n",
    "\n",
    "# And also parameters for each channel\n",
    "# view1.by_channel_params['ch0', 'visible'] = False\n",
    "# view1.by_channel_params['ch1', 'color'] = '#FF00AA'\n",
    "\n",
    "# This is needed when scale_mode='same_for_all'\n",
    "# to recompute the gain\n",
    "# this avoid to push auto_scale button\n",
    "view1.auto_scale()\n",
    "\n",
    "# put this veiwer in the main window\n",
    "win.add_view(view1)\n",
    "\n",
    "# show main window and run Qapp\n",
    "win.show()\n",
    "\n",
    "\n",
    "app.exec_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ephyviewer.tools import mkCachedBrush\n",
    "\n",
    "mkCachedBrush(\"#FFFFFF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(sigs[:,0],sigs[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ephyviewer import mkQApp, MainViewer, TraceViewer\n",
    "from ephyviewer import AnalogSignalSourceWithScatter\n",
    "import ephyviewer\n",
    "import numpy as np\n",
    "\n",
    "# you must first create a main Qt application (for event loop)\n",
    "app = mkQApp()\n",
    "\n",
    "# create 16 signals with 100000 at 10kHz\n",
    "sigs = np.random.rand(100000, 16)\n",
    "sample_rate = 1000.0\n",
    "t_start = 0.0\n",
    "\n",
    "\n",
    "# create fake 16 signals with sinus\n",
    "sample_rate = 1000.0\n",
    "t_start = 0.0\n",
    "times = np.arange(1000000) / sample_rate\n",
    "signals = np.sin(times * 2 * np.pi * 5)[:, None]\n",
    "signals = np.tile(signals, (1, 16))\n",
    "\n",
    "# detect some crossing zeros\n",
    "s0 = signals[:-2, 0]\n",
    "s1 = signals[1:-1, 0]\n",
    "s2 = signals[2:, 0]\n",
    "(peaks0,) = np.nonzero((s0 < s1) & (s2 < s1))\n",
    "(peaks1,) = np.nonzero((s0 > s1) & (s2 > s1))\n",
    "\n",
    "# create 2 familly scatters from theses 2 indexes\n",
    "scatter_indexes = {0: peaks0, 1: peaks1}\n",
    "# and asign them to some channels each\n",
    "scatter_channels = {0: [0, 5, 8], 1: [0, 5, 10]}\n",
    "source = AnalogSignalSourceWithScatter(\n",
    "    signals, sample_rate, t_start, scatter_indexes, scatter_channels\n",
    ")\n",
    "\n",
    "\n",
    "# Create the main window that can contain several viewers\n",
    "win = MainViewer(debug=True, show_auto_scale=True)\n",
    "\n",
    "# create a viewer for signal with TraceViewer\n",
    "# connected to the signal source\n",
    "view1 = TraceViewer(source=source)\n",
    "\n",
    "view1.params[\"scale_mode\"] = \"same_for_all\"\n",
    "view1.auto_scale()\n",
    "\n",
    "# put this veiwer in the main window\n",
    "win.add_view(view1)\n",
    "\n",
    "# show main window and run Qapp\n",
    "win.show()\n",
    "app.exec_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ephyviewer import mkQApp, MainViewer, TraceViewer, SpikeTrainViewer, EpochViewer, EventList\n",
    "from ephyviewer import get_sources_from_neo_segment, compose_mainviewer_from_sources\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from neo.test.generate_datasets import generate_one_simple_segment\n",
    "import neo\n",
    "\n",
    "\n",
    "# here we generate a segment with several objects\n",
    "# (this is a bad example because it mimics old neo behavior for signals (one channel=one object))\n",
    "neo_seg = generate_one_simple_segment(supported_objects=[neo.Segment, neo.AnalogSignal, neo.Event, neo.Epoch, neo.SpikeTrain])\n",
    "\n",
    "# the global QT app\n",
    "app = mkQApp()\n",
    "\n",
    "\n",
    "##############################\n",
    "# case 1 : create viewers one at a time directly from neo objects in memory\n",
    "win = MainViewer(show_auto_scale=True)\n",
    "TraceViewer.from\n",
    "# from one neo.AnalogSignal\n",
    "view1 = TraceViewer.from_neo_analogsignal(neo_seg.analogsignals[0], 'sigs')\n",
    "win.add_view(view1)\n",
    "\n",
    "# from several neo.SpikeTrains (3 spiketrains here)\n",
    "view2 = SpikeTrainViewer.from_neo_spiketrains(neo_seg.spiketrains[0:3], 'spikes')\n",
    "win.add_view(view2)\n",
    "\n",
    "# from several neo.Epoch\n",
    "view3 = EpochViewer.from_neo_epochs(neo_seg.epochs, 'epochs')\n",
    "win.add_view(view3)\n",
    "\n",
    "# from several neo.Event\n",
    "view4 = EventList.from_neo_events(neo_seg.events, 'events')\n",
    "win.add_view(view4, location='bottom',  orientation='horizontal')\n",
    "\n",
    "win.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################\n",
    "# case 2 : automagically create data sources and a complete window from a neo segment\n",
    "sources = get_sources_from_neo_segment(neo_seg)\n",
    "win2 = compose_mainviewer_from_sources(sources)\n",
    "win2.show()\n",
    "\n",
    "\n",
    "app.exec_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from statannotations.Annotator import Annotator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = sns.load_dataset(\"tips\")\n",
    "df['tip_bucket'] = pd.cut(df['tip'], 3)\n",
    "tip_bucket_list = df['tip_bucket'].unique()\n",
    "order = ['Sun', 'Thur', 'Fri', 'Sat']\n",
    "x = \"day\"\n",
    "y = \"total_bill\"\n",
    "hue = \"tip_bucket\"\n",
    "data = df\n",
    "ax = sns.boxplot(data=df, x=x, y=y, hue=hue)\n",
    "# method calls can be queued\n",
    "annot = Annotator(ax, [(\"Thur\", \"Fri\"), (\"Thur\", \"Sat\"), (\"Fri\", \"Sun\")], data=df, x=x, y=y, order=order)\n",
    "(annot\n",
    " .reset_configuration()\n",
    " .new_plot(ax, [((\"Sat\", tip_bucket_list[2]), (\"Fri\", tip_bucket_list[0]))],\n",
    "           data=df, x=x, y=y, hue=hue)\n",
    " .configure(test='t-test_ind')\n",
    " .apply_test()\n",
    " .annotate())\n",
    "\n",
    "# plt.legend(loc='upper left', bbox_to_anchor=(1.03, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ephyviewer also provides an epoch encoder which can be used with shortcut keys\n",
    "and/or the mouse to encode labels.\n",
    "\n",
    "ephyviewer makes available a CsvEpochSource class, which inherits from\n",
    "WritableEpochSource. If you would like to customize reading and writing epochs\n",
    "to files, you can write your own subclass of WritableEpochSource that implements\n",
    "the load() and save() methods.\n",
    "\n",
    "Here is an example of an epoch encoder that uses CsvEpochSource.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from ephyviewer import mkQApp, MainViewer, TraceViewer, CsvEpochSource, EpochEncoder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# lets encode some dev mood along the day\n",
    "possible_labels = [\"euphoric\", \"nervous\", \"hungry\", \"triumphant\"]\n",
    "\n",
    "filename = \"example_dev_mood_encoder.csv\"\n",
    "source_epoch = CsvEpochSource(filename, possible_labels)\n",
    "\n",
    "\n",
    "# you must first create a main Qt application (for event loop)\n",
    "app = mkQApp()\n",
    "\n",
    "# create fake 16 signals with 100000 at 10kHz\n",
    "sigs = np.random.rand(100000, 16)\n",
    "sample_rate = 1000.0\n",
    "t_start = 0.0\n",
    "\n",
    "# Create the main window that can contain several viewers\n",
    "win = MainViewer(debug=True, show_auto_scale=True)\n",
    "\n",
    "# create a viewer for signal\n",
    "view1 = TraceViewer.from_numpy(sigs, sample_rate, t_start, \"Signals\")\n",
    "view1.params[\"scale_mode\"] = \"same_for_all\"\n",
    "view1.auto_scale()\n",
    "win.add_view(view1)\n",
    "\n",
    "# create a viewer for the encoder itself\n",
    "view2 = EpochEncoder(source=source_epoch, name=\"Dev mood states along day\")\n",
    "view2.by_label_params[\"label0\", \"color\"] = \"#d16161\"\n",
    "view2.params[\"background_color\"] = \"#ffffff\"\n",
    "win.add_view(view2)\n",
    "\n",
    "\n",
    "# show main window and run Qapp\n",
    "win.show()\n",
    "\n",
    "\n",
    "app.exec_()\n",
    "\n",
    "\n",
    "# press '1', '2', '3', '4' to encode state.\n",
    "# or toggle 'Time range selector' and then use 'Insert within range'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class A:\n",
    "    # __slots__ = 'path','ripple_psd','ripple_rate'\n",
    "    def __init__(self) -> None:\n",
    "        self.path = Path(\"/home/bapung/Dropbox (University of Michigan)/ProcessedData\")\n",
    "        for f in self.path.iterdir():\n",
    "            setattr(self, f.name, self.load(f.stem))\n",
    "\n",
    "    def load(self, fp):\n",
    "        return np.load(self.path / f\"{fp}.npy\", allow_pickle=True).item()\n",
    "\n",
    "    # def __getattr__(self,name: str):\n",
    "    #     return self.load(name)['data']\n",
    "\n",
    "\n",
    "a = A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import h5py\n",
    "\n",
    "file = \"/data/DataGen/wake_new/wake-spikes.mat\"\n",
    "data = h5py.File(file, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "x = np.arange(100).reshape(10, 10)\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def go_fast(a):  # Function is compiled and runs in machine code\n",
    "    trace = 0.0\n",
    "    for i in range(a.shape[0]):\n",
    "        trace += np.tanh(a[i, i])\n",
    "    return a + trace\n",
    "\n",
    "\n",
    "# DO NOT REPORT THIS... COMPILATION TIME IS INCLUDED IN THE EXECUTION TIME!\n",
    "start = time.time()\n",
    "go_fast(x)\n",
    "end = time.time()\n",
    "print(\"Elapsed (with compilation) = %s\" % (end - start))\n",
    "\n",
    "# NOW THE FUNCTION IS COMPILED, RE-TIME IT EXECUTING FROM CACHE\n",
    "start = time.time()\n",
    "go_fast(x)\n",
    "end = time.time()\n",
    "print(\"Elapsed (after compilation) = %s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import time\n",
    "\n",
    "n = 300\n",
    "### Numpy and CPU\n",
    "s = time.time()\n",
    "X_cpu = np.ones((n, n, n))\n",
    "e = time.time()\n",
    "print(e - s)  ### CuPy and GPU\n",
    "s = time.time()\n",
    "X_gpu = cp.ones((n, n, n))\n",
    "e = time.time()\n",
    "print(e - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import subjects\n",
    "\n",
    "sess = subjects.sd.ratNday1[0]\n",
    "chan_order = np.concatenate(sess.recinfo.channel_groups)\n",
    "chan_order = np.concatenate([chan_order, chan_order[:64] + 128]).astype(\"int\")\n",
    "\n",
    "basefolder = Path(\"/data2/Clustering/RatU/RatUDay1SD/\")\n",
    "file = basefolder / \"RatU_Day1SD_2021-07-22_07-55-46.eeg\"\n",
    "n_channels = 256\n",
    "# data = np.memmap(file, dtype=\"int16\", mode=\"r\").reshape(-1, n_channels)[:,chan_order]\n",
    "# data.tofile(basefolder/'RatU_192chan1.eeg',format='int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_filename = basefolder / \"RatU_192chan.eeg\"\n",
    "write_data = np.memmap(write_filename, dtype=\"int16\", mode=\"w+\", shape=(data_new.size))\n",
    "write_data[: data_new.size] = data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from neuropy.core import Epoch\n",
    "import subjects\n",
    "\n",
    "sess = subjects.nsd.ratKday2[0]\n",
    "\n",
    "file = Path(\"/data/Clustering/sessions/RatK/Day2/RatK_Day2_2019-08-08_04-00-00.dead\")\n",
    "ep = []\n",
    "with open(file, mode=\"r\") as f:\n",
    "    for line in f:\n",
    "        ep.append(np.asarray(line.strip(\"\\n\").split(\" \")).astype(\"float\"))\n",
    "ep = np.asarray(ep) / 1000\n",
    "\n",
    "epochs = Epoch.from_array(ep[:, 0], ep[:, 1])\n",
    "epochs.save(sess.filePrefix.with_suffix(\".artifact\"))\n",
    "\n",
    "\n",
    "# test = file.read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from neuropy import plotting\n",
    "\n",
    "plotting.plot_raster(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg, AutoRegResults\n",
    "import subjects\n",
    "from hfuncs import whiten_signal\n",
    "\n",
    "sess = subjects.sd.ratNday1[0]\n",
    "# period = sess.paradigm['maze'].flatten()\n",
    "period = sess.ripple[6000].flatten()\n",
    "signal = sess.eegfile.get_signal(32, period[0], period[0] + 2)\n",
    "wht = whiten_signal(signal)\n",
    "# mod = AutoReg(signal,2,old_names=False)\n",
    "# res = mod.fit()\n",
    "# new_sig = res.predict(0,len(signal)+1)\n",
    "# residual = signal-new_sig[2:]\n",
    "# result = AutoRegResults(mod,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the PdfPages object to which we will save the pages:\n",
    "# The with statement makes sure that the PdfPages object is closed properly at\n",
    "# the end of the block, even if an Exception occurs.\n",
    "with PdfPages(\"multipage_pdf.pdf\") as pdf:\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.plot(range(7), [3, 1, 4, 1, 5, 9, 2], \"r-o\")\n",
    "    plt.title(\"Page One\")\n",
    "    pdf.savefig()  # saves the current figure into a pdf page\n",
    "    plt.close()\n",
    "\n",
    "    # if LaTeX is not installed or error caught, change to `False`\n",
    "    # plt.rcParams['text.usetex'] = False\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    x = np.arange(0, 5, 0.1)\n",
    "    plt.plot(x, np.sin(x), \"b-\")\n",
    "    plt.title(\"Page Two\")\n",
    "    pdf.attach_note(\"plot of sin(x)\")  # attach metadata (as pdf note) to page\n",
    "    pdf.savefig()\n",
    "    plt.close()\n",
    "\n",
    "    # plt.rcParams['text.usetex'] = False\n",
    "    fig = plt.figure(figsize=(4, 5))\n",
    "    plt.plot(x, x**2, \"ko\")\n",
    "    plt.title(\"Page Three\")\n",
    "    pdf.savefig(fig)  # or you can pass a Figure object to pdf.savefig\n",
    "    plt.close()\n",
    "\n",
    "    # We can also set the file's metadata via the PdfPages object:\n",
    "    d = pdf.infodict()\n",
    "    d[\"Title\"] = \"Multipage PDF Example\"\n",
    "    d[\"Author\"] = \"Jouni K. Sepp\\xe4nen\"\n",
    "    d[\"Subject\"] = \"How to create a multipage pdf file and set its metadata\"\n",
    "    d[\"Keywords\"] = \"PdfPages multipage keywords author title subject\"\n",
    "    d[\"CreationDate\"] = datetime.datetime(2009, 11, 13)\n",
    "    d[\"ModDate\"] = datetime.datetime.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as sg\n",
    "f,psd1 = sg.welch(signal.traces[0],fs=1250,nperseg=1250,noverlap=625)\n",
    "f,psd2 = sg.welch(wht.traces[0],fs=1250,nperseg=1250,noverlap=625)\n",
    "# f,psd3 = sg.welch(res.resid,fs=1250,nperseg=1250,noverlap=625)\n",
    "plt.plot(f,psd1)\n",
    "plt.plot(f,psd2)\n",
    "# plt.plot(f,psd3)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "# plt.plot(new_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from neuropy.utils.signal_process import WaveletSg\n",
    "\n",
    "wvlt = WaveletSg(wht, freqs=np.arange(100, 250, 2), ncycles=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, axs = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "axs[0].plot(np.linspace(0, 2, len(signal.traces[0])), signal.traces[0], \"k\")\n",
    "axs[1].imshow(\n",
    "    wvlt.traces,\n",
    "    aspect=\"auto\",\n",
    "    extent=[0, 2, 100, 250],\n",
    "    origin=\"lower\",\n",
    "    interpolation=\"none\",\n",
    "    # vmax=130,\n",
    "    cmap='jet',\n",
    ")\n",
    "# plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "plt.plot(signal.traces[0])\n",
    "plt.plot(wht.traces[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subjects\n",
    "\n",
    "sess = subjects.nsd.ratKday2[0]\n",
    "maze = sess.paradigm[\"maze\"].flatten()\n",
    "dest_file = sess.filePrefix.with_suffix(\".maze.eeg\")\n",
    "sess.eegfile.write_time_slice(dest_file, int(maze[0]), int(maze[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_name = \"RatU_Day4SD_2021-07-29_08-23-06.eeg_sample.eeg\"\n",
    "n_channels = 192 # number of recorded channels in the file\n",
    "sampling_rate = 1250\n",
    "# reading data from binary file and reshaping to n_channels x time format\n",
    "data = np.memmap(file_name,dtype='int16',mode='r').reshape(-1,n_channels).T\n",
    "\n",
    "#let's plot data from first channel\n",
    "plt.plot(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "from neuropy.plotting import Fig\n",
    "\n",
    "def example_plot(ax, fontsize=12, hide_labels=False):\n",
    "    pc = ax.pcolormesh(np.random.randn(30, 30), vmin=-2.5, vmax=2.5)\n",
    "    if not hide_labels:\n",
    "        ax.set_xlabel('x-label', fontsize=fontsize)\n",
    "        ax.set_ylabel('y-label', fontsize=fontsize)\n",
    "        ax.set_title('Title', fontsize=fontsize)\n",
    "    return pc\n",
    "\n",
    "figure = Fig()\n",
    "fig,gs = figure.draw(grid=(4,4))\n",
    "\n",
    "ax = figure.add_subplot(gs[:,2:])\n",
    "ax.plot(np.arange(10),np.arange(10))\n",
    "\n",
    "subfig = fig.add_subfigure(gs[:,:2])\n",
    "axsLeft = subfig.subplots(1, 2, sharey=True)\n",
    "subfig.set_facecolor('0.75')\n",
    "for ax in axsLeft:\n",
    "    pc = example_plot(ax)\n",
    "subfig.suptitle('Left plots', fontsize='x-large')\n",
    "subfig.colorbar(pc, shrink=0.6, ax=axsLeft, location='bottom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.models import HoverTool, CustomJS, ColumnDataSource\n",
    "\n",
    "N = 20\n",
    "x = np.random.random(size=N)\n",
    "y = np.random.random(size=N)\n",
    "\n",
    "p = figure(tools=[\"hover\"], toolbar_location=None)\n",
    "p.scatter(x, y, size=10)\n",
    "\n",
    "img_x = np.linspace(0, 10, N)\n",
    "img_y = np.linspace(0, 10, N)\n",
    "\n",
    "images = []\n",
    "for a, b in zip(x, y):\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    d = np.sin(a * xx) * np.cos(b * yy)\n",
    "    images.append(d)\n",
    "\n",
    "imgs_source = ColumnDataSource(data=dict(images=images))\n",
    "img_source = ColumnDataSource(data=dict(image=[]))\n",
    "\n",
    "img = figure(x_range=(0, 10), y_range=(0, 10), tools=[], toolbar_location=None)\n",
    "img.image(image=\"image\", x=0, y=0, dw=10, dh=10, source=img_source, palette=\"Greys7\")\n",
    "\n",
    "hover = p.select_one(HoverTool)\n",
    "hover.callback = CustomJS(\n",
    "    args=dict(imgs_source=imgs_source, img_source=img_source),\n",
    "    code=\"\"\"\n",
    "var indices = cb_data.index['1d'].indices;\n",
    "if (indices.length > 0) {\n",
    "    var img = imgs_source.data.images[indices[0]];\n",
    "    img_source.data = {image: [img]};\n",
    "} else {\n",
    "    img_source.data = {image: []};\n",
    "}\n",
    "\"\"\",\n",
    ")\n",
    "hover.tooltips = None\n",
    "\n",
    "output_file(\"linked_hover.html\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from math import cos, pi, sin\n",
    "\n",
    "from bokeh.colors.named import firebrick, lightgray, orchid, seagreen, skyblue, tomato\n",
    "from bokeh.document import Document\n",
    "from bokeh.embed import file_html\n",
    "from bokeh.models import (\n",
    "    AnnularWedge,\n",
    "    ColumnDataSource,\n",
    "    ImageURL,\n",
    "    Plot,\n",
    "    Range1d,\n",
    "    Text,\n",
    "    Wedge,\n",
    ")\n",
    "from bokeh.resources import INLINE\n",
    "from bokeh.sampledata.browsers import browsers_nov_2013, icons\n",
    "from bokeh.util.browser import view\n",
    "\n",
    "df = browsers_nov_2013\n",
    "\n",
    "xdr = Range1d(start=-2, end=2)\n",
    "ydr = Range1d(start=-2, end=2)\n",
    "\n",
    "plot = Plot(x_range=xdr, y_range=ydr, width=800, height=800)\n",
    "plot.title.text = \"Web browser market share (November 2013)\"\n",
    "plot.toolbar_location = None\n",
    "\n",
    "colors = {\n",
    "    \"Chrome\": seagreen,\n",
    "    \"Firefox\": tomato,\n",
    "    \"Safari\": orchid,\n",
    "    \"Opera\": firebrick,\n",
    "    \"IE\": skyblue,\n",
    "    \"Other\": lightgray,\n",
    "}\n",
    "\n",
    "aggregated = df.groupby(\"Browser\").agg(sum)\n",
    "selected = aggregated[aggregated.Share >= 1].copy()\n",
    "selected.loc[\"Other\"] = aggregated[aggregated.Share < 1].sum()\n",
    "browsers = selected.index.tolist()\n",
    "\n",
    "radians = lambda x: 2 * pi * (x / 100)\n",
    "angles = selected.Share.map(radians).cumsum()\n",
    "\n",
    "end_angles = angles.tolist()\n",
    "start_angles = [0] + end_angles[:-1]\n",
    "\n",
    "browsers_source = ColumnDataSource(\n",
    "    dict(\n",
    "        start=start_angles,\n",
    "        end=end_angles,\n",
    "        colors=[colors[browser] for browser in browsers],\n",
    "    )\n",
    ")\n",
    "\n",
    "glyph = Wedge(\n",
    "    x=0,\n",
    "    y=0,\n",
    "    radius=1,\n",
    "    line_color=\"white\",\n",
    "    line_width=2,\n",
    "    start_angle=\"start\",\n",
    "    end_angle=\"end\",\n",
    "    fill_color=\"colors\",\n",
    ")\n",
    "plot.add_glyph(browsers_source, glyph)\n",
    "\n",
    "\n",
    "def polar_to_cartesian(r, start_angles, end_angles):\n",
    "    cartesian = lambda r, alpha: (r * cos(alpha), r * sin(alpha))\n",
    "    points = []\n",
    "\n",
    "    for start, end in zip(start_angles, end_angles):\n",
    "        points.append(cartesian(r, (end + start) / 2))\n",
    "\n",
    "    return zip(*points)\n",
    "\n",
    "\n",
    "first = True\n",
    "\n",
    "for browser, start_angle, end_angle in zip(browsers, start_angles, end_angles):\n",
    "    versions = df[(df.Browser == browser) & (df.Share >= 0.5)]\n",
    "    angles = versions.Share.map(radians).cumsum() + start_angle\n",
    "    end = angles.tolist() + [end_angle]\n",
    "    start = [start_angle] + end[:-1]\n",
    "    base_color = colors[browser]\n",
    "    fill = [base_color.lighten(i * 0.05).to_hex() for i in range(len(versions) + 1)]\n",
    "    # extra empty string accounts for all versions with share < 0.5 together\n",
    "    text = [\n",
    "        number if share >= 1 else \"\"\n",
    "        for number, share in zip(versions.VersionNumber, versions.Share)\n",
    "    ] + [\"\"]\n",
    "    x, y = polar_to_cartesian(1.25, start, end)\n",
    "\n",
    "    source = ColumnDataSource(dict(start=start, end=end, fill=fill))\n",
    "    glyph = AnnularWedge(\n",
    "        x=0,\n",
    "        y=0,\n",
    "        inner_radius=1,\n",
    "        outer_radius=1.5,\n",
    "        start_angle=\"start\",\n",
    "        end_angle=\"end\",\n",
    "        line_color=\"white\",\n",
    "        line_width=2,\n",
    "        fill_color=\"fill\",\n",
    "    )\n",
    "    plot.add_glyph(source, glyph)\n",
    "\n",
    "    text_angle = [(start[i] + end[i]) / 2 for i in range(len(start))]\n",
    "    text_angle = [\n",
    "        angle + pi if pi / 2 < angle < 3 * pi / 2 else angle for angle in text_angle\n",
    "    ]\n",
    "\n",
    "    text_source = ColumnDataSource(dict(text=text, x=x, y=y, angle=text_angle))\n",
    "    glyph = Text(\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        text=\"text\",\n",
    "        angle=\"angle\",\n",
    "        text_align=\"center\",\n",
    "        text_baseline=\"middle\",\n",
    "        text_font_size=\"11px\",\n",
    "    )\n",
    "    plot.add_glyph(text_source, glyph)\n",
    "\n",
    "\n",
    "def to_base64(png):\n",
    "    return \"data:image/png;base64,\" + base64.b64encode(png).decode(\"utf-8\")\n",
    "\n",
    "\n",
    "urls = [to_base64(icons.get(browser, b\"\")) for browser in browsers]\n",
    "x, y = polar_to_cartesian(1.7, start_angles, end_angles)\n",
    "\n",
    "icons_source = ColumnDataSource(dict(urls=urls, x=x, y=y))\n",
    "glyph = ImageURL(url=\"urls\", x=\"x\", y=\"y\", anchor=\"center\")\n",
    "plot.add_glyph(icons_source, glyph)\n",
    "\n",
    "text = [\"%.02f%%\" % value for value in selected.Share]\n",
    "x, y = polar_to_cartesian(0.7, start_angles, end_angles)\n",
    "\n",
    "text_source = ColumnDataSource(dict(text=text, x=x, y=y))\n",
    "glyph = Text(x=\"x\", y=\"y\", text=\"text\", text_align=\"center\", text_baseline=\"middle\")\n",
    "plot.add_glyph(text_source, glyph)\n",
    "\n",
    "doc = Document()\n",
    "doc.add_root(plot)\n",
    "doc.validate()\n",
    "\n",
    "filename = \"donut.html\"\n",
    "with open(filename, \"w\") as f:\n",
    "    f.write(file_html(doc, INLINE, \"Donut Chart\"))\n",
    "print(\"Wrote %s\" % filename)\n",
    "view(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ephyviewer import mkQApp, MainViewer, TraceViewer, TimeFreqViewer\n",
    "from ephyviewer import InMemoryAnalogSignalSource\n",
    "import ephyviewer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# you must first create a main Qt application (for event loop)\n",
    "app = mkQApp()\n",
    "\n",
    "# create fake 16 signals with 100000 at 10kHz\n",
    "sigs = np.random.rand(100000, 16)\n",
    "sample_rate = 1000.0\n",
    "t_start = 0.0\n",
    "\n",
    "# Create the main window that can contain several viewers\n",
    "win = MainViewer(debug=True, show_auto_scale=True)\n",
    "\n",
    "# Create a datasource for the viewer\n",
    "# here we use InMemoryAnalogSignalSource but\n",
    "# you can alose use your custum datasource by inheritance\n",
    "source = InMemoryAnalogSignalSource(sigs, sample_rate, t_start)\n",
    "\n",
    "# create a viewer for signal with TraceViewer\n",
    "view1 = TraceViewer(source=source, name=\"trace\")\n",
    "view1.params[\"scale_mode\"] = \"same_for_all\"\n",
    "view1.auto_scale()\n",
    "win.add_view(view1)\n",
    "\n",
    "sigs = np.random.rand(100000, 16)\n",
    "sample_rate = 1200.0\n",
    "t_start = 30.0\n",
    "\n",
    "source2 = InMemoryAnalogSignalSource(sigs, sample_rate, t_start)\n",
    "\n",
    "\n",
    "# create a time freq viewer conencted to the same source\n",
    "view1 = TraceViewer(source=source2, name=\"trace2\")\n",
    "view1.params[\"scale_mode\"] = \"same_for_all\"\n",
    "view1.auto_scale()\n",
    "\n",
    "# add them to mainwindow\n",
    "win.add_view(view1)\n",
    "\n",
    "\n",
    "# show main window and run Qapp\n",
    "win.show()\n",
    "app.exec_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subjects\n",
    "from neuropy.core import Signal\n",
    "from neuropy_viewer import view_multiple_signals\n",
    "from neuropy.utils import signal_process\n",
    "\n",
    "sess = subjects.nsd.ratUday2[0]\n",
    "maze = sess.paradigm[\"maze\"]\n",
    "eeg = sess.eegfile.get_signal(107, maze[0], maze[1])\n",
    "\n",
    "spec = signal_process.SpectrogramBands(eeg, window=1, overlap=0.5)\n",
    "theta_signal = Signal(spec.theta.reshape(1, -1), sampling_rate=2, t_start=eeg.t_start)\n",
    "\n",
    "position = sess.position.time_slice(maze[0], maze[1])\n",
    "pos_signal = Signal(position.traces, position.sampling_rate, position.t_start)\n",
    "view_multiple_signals([eeg, theta_signal, pos_signal])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ephys_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "52f254424580b91f6c7110030cc7bfbb44a6bdcb44870c3ec204b7f2c5b1ac39"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
