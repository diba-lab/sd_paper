{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RatU Day4SD recording info\n",
    "- No timestamps were deleted after concatenating .dat files from various folders of open-ephys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: /data/Clustering/sessions/RatU/RatUDay4SD/RatU_Day4SD_2021-07-29_08-23-06.xml \n",
      "# channels: 192\n",
      "sampling rate: 30000\n",
      "lfp Srate (downsampled): 1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import subjects\n",
    "\n",
    "sess = subjects.sd.ratUday4[0]\n",
    "print(sess.recinfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set probe configuration\n",
    "- RatU_Day4SD has two probes: both 128chan-8shanks diagnostic biochips.\n",
    "- 64 channels in one of the probes (implanted in left hemisphere) had no signal from 4 shanks (probably one of the intan chips was faulty). So only 192 channels were recorded, the channels in .dat file are already order according to depth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from neuropy.core import shank, probe, probegroup\n",
    "from neuropy.plotting import plot_probe\n",
    "\n",
    "shanks = []\n",
    "channel_groups = sess.recinfo.channel_groups\n",
    "badchans = sess.recinfo.skipped_channels\n",
    "\n",
    "#--- diagnostic-biochip 8 shanks -----------\n",
    "for i in range(8):\n",
    "    chans = channel_groups[i]\n",
    "    shank = shank.auto_generate(\n",
    "        columns=2,\n",
    "        contacts_per_column=8,\n",
    "        xpitch=15,\n",
    "        ypitch=15,\n",
    "        y_shift_per_column=[0,-7.5],\n",
    "        channel_id=np.append(\n",
    "            channel_groups[i][::2][::-1], channel_groups[i][1::2][::-1]\n",
    "        ),\n",
    "    )\n",
    "    shank.set_disconnected_channels(sess.recinfo.skipped_channels)\n",
    "    shanks.append(shank)\n",
    "\n",
    "probe1 = probe(shanks)\n",
    "\n",
    "#--- dignostic biochip 4 shanks (4 shanks were bad) ----------- \n",
    "shanks = []\n",
    "for i in range(8,12):\n",
    "\n",
    "    shank = shank.auto_generate(\n",
    "        columns=2,\n",
    "        contacts_per_column=8,\n",
    "        xpitch=15,\n",
    "        ypitch=15,\n",
    "        y_shift_per_column=[0, -7.5],\n",
    "        channel_id=np.append(\n",
    "            channel_groups[i][::2][::-1], channel_groups[i][1::2][::-1]\n",
    "        ),\n",
    "    )\n",
    "    shank.set_disconnected_channels(sess.recinfo.skipped_channels)\n",
    "    shanks.append(shank)\n",
    "\n",
    "\n",
    "probe2 = probe(shanks)\n",
    "probe2.move((probe1.x_max+500,0))\n",
    "\n",
    "prbgrp = probegroup()\n",
    "prbgrp.add_probe(probe1)\n",
    "prbgrp.add_probe(probe2)\n",
    "\n",
    "prbgrp.filename = sess.fileprefix.with_suffix(\".probegroup.npy\")\n",
    "prbgrp.save()\n",
    "plot_probe(prbgrp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to json format for spyking-circus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils import probe_util\n",
    "\n",
    "file = sess.filePrefix.with_suffix('.prb')\n",
    "probe_util.write_spyking_circus(file,sess.probegroup,shanksCombine=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create experimental paradigm\n",
    "- pre sleep is a little shorter\n",
    "- animal was lazy on re-maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.paradigm.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neuropy.core import Epoch\n",
    "\n",
    "datetime_data = pd.read_csv(sess.filePrefix.with_suffix('.datetime.csv'))\n",
    "durations = datetime_data.nFrames/sess.recinfo.dat_sampling_rate\n",
    "epochs = pd.DataFrame(\n",
    "    {\n",
    "        \"start\": [0, 9411,12547,30565,12547,45161],\n",
    "        \"stop\": [9410, 12546, 30564, 45160,45160,48283],\n",
    "        \"label\": [\"pre\", \"maze\", \"sd\",'rs','post','re-maze'],\n",
    "    }\n",
    ")\n",
    "\n",
    "paradigm = Epoch(epochs=epochs)\n",
    "paradigm.filename = sess.filePrefix.with_suffix(\".paradigm.npy\")\n",
    "paradigm.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect epochs\n",
    "Here we will various types of epochs which typical for hippocampal recordings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artifacts epochs\n",
    "A typical session will have some artifacts that may negatively influence many analyses. Using a simple zscore measure, we can identify epochs where signal is above some threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses import detect_artifact_epochs\n",
    "from neuropy import plotting\n",
    "from neuropy.utils import signal_process\n",
    "from neuropy.core import Signal\n",
    "print(sess)\n",
    "signal = sess.eegfile.get_signal([96])\n",
    "# filt_trace = signal_process.filter_sig.highpass(signal.traces,cutoff=400)\n",
    "# filtered_signal = Signal(filt_trace,signal.sampling_rate)\n",
    "artifact_epochs = detect_artifact_epochs(signal, thresh=7)\n",
    "artifact_epochs.save(sess.filePrefix.with_suffix(\".artifact.npy\"))\n",
    "# artifact_epochs.save()\n",
    "plotting.plot_artifact_epochs(artifact_epochs,signal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "28488/60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write artifact epochs to spyking circus format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.io import SpykingCircusIO\n",
    "\n",
    "file = sess.filePrefix.with_suffix('.dead')\n",
    "SpykingCircusIO.write_epochs(file,sess.artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sleep scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core import Signal\n",
    "from neuropy.analyses import brainstates\n",
    "\n",
    "signal = sess.eegfile.get_signal() \n",
    "brainstates = brainstates.detect_brainstates_epochs(signal=signal,probe=sess.probegroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brainstates.filename = sess.filePrefix.with_suffix('.brainstates')\n",
    "brainstates.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ripple epochs\n",
    "To detect ripples one also needs probegroup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses import oscillations\n",
    "signal = sess.eegfile.get_signal()\n",
    "ripple_epochs =oscillations.detect_ripple_epochs(signal, sess.probegroup)\n",
    "ripple_epochs.filename = sess.filePrefix.with_suffix('.ripple.npy')\n",
    "ripple_epochs.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = sess.eegfile.get_signal(channel_id=[1, 2, 3, 4], t_start=1, t_stop=1.2)\n",
    "plotting.plot_signal_traces(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing spiketrains from Phy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.io import PhyIO\n",
    "from neuropy.core import Neurons\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "cluster_path = Path(\"/home/bapung/Documents/ClusteringHub/spykcirc/RatU/RatUDay4SD/RatU_Day4SD_2021-07-29_08-23-06-1.GUI\")\n",
    "chan_grps = sess.recinfo.channel_groups\n",
    "phy_data = PhyIO(cluster_path)\n",
    "spiketrains =phy_data.spiketrains\n",
    "peak_chans = phy_data.peak_channels\n",
    "waveforms = phy_data.waveforms\n",
    "shank_id = sess.probegroup.get_shank_id_for_channels(peak_chans)\n",
    "\n",
    "neuron_type_id = phy_data.cluster_info.q.values\n",
    "neuron_type = np.ones(len(neuron_type_id), dtype=\"U5\")\n",
    "neuron_type[neuron_type_id<4] = 'pyr'\n",
    "neuron_type[neuron_type_id==6] = 'mua'\n",
    "neuron_type[neuron_type_id==8] = 'inter'\n",
    "\n",
    "\n",
    "neurons = Neurons(\n",
    "    np.array(spiketrains, dtype=object),\n",
    "    t_stop=sess.eegfile.duration,\n",
    "    sampling_rate=phy_data.sampling_rate,\n",
    "    peak_channels=peak_chans,\n",
    "    waveforms=np.array(waveforms,dtype='object'),\n",
    "    shank_ids=np.array(shank_id).astype(int),\n",
    "    neuron_type=neuron_type,\n",
    "    metadata={'cluster_path':cluster_path}\n",
    ")\n",
    "\n",
    "neurons.filename = sess.filePrefix.with_suffix('.neurons')\n",
    "neurons.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "from neuropy.plotting import plot_raster\n",
    "\n",
    "\n",
    "plt.plot(phy_data.peak_waveforms[0])\n",
    "plot_raster(neurons,color='jet',add_vert_jitter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BinnedSpiketrain and Mua objects using Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mua =sess.neurons.get_mua()\n",
    "mua.filename = sess.filePrefix.with_suffix(\".mua.npy\")\n",
    "mua.save()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from neuropy import plotting\n",
    "smth_mua = sess.mua.get_smoothed(sigma=0.02)\n",
    "plotting.plot_mua(smth_mua)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses import detect_pbe_epochs\n",
    "\n",
    "pbe = detect_pbe_epochs(smth_mua)\n",
    "pbe.filename = sess.filePrefix.with_suffix('.pbe')\n",
    "pbe.save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Position\n",
    "- concatenated .dat file did not have any deleted timepoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import position from optitrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.io import OptitrackIO\n",
    "from neuropy.core import Position\n",
    "from pathlib import Path\n",
    "\n",
    "opti_folder = sess.filePrefix.parent / 'position'\n",
    "opti_data = OptitrackIO(dirname=opti_folder,scale_factor=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align position with .dat file\n",
    "- t_error for maze position alignment were estimated using theta power and speed cross correlogram.\n",
    "- theta channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ------- maze align corection ---------\n",
    "t_error = [0, 0, 0.8, 0, 0, 0.680]\n",
    "\n",
    "# ---- startimes of concatenated .dat files\n",
    "tracking_sRate = opti_data.sampling_rate\n",
    "rec_datetime = pd.read_csv(sess.filePrefix.with_suffix(\".datetime.csv\"))\n",
    "data_time = []\n",
    "for i, file_time in enumerate(rec_datetime[\"StartTime\"]):\n",
    "    tbegin = datetime.strptime(file_time, \"%Y-%m-%d_%H-%M-%S\") + pd.Timedelta(\n",
    "        t_error[i], unit=\"sec\"\n",
    "    )\n",
    "    nframes = rec_datetime[\"nFrames\"][i]\n",
    "    duration = pd.Timedelta(nframes / sess.recinfo.dat_sampling_rate, unit=\"sec\")\n",
    "    tend = tbegin + duration\n",
    "    trange = pd.date_range(\n",
    "        start=tbegin,\n",
    "        end=tend,\n",
    "        periods=int(duration.total_seconds() * tracking_sRate),\n",
    "        closed=\"left\",\n",
    "    )\n",
    "    data_time.extend(trange)\n",
    "data_time = pd.to_datetime(data_time)\n",
    "\n",
    "x, y, z = opti_data.get_position_at_datetimes(data_time)\n",
    "traces = np.vstack((z, x, y))\n",
    "\n",
    "position = Position(traces=traces, t_start=0, sampling_rate=opti_data.sampling_rate)\n",
    "position.save(sess.filePrefix.with_suffix(\".position.npy\"))\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "ax.plot(position.x, position.y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linearize position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils import position_util\n",
    "\n",
    "for e in ['re-maze']:\n",
    "    maze = sess.paradigm[e].flatten()\n",
    "    maze_pos = sess.position.time_slice(maze[0],maze[1])\n",
    "    linear_pos = position_util.linearize_position(maze_pos)\n",
    "    e = e.replace('-','')\n",
    "    # linear_pos.save(sess.filePrefix.with_suffix(f'.{e}.linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_,ax = plt.subplots()\n",
    "ax.plot(linear_pos.time,linear_pos.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString,Polygon\n",
    "\n",
    "line = LineString([(0,0),(1,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "maze = sess.paradigm['maze'].flatten()\n",
    "position = sess.position.time_slice(maze[0],maze[1])\n",
    "x,y = position.x,position.y\n",
    "\n",
    "# line = Polygon(zip(x[::30],y[::30]))\n",
    "\n",
    "xbin = np.arange(x.min(),x.max(),2)\n",
    "ybin = np.arange(y.min(),y.max(),2)\n",
    "occupancy = np.histogram2d(x,y,bins=[xbin,ybin])[0]\n",
    "occupancy = occupancy/60\n",
    "# occupancy = np.sqrt(occupancy)\n",
    "# occupancy = gaussian_filter(occupancy,sigma=2)\n",
    "\n",
    "x_max,y_max = np.where(occupancy>=0.5) \n",
    "\n",
    "# plt.plot(x,y,'r')\n",
    "plt.pcolormesh(xbin[:-1],ybin[:-1],np.flipud(np.rot90(occupancy)),shading='gouraud',vmax=5)\n",
    "plt.plot(xbin[x_max],ybin[y_max],'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backend_bases import MouseButton\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "maze = sess.paradigm['re-maze'].flatten()\n",
    "position = sess.position.time_slice(*maze)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(position.x,position.y)\n",
    "\n",
    "coord = []\n",
    "\n",
    "def on_click(event):\n",
    "    if (event.button is MouseButton.LEFT) and (event.inaxes):\n",
    "        # print(f'{event.xdata} {event.ydata}')\n",
    "        # ax.plot(event.xdata,event.ydata,'r',lw=20)\n",
    "        global coord\n",
    "\n",
    "        coord.append((event.xdata, event.ydata))\n",
    "        x = event.xdata\n",
    "        y = event.ydata\n",
    "        \n",
    "        ax.plot(x,y,'o',color='r')\n",
    "        fig.canvas.draw() #redraw the figure\n",
    "    \n",
    "    if (event.button is MouseButton.RIGHT):\n",
    "        fig.disconnent()\n",
    "    \n",
    "\n",
    "\n",
    "        # plt.disconnect(binding_id)\n",
    "\n",
    "fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString\n",
    "line = LineString(coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_delta = 2\n",
    "distances = np.arange(0, line.length, distance_delta)\n",
    "# or alternatively without NumPy:\n",
    "# points_count = int(line.length // distance_delta) + 1\n",
    "# distances = (distance_delta * i for i in range(points_count))\n",
    "points = [line.interpolate(distance) for distance in distances] + [line.boundary[1]]\n",
    "# multipoint = unary_union(points)  # or new_line = LineString(points)\n",
    "new_line = LineString(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots()\n",
    "plt.plot(*line.xy,'r.')\n",
    "plt.plot(*new_line.xy,'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "lin_pos = []\n",
    "for x,y in zip(position.x,position.y):\n",
    "    lin_pos.append(line.project(Point(x,y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core import Position\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "lin_pos = np.array(lin_pos).reshape(1,-1)\n",
    "lin_pos = gaussian_filter1d(lin_pos,sigma=6)\n",
    "linear_position = Position(traces=lin_pos,t_start=maze[0],sampling_rate=position.sampling_rate,metadata={'method':'shapely linearization'}) \n",
    "linear_position.save(sess.filePrefix.with_suffix('.remaze.linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,ax = plt.subplots()\n",
    "ax.plot(linear_position.time,linear_position.x)\n",
    "ax.plot(linear_position.time,linear_position.speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(position.time,lin_pos)\n",
    "plt.plot(position.time,position.x)\n",
    "# plt.plot(sess.lin_maze.time,sess.lin_maze.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hfuncs import linearize_using_shapely\n",
    "\n",
    "maze = sess.paradigm['maze'].flatten()\n",
    "linearize_using_shapely(sess.position.time_slice(*maze))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cce1618081139d19eb1ee8d40815d94a2de4f62e1efb20d9406ddb60628c36ae"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('data_analysis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
