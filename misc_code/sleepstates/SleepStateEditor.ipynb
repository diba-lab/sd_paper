{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies \n",
    "* ephyviewer\n",
    "* pyqtgraph\n",
    "\n",
    "```bash\n",
    "\n",
    "conda install ephyviewer\n",
    "conda install -c conda-forge pyqtgraph\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ephyviewer import (\n",
    "    mkQApp,\n",
    "    MainViewer,\n",
    "    TraceViewer,\n",
    "    CsvEpochSource,\n",
    "    EpochViewer,\n",
    "    WritableEpochSource,\n",
    "    EpochEncoder,\n",
    "    SpikeTrainViewer,\n",
    "    TimeFreqViewer,\n",
    ")\n",
    "from ephyviewer import (\n",
    "    InMemoryEpochSource,\n",
    "    InMemorySpikeSource,\n",
    "    InMemoryAnalogSignalSource,\n",
    ")\n",
    "import numpy as np\n",
    "import subjects\n",
    "import os\n",
    "import pandas as pd\n",
    "import signal_process\n",
    "import ephyviewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sleep states data load/save\n",
    "\n",
    "Inherits `WritableEpochSource` from `ephyviewer` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class statesSource(WritableEpochSource):\n",
    "    def __init__(\n",
    "        self,\n",
    "        filename,\n",
    "        possible_labels,\n",
    "        color_labels=None,\n",
    "        channel_name=\"\",\n",
    "        restrict_to_possible_labels=False,\n",
    "    ):\n",
    "\n",
    "        self.filename = filename\n",
    "\n",
    "        WritableEpochSource.__init__(\n",
    "            self,\n",
    "            epoch=None,\n",
    "            possible_labels=possible_labels,\n",
    "            color_labels=color_labels,\n",
    "            channel_name=channel_name,\n",
    "            restrict_to_possible_labels=restrict_to_possible_labels,\n",
    "        )\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"\n",
    "        Returns a dictionary containing the data for an epoch.\n",
    "        Data is loaded from the CSV file if it exists; otherwise the superclass\n",
    "        implementation in WritableEpochSource.load() is called to create an\n",
    "        empty dictionary with the correct keys and types.\n",
    "        The method returns a dictionary containing the loaded data in this form:\n",
    "        { 'time': np.array, 'duration': np.array, 'label': np.array, 'name': string }\n",
    "        \"\"\"\n",
    "\n",
    "        if os.path.exists(self.filename):\n",
    "            # if file already exists, load previous epoch\n",
    "            data = pd.read_pickle(self.filename)\n",
    "            df = pd.DataFrame()\n",
    "            df[\"time\"] = data[\"start\"]\n",
    "            df[\"duration\"] = data[\"end\"] - data[\"start\"]\n",
    "            df[\"label\"] = \"U\"\n",
    "            state_number_dict = {\n",
    "                1: \"nrem\",\n",
    "                2: \"rem\",\n",
    "                3: \"quiet\",\n",
    "                4: \"active\",\n",
    "            }\n",
    "            data[\"name\"] = data[\"state\"].map(state_number_dict)\n",
    "\n",
    "            epoch_labels = np.array([f\" State{_}\" for _ in data[\"state\"]])\n",
    "            epoch = {\n",
    "                \"time\": data[\"start\"].values,\n",
    "                \"duration\": data[\"end\"].values - data[\"start\"].values,\n",
    "                \"label\": epoch_labels,\n",
    "            }\n",
    "        else:\n",
    "            # if file does NOT already exist, use superclass method for creating\n",
    "            # an empty dictionary\n",
    "            epoch = super().load()\n",
    "\n",
    "        return epoch\n",
    "\n",
    "    def save(self):\n",
    "        df = pd.DataFrame()\n",
    "        df[\"start\"] = np.round(self.ep_times, 6)  # round to nearest microsecond\n",
    "        df[\"end\"] = np.round(self.ep_times, 6) + np.round(\n",
    "            self.ep_durations\n",
    "        )  # round to nearest microsecond\n",
    "        df[\"duration\"] = np.round(\n",
    "            self.ep_durations, 6\n",
    "        )  # round to nearest microsecond\n",
    "        state_number_dict = {\"nrem\": 1, \"rem\": 2, \"quiet\": 3, \"active\": 4}\n",
    "        df[\"name\"] = self.ep_labels\n",
    "        df[\"state\"] = df[\"name\"].map(state_number_dict)\n",
    "        df.sort_values([\"time\", \"duration\", \"name\"], inplace=True)\n",
    "        df.to_pickle(self.filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sessions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = subjects.Sd().ratNday1[0]\n",
    "filename = sess.brainstates.files.states\n",
    "state_labels = sess.brainstates.labels\n",
    "chan_lfp = np.asarray(sess.recinfo.geteeg(chans=56)).reshape(-1, 1)\n",
    "filtered_lfp = signal_process.filter_sig.bandpass(chan_lfp, lf=120, hf=150, ax=0, fs=1250)\n",
    "source_epoch = statesSource(str(filename), state_labels)\n",
    "sample_rate = sess.recinfo.lfpSrate\n",
    "t_start = 0.0\n",
    "\n",
    "signals = np.hstack((chan_lfp,filtered_lfp))\n",
    "\n",
    "ephyviewer.VideoViewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding views for browsing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you must first create a main Qt application (for event loop)\n",
    "app = mkQApp()\n",
    "\n",
    "# Create the main window that can contain several viewers\n",
    "win = MainViewer(debug=True, show_auto_scale=True)\n",
    "\n",
    "# create a viewer for signal\n",
    "view1 = TraceViewer.from_numpy(\n",
    "    np.hstack((sigs, filtered_sig)), sample_rate, t_start, \"Signals\"\n",
    ")\n",
    "view1.params[\"scale_mode\"] = \"same_for_all\"\n",
    "view1.auto_scale()\n",
    "win.add_view(view1)\n",
    "\n",
    "source_sig = InMemoryAnalogSignalSource(sigs, sample_rate, t_start)\n",
    "# create a viewer for the encoder itself\n",
    "view2 = EpochEncoder(source=source_epoch, name=\"Dev mood states along day\")\n",
    "win.add_view(view2)\n",
    "\n",
    "view3 = TimeFreqViewer(source=source_sig, name=\"tfr\")\n",
    "view3.params[\"show_axis\"] = False\n",
    "view3.params[\"timefreq\", \"deltafreq\"] = 1\n",
    "win.add_view(view3)\n",
    "\n",
    "\n",
    "# ----- spikes --------\n",
    "spikes = sess.spikes.pyr\n",
    "spk_id = sess.spikes.pyrid\n",
    "\n",
    "all_spikes = []\n",
    "for i, (t, id_) in enumerate(zip(spikes, spk_id)):\n",
    "    all_spikes.append({\"time\": t, \"name\": f\"Unit {i}\"})\n",
    "\n",
    "spike_source = InMemorySpikeSource(all_spikes=all_spikes)\n",
    "view4 = SpikeTrainViewer(source=spike_source)\n",
    "win.add_view(view4)\n",
    "# show main window and run Qapp\n",
    "win.show()\n",
    "\n",
    "\n",
    "app.exec_()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b10c821bc4bd3f433a613d47515e6babc6c2152896bd1e143404cc9d6ede4ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('data_analysis': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}